{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Spectral Feature Extracted based on SSD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn as sk\n",
    "from scipy import signal, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n",
    "feat_path = os.path.join(projectpath, 'results', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_plotting.expl_plotting as expl_plot\n",
    "import lfpecog_features.feats_spectral_baseline as specBase\n",
    "import lfpecog_features.feats_spectral_features as spectral\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "import lfpecog_analysis.get_acc_derivs as accDerivs\n",
    "\n",
    "\n",
    "from lfpecog_plotting.plotHelpers import remove_duplicate_legend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LEN_sec = 10\n",
    "WIN_OVERLAP_part = 0.0\n",
    "ssd_path = os.path.join(feat_path, 'SSD_powers',\n",
    "                        f'windows_{WIN_LEN_sec}s_'\n",
    "                        f'{WIN_OVERLAP_part}overlap')\n",
    "IGNORE_PTS = ['010', '014',]\n",
    "\n",
    "LID_SCORE_INCL = 1  # from this score, features are labeled into LID+ group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available subs with features \n",
    "SUBS = list(set([name.split('_')[1] for name in os.listdir(ssd_path)]))\n",
    "\n",
    "for sub in IGNORE_PTS:\n",
    "    SUBS.remove(sub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try:\n",
    "- only include ECoG and ipsilateral STN LFP\n",
    "- exclude moments where was only Dyskinesia in body-side ipsilateral to ECoG (NOT CORRESPONDING WITH ECoG-hemisphere)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Load Clinical Scores\n",
    "\n",
    "Select moments with Dyskinesia at WRONG BODYSIDE (ipsilateral to ECoG) for removal later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = {}\n",
    "ECOG_SIDES = {}\n",
    "REMOVE_TIMES = {}  # remove moments with only 'WRONG SIDE' dyskinesia\n",
    "\n",
    "for sub in SUBS:\n",
    "        # get CDRS\n",
    "        scores_temp = importClin.run_import_clinInfo(sub=sub)\n",
    "                # check if scores are present\n",
    "        if type(scores_temp) == type(None):\n",
    "                print(f'None CDRS-scores loaded for sub {sub}')\n",
    "                continue\n",
    "\n",
    "        # get ECoG-side\n",
    "        ecog_side = importClin.get_ecog_side(sub)\n",
    "        ECOG_SIDES[sub] = ecog_side\n",
    "        # define CDRS of body-side to include\n",
    "        if ecog_side == 'left': LID_side_incl = 'right'\n",
    "        elif ecog_side == 'right': LID_side_incl = 'left'\n",
    "        \n",
    "        # identify minutes to remove bcs only Dyskinesia at none-ECoG side\n",
    "        REMOVE_TIMES[sub] = []\n",
    "        for i, t in enumerate(scores_temp['dopa_time']):\n",
    "                if np.logical_and(scores_temp.iloc[i][f'CDRS_total_{LID_side_incl}'] < 1,\n",
    "                                scores_temp.iloc[i][f'CDRS_total_{ecog_side}'] > 0):\n",
    "                        REMOVE_TIMES[sub].append(t)\n",
    "\n",
    "        # include selected CDRS\n",
    "        SCORES[sub] = scores_temp[['dopa_time', f'CDRS_total_{LID_side_incl}']]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Load Features\n",
    "\n",
    "Only include ECoG and ECoG-sided STN-LFP for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = {}\n",
    "for sub in SUBS:\n",
    "    ecog_side = ECOG_SIDES[sub]\n",
    "    # load ECog Features\n",
    "    ecog_fts = pd.read_csv(os.path.join(ssd_path, f'SSDfeatures_{sub}_ecog_{ecog_side}.csv'),\n",
    "                            index_col=0, header=0)\n",
    "    # rename and add ECOG to ft-names\n",
    "    rename_cols = {}\n",
    "    for key in ecog_fts.keys(): rename_cols[key] = f'ECOG_{key}'\n",
    "    ecog_fts = ecog_fts.rename(columns=rename_cols)\n",
    "    \n",
    "    # load ECog Features\n",
    "    stn_fts = pd.read_csv(os.path.join(ssd_path, f'SSDfeatures_{sub}_lfp_{ecog_side}.csv'),\n",
    "                            index_col=0, header=0)\n",
    "    # rename and add STN to ft-names\n",
    "    rename_cols = {}\n",
    "    for key in stn_fts.keys(): rename_cols[key] = f'STN_{key}'\n",
    "    stn_fts = stn_fts.rename(columns=rename_cols)\n",
    "\n",
    "    merged_fts = pd.concat([stn_fts, ecog_fts], axis=1, ignore_index=False)\n",
    "    merged_fts.index = merged_fts.index / 60  # convert to minutes to agree with CDRS score\n",
    "    FEATS[sub] = merged_fts\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Prepare Features and Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features to exclude and get CDRS scores to remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 106 rows in sub-013\n",
      "removed 244 rows in sub-014\n",
      "removed 0 rows in sub-016\n",
      "removed 0 rows in sub-009\n",
      "removed 0 rows in sub-008\n",
      "removed 0 rows in sub-012\n"
     ]
    }
   ],
   "source": [
    "# REMOVE ROWS DUE TO DYSKINESIA ONLY (!!) IN NONE-ECOG-SIDE\n",
    "for sub in SUBS:\n",
    "  ft_times = FEATS[sub].index\n",
    "  score_times = SCORES[sub]['dopa_time']\n",
    "\n",
    "  remove_ft_idx = []\n",
    "  # select feature-rows which are closest to a CDRS-moments which should be excluded\n",
    "  for ft_row, t in enumerate(ft_times):\n",
    "      t_diffs = abs(score_times - t)\n",
    "      i = np.argmin(t_diffs)\n",
    "\n",
    "      if score_times[i] in REMOVE_TIMES[sub]:\n",
    "        remove_ft_idx.append(ft_times[i])  \n",
    "          \n",
    "  FEATS[sub] = FEATS[sub].drop(remove_ft_idx, axis=0)\n",
    "  print(f'removed {len(remove_ft_idx)} rows in sub-{sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CDRS LABELS FOR FEATURE WINDOW TIMES\n",
    "FT_LABELS = {}\n",
    "\n",
    "for sub in SUBS:\n",
    "    ft_times = FEATS[sub].index\n",
    "\n",
    "    ft_scores = []\n",
    "\n",
    "    for t in ft_times:\n",
    "        t_diffs = abs(SCORES[sub]['dopa_time'] - t)\n",
    "        i = np.argmin(t_diffs)\n",
    "        ft_scores.append(SCORES[sub].iat[i, 1])  # take column 1, is CDRS score\n",
    "\n",
    "    FT_LABELS[sub] = ft_scores\n",
    "\n",
    "    assert FEATS[sub].shape[0] == len(FT_LABELS[sub]), (\n",
    "        'Feature DataFrame and Ft-Labels must have same length'\n",
    "    )\n",
    "# no_LID_sel = np.array(ft_scores) == 0\n",
    "# LID_sel = np.array(ft_scores) >= LID_SCORE_INCL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "013\n",
      "# of feats w/o LID 185\n",
      "# of feats WITH LID 166\n",
      "\n",
      "014\n",
      "# of feats w/o LID 322\n",
      "# of feats WITH LID 0\n",
      "\n",
      "016\n",
      "# of feats w/o LID 274\n",
      "# of feats WITH LID 88\n",
      "\n",
      "009\n",
      "# of feats w/o LID 129\n",
      "# of feats WITH LID 261\n",
      "\n",
      "008\n",
      "# of feats w/o LID 24\n",
      "# of feats WITH LID 255\n",
      "\n",
      "012\n",
      "# of feats w/o LID 33\n",
      "# of feats WITH LID 388\n"
     ]
    }
   ],
   "source": [
    "for sub in SUBS:\n",
    "    print(f'\\n{sub}')\n",
    "    bp_values_list = []\n",
    "    bp_keys = []\n",
    "\n",
    "    no_LID_sel = np.array(FT_LABELS[sub]) == 0\n",
    "    LID_sel = np.array(FT_LABELS[sub]) >= LID_SCORE_INCL\n",
    "\n",
    "    print(f'# of feats w/o LID {sum(no_LID_sel)}')\n",
    "    print(f'# of feats WITH LID {sum(LID_sel)}')\n",
    "\n",
    "    for n_col, ft in enumerate(FEATS[sub].keys()):\n",
    "        values = FEATS[sub].values[:, n_col]\n",
    "        # split values on Dyskinesia\n",
    "        no_LID_values = values[no_LID_sel]\n",
    "        LID_values = values[LID_sel]\n",
    "        # drop NaNs\n",
    "        no_LID_values = no_LID_values[~np.isnan(no_LID_values)]\n",
    "        LID_values = LID_values[~np.isnan(LID_values)]\n",
    "        # define mean and std of no-LID for Z-SCORE\n",
    "        m = np.nanmean(no_LID_values)\n",
    "        sd = np.nanstd(no_LID_values)\n",
    "        # Z-SCORE Dyskinesia values\n",
    "        Z_LID_values = (LID_values - m) / sd\n",
    "\n",
    "\n",
    "        #ä add feat and z-score values to lists for BOXPLOT\n",
    "        bp_values_list.append(list(Z_LID_values))\n",
    "        bp_keys.append(ft)\n",
    "\n",
    "    plt.boxplot(bp_values_list)\n",
    "\n",
    "    plt.hlines(y=0, xmin=0, xmax=24, color='k', alpha=.3)\n",
    "    plt.hlines(y=[-2, 2], xmin=0, xmax=24, color='r', alpha=.3)\n",
    "\n",
    "    plt.ylim(-5, 5)\n",
    "\n",
    "    plt.title(sub)\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_dysk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
