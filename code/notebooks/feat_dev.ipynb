{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Development Extraction: Neurophysiology [dyskinesia project]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b> Content </b>\n",
    "\n",
    "\n",
    "<b> Aperiodic estimates </b>\n",
    "Relevant literature:\n",
    "- Periodic and a-periodic components relevance and interaction, different reasons (per + a-per) for signal changes observed within a specific bandwidth. Aperiodic component (complicated) vs exponent (1/f) (Donoghue, ..., Shestyuk & Voytek, Nature Neurosc 2020 : https://www.nature.com/articles/s41593-020-00744-x)\n",
    "- cycle-by-cycle features: bycycle toolbox (Cole & Voytek, J of Neurophys 2019, https://journals.physiology.org/doi/full/10.1152/jn.00273.2019)\n",
    "- aperiodic component, PD severity, and cortico-subcortico-activity, Bush & Zou, Richardson, bioRxiv 2023 https://www.biorxiv.org/content/10.1101/2023.02.08.527719v1?rss=1\n",
    "\n",
    "<b> Periodic component analysis: </b> \n",
    "- Try Wavelet Dceomposition vs Welch (tapered) Spectral Decomposition\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from scipy.stats import pearsonr, mannwhitneyu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib import __version__ as plt_version\n",
    "from scipy import signal, stats\n",
    "# from array import array\n",
    "# import datetime as dt\n",
    "# #mne\n",
    "# import mne_bids\n",
    "# import mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "print('matplotlib', plt_version)\n",
    "## FEB 2022:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_features.feats_spectral_baseline as specBase\n",
    "import lfpecog_features.feats_spectral_features as spectral\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "import lfpecog_features.feats_helper_funcs as ftHelp\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "# import lfpecog_analysis.get_acc_derivs as accDerivs\n",
    "\n",
    "\n",
    "import lfpecog_plotting.plotHelpers as plotHelp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load preprocessed and merged Sub-Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ACC pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_to_plot = [\n",
    "    '008', \n",
    "    # '009', '010', '012', \n",
    "    # '013', '014', '016'\n",
    "]\n",
    "\n",
    "data_version = 'v4.0'\n",
    "mins_recording = []\n",
    "\n",
    "for sub in subs_to_plot:\n",
    "    # load Acc-detected movement labels\n",
    "    acc = load_class_pickle(os.path.join(\n",
    "        get_project_path('data'),\n",
    "        'merged_sub_data', data_version, f'sub-{sub}',\n",
    "        f'{sub}_mergedData_{data_version}_accLeft.P'\n",
    "    ))\n",
    "    # acc = correct_acc_class(acc)\n",
    "\n",
    "    # mins_recording.append(acc.data.shape[0] / acc.fs / 60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ephys pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WINDOWED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_to_plot = [\n",
    "    # '008', '009', '010', '012', \n",
    "    # '013', '014',\n",
    "    '012',\n",
    "]\n",
    "task = 'rest'\n",
    "data_version = 'v3.0'\n",
    "mins_recording = []\n",
    "\n",
    "# for sub in subs_to_plot:\n",
    "#     # load Acc-detected movement labels\n",
    "#     data = load_class_pickle(os.path.join(\n",
    "#         get_project_path('data'), 'windowed_data_classes_60s',\n",
    "#         data_version, f'sub-{sub}', task,\n",
    "#         f'{sub}_mneEpochs_{task}_{data_version}_win60s_overlap0.5.P'\n",
    "#     ))\n",
    "#     # acc = correct_acc_class(acc)\n",
    "\n",
    "# data.list_mne_objects[0].times.shape\n",
    "# data.list_mne_objects[0].ch_names\n",
    "# data.list_mne_objects[0].get_data().shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGED DATA per DATATYPE (source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TASK DATA BEFORE MERGING\n",
    "sub = '019'\n",
    "data_version = 'v4.0'\n",
    "dType = 'ecog_right'\n",
    "\n",
    "path = os.path.join(get_project_path('data'),\n",
    "                    'preprocessed_data',\n",
    "                    f'sub-{sub}', 'v4.0',)\n",
    "f_data = f'data_{sub}_Rest_StimOffDopa35_{data_version}_{dType}_2048Hz.npy'\n",
    "c_data = f'names_{sub}_Rest_StimOffDopa35_{data_version}_{dType}.csv'\n",
    "\n",
    "d = np.load(os.path.join(path, f_data))\n",
    "cols = pd.read_csv(os.path.join(path, c_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MERGED PICKLE\n",
    "\n",
    "data_version = 'v4.0'\n",
    "sub = '019'\n",
    "dat = {}\n",
    "dType = 'lfp_right'\n",
    "dat[dType] = load_class_pickle(os.path.join(\n",
    "        get_project_path('data'), 'merged_sub_data',\n",
    "        'v4.0', f'sub-{sub}',\n",
    "        f'{sub}_mergedData_{data_version}_{dType}.P'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_sources = ['lfp_right', 'lfp_left' ]  #'lfp_right', 'ecog_left', 'ecog_right']\n",
    "use_stored_windows = True\n",
    "\n",
    "sub = '108'\n",
    "json_path = os.path.join(utilsFiles.get_onedrive_path('data'),\n",
    "                     'featureExtraction_jsons',\n",
    "                     'ftExtr_spectral_v6.json')\n",
    "with open(json_path, 'r') as json_data:\n",
    "    SETTINGS = json.load(json_data)\n",
    "\n",
    "windows_path = os.path.join(utilsFiles.get_project_path('data', extern_HD=False),\n",
    "                    'windowed_data_classes_'\n",
    "                    f'{SETTINGS[\"WIN_LEN_sec\"]}s_'\n",
    "                    f'{SETTINGS[\"WIN_OVERLAP_part\"]}overlap',\n",
    "                    SETTINGS['DATA_VERSION'],\n",
    "                    f'sub-{sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = {}\n",
    "for dType in ephys_sources[:1]:\n",
    "    print(f'\\tstart {dType}')\n",
    "    # define path for windows of dType\n",
    "    dType_fname = (f'sub-{sub}_windows_'\n",
    "                    f'{SETTINGS[\"WIN_LEN_sec\"]}s_'\n",
    "                    f'{SETTINGS[\"DATA_VERSION\"]}_{dType}.P')\n",
    "    dType_win_path = os.path.join(windows_path, dType_fname)\n",
    "\n",
    "    # check if windows are already available\n",
    "    if np.logical_and(use_stored_windows,\n",
    "                      os.path.exists(dType_win_path)):\n",
    "        print(f'load data from {windows_path}....')\n",
    "        # windows[dType] = utilsFiles.load_class_pickle(dType_win_path)\n",
    "        wins = utilsFiles.load_class_pickle(dType_win_path)\n",
    "        print(f'\\tWINDOWS LOADED from {dType_fname} in {windows_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore ssd'd Spectral Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.get_ssd_data as ssd\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_analysis.get_SSD_timefreqs as ssd_TimeFreq\n",
    "import lfpecog_plotting.plot_timeFreqs_ssd_psds as plot_ssd_TFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SSD construction overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT VISUAL SSD OVERVIEW\n",
    "\n",
    "# # loop over defined frequency bands\n",
    "# for bw in SETTINGS['SPECTRAL_BANDS']:\n",
    "#     f_range = SETTINGS['SPECTRAL_BANDS'][bw]\n",
    "    # check whether to perform SSD\n",
    "    # (ssd_filt_data,\n",
    "    #     ssd_pattern,\n",
    "    #     ssd_eigvals\n",
    "    # ) = ssd.get_SSD_component(\n",
    "    #     data_2d=win_dat.T,\n",
    "    #     fband_interest=f_range,\n",
    "    #     s_rate=windows.fs,\n",
    "    #     use_freqBand_filtered=True,\n",
    "    #     return_comp_n=0,\n",
    "    # )\n",
    "\n",
    "#     f, psd = signal.welch(ssd_filt_data, axis=-1,\n",
    "#                     nperseg=windows.fs, fs=windows.fs)\n",
    "#     plt.plot(f, psd, label=bw)\n",
    "\n",
    "        \n",
    "\n",
    "# plt.xlim(0, 100)\n",
    "# plt.title(f'WINDOW # {i_w} - {dType.upper()}')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SSD timeseries (class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get windowed bands of different dtypes per sub\n",
    "importlib.reload(ftHelp)\n",
    "importlib.reload(ssd)\n",
    "importlib.reload(ssd_TimeFreq)\n",
    "\n",
    "sub = '022'\n",
    "\n",
    "# call from feats_extract_multivar.py\n",
    "ssd_subClass = ssd.get_subject_SSDs(\n",
    "    sub=sub,\n",
    "    incl_stn=True,\n",
    "    incl_ecog=True,\n",
    "    ft_setting_fname='ftExtr_spectral_v6.json',)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore feature - dyskinesia correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature details\n",
    "WIN_LEN=10\n",
    "WIN_OVERLAP=0.5\n",
    "DATA_VERSION='v4.2'\n",
    "FT_VERSION='v7'\n",
    "SSD_BROAD=True\n",
    "INCL_STN_ONLY_PTS=True\n",
    "IGNORE_PTS=['011', '104', '106']\n",
    "\n",
    "# analysis details\n",
    "EPOCH_LEN_SEC = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find available subs\n",
    "SUBS = utilsFiles.get_avail_ssd_subs(\n",
    "    DATA_VERSION=DATA_VERSION,\n",
    "    FT_VERSION=FT_VERSION,\n",
    "    IGNORE_PTS=IGNORE_PTS\n",
    ")\n",
    "print(f'SUBS: n={len(SUBS)} ({SUBS})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_descriptive_SSD_PSDs as plot_PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ssd_TimeFreq)\n",
    "\n",
    "\n",
    "TFs = ssd_TimeFreq.get_all_ssd_timeFreqs(\n",
    "    SUBS=SUBS, FT_VERSION=FT_VERSION,\n",
    "    DATA_VERSION=DATA_VERSION,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFs['010']['lfp_right'].times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.prep_and_plot_groupTimeFreqs as groupTFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(groupTFs)\n",
    "source = 'lfp_left'\n",
    "FIG_TARGET = 'LID'\n",
    "\n",
    "(ps_arr, arr_times,\n",
    " fx, present_subs) = groupTFs.get_group_timefreq(\n",
    "    source=source, TARGET=FIG_TARGET,\n",
    "    MIN_SUBS=5, DATA_VERSION=DATA_VERSION,\n",
    "    FT_VERSION=FT_VERSION, LOG_POWER=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(groupTFs)\n",
    "\n",
    "SHOW_PRES_SUBS = True\n",
    "\n",
    "FIG_NAME = f'timeFreq_{FIG_TARGET}_{source}'\n",
    "if SHOW_PRES_SUBS: FIG_NAME += '_subs'\n",
    "\n",
    "groupTFs.plot_group_timeFreq(\n",
    "    TARGET=FIG_TARGET, SHOW_PRES_SUBS=SHOW_PRES_SUBS,\n",
    "    data_arr=ps_arr, freqs=fx, times=arr_times,\n",
    "    present_subs=present_subs,\n",
    "    save_figname=FIG_NAME,\n",
    "    FT_VERSION=FT_VERSION,\n",
    "    DATA_VERSION=DATA_VERSION,\n",
    "    fig_title=(f'Group level spectral data ({source}), '\n",
    "               'around dyskinesia-onset'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.psd_lid_stats as psd_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_freqCorr_arr(\n",
    "    datatype='STN',\n",
    "    BLOCK_LEN = 300,  # 5 minutes\n",
    "    DATA_VERSION='v4.0',\n",
    "    FT_VERSION='v6',\n",
    "):\n",
    "    store_path = os.path.join(get_project_path('results'), 'stats',\n",
    "                              f'data_{DATA_VERSION}_ft_{FT_VERSION}',\n",
    "                              f'{datatype}_LMM_noLID_vs_LID')\n",
    "    total_freqs = []\n",
    "\n",
    "    for i_f, f_hz in enumerate(np.arange(4, 90)):\n",
    "        if f_hz > 35 and f_hz < 60:\n",
    "            # print(f'skip {f_hz} Hz')\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(os.path.join(store_path,\n",
    "                         f'{datatype}_LMM_LID_PSD_{f_hz}Hz_df.xlsx'),\n",
    "                    index_col=0,)\n",
    "        statsubs = [s for s in np.unique(df['sub']) if '_match' in s]\n",
    "\n",
    "        for i_s, s in enumerate(statsubs):\n",
    "\n",
    "            sub_pows, sub_scores = [], []\n",
    "            d = df[df['sub'] == s].reset_index(drop=True)\n",
    "            # divide borders for timeblock dividing of features\n",
    "            borders = [i for i in np.arange(0, len(d), BLOCK_LEN)] + [len(d)]\n",
    "            for i1, i2 in zip(borders[:-1], borders[1:]):\n",
    "                # take mean CDRS score in block\n",
    "                sub_scores.append(np.mean(d['CDRS'][i1:i2]))\n",
    "                # take mean power in block\n",
    "                sub_pows.append(np.mean(d['mean_power'][i1:i2]))\n",
    "\n",
    "            sub_arr = np.array([\n",
    "                [s] * len(sub_pows),\n",
    "                [i_s] * len(sub_pows),\n",
    "                sub_scores, sub_pows\n",
    "            ]).T\n",
    "            if i_s == 0: f_arr = sub_arr\n",
    "            else: f_arr = np.concatenate([f_arr, sub_arr], axis=0)\n",
    "\n",
    "        if i_f == 0: total_arr = f_arr\n",
    "        else: total_arr = np.dstack([f_arr, total_arr],)\n",
    "\n",
    "        total_freqs.append(f_hz)\n",
    "\n",
    "        # print(f'{f_hz} Hz, total shape: {total_arr.shape}')\n",
    "            # print(s, sub_arr.shape, f_arr.shape)\n",
    "            # plt.scatter(sub_scores, sub_pows)\n",
    "            # plt.title(s)\n",
    "            # plt.show()\n",
    "    total_arr = total_arr.T\n",
    "    print(f'{datatype}: total shape: {total_arr.shape}, length freqs: {len(total_freqs)}')\n",
    "\n",
    "    return total_arr, total_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import mixedlm\n",
    "import lfpecog_plotting.plot_FreqCorr as plt_FreqCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqCorr_df(total_3d_arr, total_freqs=None, datatype='STN',\n",
    "                    method='GLMM',):\n",
    "    p_list, coeff_list = [], []\n",
    "    if method == 'Pearson': coeff_err_list = []\n",
    "    \n",
    "    for i_f in np.arange(total_3d_arr.shape[0]):\n",
    "        sub_strings = total_3d_arr[i_f, 0, :]\n",
    "        sub_strings = list(np.unique(sub_strings))\n",
    "        temp_df = pd.DataFrame(\n",
    "            data=total_3d_arr[i_f, 1:, :].T,\n",
    "            columns=['sub_idx', 'CDRS', 'pow']\n",
    "        ).astype(np.float64)  # leave out string sub 'sub'\n",
    "\n",
    "        if method == 'GLMM':\n",
    "            model = mixedlm(\"pow ~ CDRS\", temp_df,\n",
    "                            groups=temp_df[\"sub_idx\"])\n",
    "            result = model.fit(method='lbfgs')\n",
    "            # Extract the p-value for the Condition variable\n",
    "            p_list.append(result.pvalues['CDRS'])\n",
    "            coeff_list.append(result.fe_params['CDRS'])\n",
    "\n",
    "        elif method == 'Pearson':\n",
    "            f_Rs = []\n",
    "            for i_s, sub in enumerate(np.unique(temp_df['sub_idx'].values)):\n",
    "                dat = temp_df[temp_df['sub_idx'] == sub]\n",
    "                R, p = pearsonr(dat['CDRS'], dat['pow'])\n",
    "                f_Rs.append(R)\n",
    "                          \n",
    "                if total_freqs[i_f] in [75, 85]:\n",
    "                    plt.scatter(dat['CDRS'], dat['pow'])\n",
    "                    plt.title(f'{total_freqs[i_f]} Hz {sub_strings[i_s]} R: '\n",
    "                              f'{round(R, 3)}, p: {round(p, 5)}')\n",
    "                    plt.show()\n",
    "                    \n",
    "            coeff_list.append(np.nanmean(f_Rs))\n",
    "            coeff_err_list.append(np.nanstd(f_Rs) / np.sqrt(len(f_Rs)))\n",
    "            p_list.append(1)\n",
    "            # TODO: p_list.append() fisher corrected test for means\n",
    "                \n",
    "    # print(result.summary())\n",
    "    # plt.bar(x=total_freqs, height=coeff_list)\n",
    "    \n",
    "    if method == 'GLMM':\n",
    "        df = pd.DataFrame(data=np.array([coeff_list, p_list]).T,\n",
    "                          columns=['R', 'p'])\n",
    "    elif method == 'Pearson':\n",
    "        df = pd.DataFrame(data=np.array([coeff_list, p_list,\n",
    "                                         coeff_err_list]).T,\n",
    "                          columns=['R', 'p', 'R_stderr'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATES STN and ECOG Correlations based on stored PSD Dataframes per Hz-bin\n",
    "BLOCK_SECS = 180\n",
    "STAT_METHOD = 'Pearson'\n",
    "\n",
    "total_arr, total_f = get_3d_freqCorr_arr(\n",
    "    datatype='STN',\n",
    "    BLOCK_LEN = BLOCK_SECS,  # 300 = 5 minutes\n",
    "    DATA_VERSION=DATA_VERSION,\n",
    "    FT_VERSION=FT_VERSION,\n",
    ")\n",
    "stn_df = get_freqCorr_df(total_3d_arr=total_arr, datatype='STN',\n",
    "                         total_freqs=total_f,\n",
    "                         method=STAT_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_arr, total_f = get_3d_freqCorr_arr(\n",
    "    datatype='ECOG',\n",
    "    BLOCK_LEN = BLOCK_SECS,\n",
    "    DATA_VERSION=DATA_VERSION,\n",
    "    FT_VERSION=FT_VERSION,\n",
    ")\n",
    "ecog_df = get_freqCorr_df(total_3d_arr=total_arr, datatype='ECOG',\n",
    "                          method=STAT_METHOD, total_freqs=total_f,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(total_f, color='orange')\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(stn_df['R'], color='green')\n",
    "ax2.plot(ecog_df['R'], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plt_FreqCorr)\n",
    "\n",
    "\n",
    "freqCorr_dict = {'STN_match': stn_df,\n",
    "                 'ECOG_match': ecog_df}\n",
    "\n",
    "plt_FreqCorr.plot_FreqCorr(\n",
    "    frqCor_values=freqCorr_dict,\n",
    "    freqs=total_f,\n",
    "    use_exact_values=True,\n",
    "    save_dir=os.path.join(get_project_path('figures'),\n",
    "                          'ft_exploration',\n",
    "                          f'data_{DATA_VERSION}_ft_{FT_VERSION}',\n",
    "                          'FreqCorrPlots'),\n",
    "    fig_name=f'{SAVE_DATE}_FreqCorr_STN_ECoG_CDRSvsPow_{STAT_METHOD}_meanPer{BLOCK_SECS}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plt_FreqCorr)\n",
    "\n",
    "# calculate Rs\n",
    "FreqCorrs_results, freqs = plt_FreqCorr.calculate_Rs_FreqCorr(\n",
    "    FreqCorr_dict=FrqCor, mean_per_score=True,)\n",
    "\n",
    "# Plot mean Rs per state\n",
    "plt_FreqCorr.plot_FreqCorr(\n",
    "    FreqCorrs_results, freqs,\n",
    "    save_dir=os.path.join(get_project_path('figures'),\n",
    "                          'ft_exploration',\n",
    "                          f'data_{DATA_VERSION}_ft_{FT_VERSION}',\n",
    "                          'FreqCorrPlots'),\n",
    "    fig_name=f'{SAVE_DATE}_FreqCorr_STN_bilat_CDRS_meanPerScores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check SSD extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate SSD extraction\n",
    "\n",
    "importlib.reload(ssd)\n",
    "# loop over windows\n",
    "\n",
    "for i_w, win_dat in enumerate(windows.data[:5]):\n",
    "    win_dat = win_dat.astype(np.float64)    \n",
    "    # select only rows without missing\n",
    "    nan_rows = np.array([pd.isna(win_dat[:, i]).any()\n",
    "                for i in range(win_dat.shape[-1])])\n",
    "    win_dat = win_dat[:, ~nan_rows]\n",
    "    win_chnames = list(compress(windows.keys, ~nan_rows))\n",
    "    win_time = windows.win_starttimes[i_w]\n",
    "    \n",
    "    ssds = ssd.SSD_bands_per_window(\n",
    "        data=win_dat.T, s_rate=windows.fs,\n",
    "        freq_bands_incl=SETTINGS['SPECTRAL_BANDS'],\n",
    "    )\n",
    " \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase features to add:\n",
    "- local PAC from De Hempt (ECoG) (beta-phase, gamma-ampl)\n",
    "    - EEGLAB ASYMM PAC\n",
    "    - check calculation via entropy of amplitudes per bin\n",
    "    - or MI-inde\n",
    "- phase-phase: CHECK CAGNAN BURST WORK\n",
    "    - connectivity phase differences from Swann et al (phase-coherence) (angle STN versus angle ECoG, compare with imaginary-coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.phase_plotting as phaseplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(phaseplot)\n",
    "\n",
    "### phase difference\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# get both signals\n",
    "sig1 = ssds.lo_beta.copy()\n",
    "sig2 = ssd0.lo_beta.copy()\n",
    "# convert to analytic signal\n",
    "a1 = signal.hilbert(x=sig1,)\n",
    "a2 = signal.hilbert(x=sig2,)\n",
    "# get phase from analytical signal, convert from pi to degree\n",
    "rad1 = np.angle(a1)\n",
    "deg1 = np.rad2deg(rad1)\n",
    "rad2 = np.angle(a2)\n",
    "deg2 = np.rad2deg(rad2)\n",
    "# get difference, convert all to positive degrees (-90 -> +270)\n",
    "rad_diff = rad1 - rad2\n",
    "deg_diff = deg1 - deg2\n",
    "mask_deg = deg_diff < 0  # bool-array, 0 for values >= 0\n",
    "mask_rad = rad_diff < 0\n",
    "corr_rad = np.array([2 * np.pi] * len(rad_diff)) * mask_rad  # corr array is set 0 for pos diff-values\n",
    "rad_diff += corr_rad\n",
    "corr_deg = np.array([360] * len(deg_diff)) * mask_deg  # corr array is set 0 for pos diff-values\n",
    "deg_diff += corr_deg\n",
    "plt.plot(rad_diff, label='corr', alpha=.8, ls='dotted')\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(sig1)\n",
    "plt.plot(sig2)\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "phaseplot.plot_rose_axis(radians=rad_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_phase = ssd_014.ecog_right.lo_beta[10].copy()\n",
    "sig_ampl = ssd_014.ecog_right.broad_gamma[10].copy()\n",
    "# sig = ssds.lo_beta.copy()\n",
    "\n",
    "a_phase = signal.hilbert(x=sig_phase,)\n",
    "a_ampl = signal.hilbert(x=sig_ampl,)\n",
    "phase = np.angle(a_phase)\n",
    "phase_deg = np.rad2deg(phase)  #phase * (180 / np.pi)\n",
    "ampl = abs(a_ampl)\n",
    "plt.plot(phase)\n",
    "plt.plot(ampl)\n",
    "plt.xlim(0, 1000)\n",
    "plt.yticks([-np.pi, 0, np.pi],\n",
    "           labels=['-180', '0', '+180'],)\n",
    "plt.ylabel('Phase (degree)')\n",
    "plt.xlabel('time (samples)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpac import Pac\n",
    "import lfpecog_features.feats_phase_amp_coupling as fts_pac\n",
    "import lfpecog_features.extract_ssd_features as ssdFts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS = utilsFiles.load_ft_ext_cfg(cfg_fname='ftExtr_spectral_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(phase_fts)\n",
    "\n",
    "pac_values = fts_pac.calculate_PAC_matrix(\n",
    "    sig_pha=ssd_014.ecog_right.lo_beta,\n",
    "    sig_amp=ssd_014.ecog_right.narrow_gamma,\n",
    "    window_times=ssd_014.ecog_right.times,\n",
    "    fs=ssd_014.ecog_right.fs,\n",
    "    freq_range_pha=SETTINGS['SPECTRAL_BANDS']['lo_beta'],\n",
    "    freq_range_amp=SETTINGS['SPECTRAL_BANDS']['narrow_gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop phase-difference values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_deg = phase * (180 / np.pi)\n",
    "\n",
    "phase_bins = {}\n",
    "for bin_start in np.arange(-180, 180, 20):\n",
    "    bin_sel = np.logical_and(phase_deg > bin_start,\n",
    "                             phase_deg<(bin_start+20))\n",
    "    ampl_sel = ampl[bin_sel]\n",
    "\n",
    "    phase_bins[bin_start] = ampl_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin in phase_bins:\n",
    "    amps = phase_bins[bin]\n",
    "    plt.hist(amps,alpha=.3)\n",
    "    ent = stats.entropy(amps)\n",
    "    plt.title(f'{bin} degree: entropy {ent}')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSD with meet toolbox (https://github.com/neurophysics/meet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meet.meet as meet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "i_win = 5\n",
    "win_dat = data.list_mne_objects[i_win].get_data()  # epochs x channels x times\n",
    "ch_names = data.list_mne_objects[i_win].ch_names\n",
    "fs = data.info['sfreq']\n",
    "nperseg = 1024\n",
    "bw_ranges = {   'alpha': [8, 12],\n",
    "                'lo_beta': [12, 20],\n",
    "                'hi_beta': [20, 35],\n",
    "                'beta': [12, 35],\n",
    "                'midgamma': [60, 90]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfpecog_features import feats_SSD as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and plot SSD functionality\n",
    "\n",
    "importlib.reload(ssd)\n",
    "\n",
    "SOURCE_SEL = 'ECOG'\n",
    "F_BAND_SEL = 'midgamma'\n",
    "epoch_i = 50\n",
    "plt.close()\n",
    "# select 2d data of one source (n-channels x n-samples)\n",
    "ch_sel = [n.startswith(SOURCE_SEL) for n in ch_names]\n",
    "epoch_dat = win_dat[epoch_i, ch_sel, :]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8,8))\n",
    "\n",
    "for F_BAND_SEL in ['lo_beta', 'hi_beta', 'beta', 'midgamma']:\n",
    "    ssd_filt_data, ssd_pattern, ssd_eigvals = ssd.get_SSD_component(\n",
    "        data_2d=epoch_dat,\n",
    "        fband_interest=bw_ranges[F_BAND_SEL],\n",
    "        s_rate=fs,\n",
    "        use_freqBand_filtered=True,\n",
    "        return_comp_n=0,\n",
    "    )\n",
    "    f, psd = signal.welch(ssd_filt_data, axis=-1, nperseg=fs, fs=fs)\n",
    "\n",
    "    axes[0].plot(ssd_filt_data, label=F_BAND_SEL)\n",
    "    axes[1].plot(f, psd, label=F_BAND_SEL)\n",
    "\n",
    "# psd of origin\n",
    "for i in range(epoch_dat.shape[0]):\n",
    "    f, psd = signal.welch(epoch_dat[i, :], nperseg=fs, fs=fs)\n",
    "    axes[2].plot(f, psd, label=F_BAND_SEL, c='k', alpha=.3,)\n",
    "\n",
    "axes[0].legend(ncol=4)\n",
    "axes[1].legend()\n",
    "axes[0].set_title('SSD filtered bands', fontsize=14, weight='bold',)\n",
    "axes[0].set_ylabel('LFP (a.u.)', fontsize=14,)\n",
    "axes[0].set_xlabel('Time (samples, 2048 Hz)', fontsize=14,)\n",
    "axes[1].set_title('Freq-specific PSD after SSD', fontsize=14, weight='bold',)\n",
    "axes[2].set_title('Original PSDs of channels', fontsize=14, weight='bold',)\n",
    "\n",
    "for ax in [1, 2]:\n",
    "    axes[ax].set_xlim(0, 100)\n",
    "    axes[ax].set_xlabel('Frequency (Hz)', fontsize=14,)\n",
    "    axes[ax].set_ylabel('Power (a.u.)', fontsize=14,)\n",
    "\n",
    "for ax in axes: ax.tick_params(axis='both', labelsize=10)\n",
    "plt.tight_layout()\n",
    "figname = 'SSD_example_timeseries_PSD'\n",
    "# plt.savefig(os.path.join(figpath, 'ft_exploration', 'SSD', figname),\n",
    "#             dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot SSD Components\n",
    "# for i, b in enumerate(SSD_beta):\n",
    "#     plt.plot(b, label=f'ch {i}',\n",
    "#              alpha=(1 - (i * .2)),\n",
    "#              lw=5 - i)\n",
    "# # beta1d = SSD_beta.T @ np.atleast_2d(SSD_eigvals).T  # combined signal, not relevant\n",
    "# # plt.plot(beta1d, label='product', c='k')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_excel('C://Users/habetsj/Downloads/Mappe1.xlsx', header=1)\n",
    "\n",
    "d = d[[k for k in d.keys() if k.startswith('UPDRS')]]\n",
    "nan_sel = [~pd.isna(d.values[i]).any() for i in np.arange(d.shape[0])]\n",
    "d = d.iloc[nan_sel, :].reset_index(drop=True)\n",
    "str_sel = [any([isinstance(s, str) for s in d.iloc[i]]) for i in np.arange(d.shape[0])]\n",
    "d = d.iloc[~np.array(str_sel), :].reset_index(drop=True)\n",
    "\n",
    "plt.scatter(d.iloc[:, 1], d.iloc[:, 0])\n",
    "plt.xlabel(d.keys()[1])\n",
    "plt.ylabel(d.keys()[0])\n",
    "\n",
    "w = stats.wilcoxon(d.iloc[:, 1], d.iloc[:, 0])\n",
    "p = stats.pearsonr(d.iloc[:, 1], d.iloc[:, 0])\n",
    "plt.title(f'{p}\\n{w}\\n(n = {d.shape[0]} PD patients)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('C://Users/habetsj/Downloads/Fallzahl_OFF_ON', dpi=150, facecolor='w')\n",
    "plt.close()\n",
    "\n",
    "plt.scatter(d.iloc[:, 1], d.iloc[:, 1] - d.iloc[:, 0])\n",
    "plt.xlabel(d.keys()[1])\n",
    "plt.ylabel('UPDRS improvement due to Stimulation')\n",
    "\n",
    "w = stats.wilcoxon(d.iloc[:, 1], d.iloc[:, 1] - d.iloc[:, 0])\n",
    "p = stats.pearsonr(d.iloc[:, 1], d.iloc[:, 1] - d.iloc[:, 0])\n",
    "plt.title(f'{p}\\n{w}\\n(n = {d.shape[0]} PD patients)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('C://Users/habetsj/Downloads/Fallzahl_OFF_change', dpi=150, facecolor='w')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ecog_dysk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
