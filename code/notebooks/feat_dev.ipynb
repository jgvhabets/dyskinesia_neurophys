{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Development Extraction: Neurophysiology [dyskinesia project]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b> Content </b>\n",
    "\n",
    "\n",
    "<b> Aperiodic estimates </b>\n",
    "Relevant literature:\n",
    "- Periodic and a-periodic components relevance and interaction, different reasons (per + a-per) for signal changes observed within a specific bandwidth. Aperiodic component (complicated) vs exponent (1/f) (Donoghue, ..., Shestyuk & Voytek, Nature Neurosc 2020 : https://www.nature.com/articles/s41593-020-00744-x)\n",
    "- cycle-by-cycle features: bycycle toolbox (Cole & Voytek, J of Neurophys 2019, https://journals.physiology.org/doi/full/10.1152/jn.00273.2019)\n",
    "- aperiodic component, PD severity, and cortico-subcortico-activity, Bush & Zou, Richardson, bioRxiv 2023 https://www.biorxiv.org/content/10.1101/2023.02.08.527719v1?rss=1\n",
    "\n",
    "<b> Periodic component analysis: </b> \n",
    "- Try Wavelet Dceomposition vs Welch (tapered) Spectral Decomposition\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from scipy.stats import pearsonr, mannwhitneyu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import signal, stats\n",
    "from array import array\n",
    "import datetime as dt\n",
    "# #mne\n",
    "# import mne_bids\n",
    "import mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "## FEB 2022:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_plotting.expl_plotting as expl_plot\n",
    "import lfpecog_features.feats_spectral_baseline as specBase\n",
    "import lfpecog_features.feats_spectral_features as spectral\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "import lfpecog_features.feats_helper_funcs as ftHelp\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "# import lfpecog_analysis.get_acc_derivs as accDerivs\n",
    "\n",
    "\n",
    "import lfpecog_plotting.plotHelpers as plotHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(plotHelp.get_colors().values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and Plot CDRS scores from both raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traces\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores_bilat = []\n",
    "max_scores_ecoglat = []\n",
    "rater='Patricia'\n",
    "\n",
    "for s in ['008', '009', '010', '012',\n",
    "             '013', '014', '016', '017']:\n",
    "\n",
    "    t, scores = importClin.get_cdrs_specific(\n",
    "        sub=s, rater=rater, side='both')\n",
    "    max_scores_bilat.append(np.nanmax(scores))\n",
    "\n",
    "    t, scores = importClin.get_cdrs_specific(\n",
    "        sub=s, rater=rater, side='contra ecog')\n",
    "    max_scores_ecoglat.append(np.nanmax(scores))\n",
    "\n",
    "print('BILATERAL', max_scores_bilat, np.mean(max_scores_bilat))\n",
    "print('ECoG lat.', max_scores_ecoglat, np.mean(max_scores_ecoglat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(importClin)\n",
    "# CHECK CLINICAL RATINGS\n",
    "subs_incl = ['008', '009', '010', '012',\n",
    "             '013', '014', '016']\n",
    "\n",
    "clrs = colors\n",
    "styles = ['solid', 'dotted']\n",
    "fig, axes = plt.subplots(1,1, figsize=(12, 6))\n",
    "\n",
    "for i_sub, sub in enumerate(subs_incl):\n",
    "    reg_t, reg_scores = {}, {}\n",
    "    for i_r, rater in enumerate(['Patricia', 'Jeroen']):\n",
    "        t, scores = importClin.get_cdrs_specific(sub=sub, rater=rater)\n",
    "        axes.plot(t, scores,  # [0]\n",
    "                color=clrs[i_sub], ls=styles[i_r], lw=3, label=f'{sub} ({rater})')\n",
    "\n",
    "        # regularize scores\n",
    "        reg_t[i_r], reg_scores[i_r] = importClin.get_cdrs_specific(\n",
    "            sub=sub, rater=rater, regularize=True,)\n",
    "        # axes[1].plot(reg_t[i_r], reg_scores[i_r],\n",
    "        #         color=clrs[i_sub], ls=styles[i_r], lw=3, )\n",
    "    \n",
    "    # calculate correlations\n",
    "    # only take minutes present in both scores\n",
    "    t_start = max([reg_t[i_r][0] for i_r in [0, 1]])\n",
    "    t_stop = min([reg_t[i_r][-1] for i_r in [0, 1]])\n",
    "    sel0 = [time >= t_start and time <= t_stop for time in reg_t[0]]\n",
    "    sel1 = [time >= t_start and time <= t_stop for time in reg_t[1]]\n",
    "    \n",
    "    print(sub, pearsonr(reg_scores[0][sel0], reg_scores[1][sel1]))\n",
    "\n",
    "# axes[0].set_title('Inserted scores per timepoint', size=14)\n",
    "# axes[1].set_title('Interpolated scores (per 1 minute)', size=14)\n",
    "handles, labels = axes.get_legend_handles_labels()\n",
    "plt.legend(handles, labels, ncol=5, bbox_to_anchor=(.5, -.25),\n",
    "               loc='upper center', fontsize=14,)\n",
    "# for ax in axes:\n",
    "axes.set_ylabel('CDRS score', fontsize=14)\n",
    "axes.set_xlabel('Time (minutes vs LDOPA-intake)', fontsize=14)\n",
    "axes.tick_params(axis='both', labelsize=14, size=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "# figname = 'CDRS_scores_2rater_interpolation'\n",
    "# plt.savefig(os.path.join(figpath, 'clinical_scores', figname), dpi=150,\n",
    "#             facecolor='w',)\n",
    "# figname = 'CDRS_scores_2raters'\n",
    "# plt.savefig(os.path.join(figpath, 'clinical_scores', figname), dpi=150,\n",
    "#             facecolor='w',)\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Merged Sub-Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load none ephys pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_to_plot = [\n",
    "    '008', '009', '010', '012', \n",
    "    '013', '014', '016']\n",
    "\n",
    "data_version = 'v3.1'\n",
    "mins_recording = []\n",
    "\n",
    "for sub in subs_to_plot:\n",
    "    # load Acc-detected movement labels\n",
    "    acc = load_class_pickle(os.path.join(\n",
    "        get_project_path('data'),\n",
    "        'merged_sub_data', data_version,\n",
    "        f'{sub}_mergedDataClass_{data_version}_noEphys.P'\n",
    "    ))\n",
    "    acc = correct_acc_class(acc)\n",
    "\n",
    "    mins_recording.append(acc.data.shape[0] / acc.fs / 60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ephys pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WINDOWED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_to_plot = [\n",
    "    # '008', '009', '010', '012', \n",
    "    # '013', '014',\n",
    "    '012',\n",
    "]\n",
    "task = 'rest'\n",
    "data_version = 'v3.0'\n",
    "mins_recording = []\n",
    "\n",
    "# for sub in subs_to_plot:\n",
    "#     # load Acc-detected movement labels\n",
    "#     data = load_class_pickle(os.path.join(\n",
    "#         get_project_path('data'), 'windowed_data_classes_60s',\n",
    "#         data_version, f'sub-{sub}', task,\n",
    "#         f'{sub}_mneEpochs_{task}_{data_version}_win60s_overlap0.5.P'\n",
    "#     ))\n",
    "#     # acc = correct_acc_class(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.list_mne_objects[0].times.shape\n",
    "\n",
    "data.list_mne_objects[0].ch_names\n",
    "\n",
    "data.list_mne_objects[0].get_data().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGED DATA per DATATYPE (source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_incl = [\n",
    "    '013', \n",
    "    # '009', '010', '012', \n",
    "    # '013', '014',\n",
    "    # '012',\n",
    "]\n",
    "# task = 'rest'\n",
    "data_version = 'v3.0'\n",
    "\n",
    "# for sub in subs_incl:\n",
    "#     # load merged data class\n",
    "#     data = load_class_pickle(os.path.join(\n",
    "#         get_project_path('data'), 'merged_sub_data',\n",
    "#         data_version,\n",
    "#         f'{sub}_mergedDataClass_{data_version}.P'\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '012'\n",
    "dat = {}\n",
    "dType = 'lfp_left'\n",
    "dat[dType] = load_class_pickle(os.path.join(\n",
    "        get_project_path('data'), 'merged_sub_data',\n",
    "        data_version, f'sub-{sub}',\n",
    "        f'{sub}_mergedData_{data_version}_{dType}.P'\n",
    "    ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_sources = ['lfp_left', ]  #'lfp_right', 'ecog_left', 'ecog_right']\n",
    "use_stored_windows = True\n",
    "\n",
    "sub = '014'\n",
    "json_path = os.path.join(utilsFiles.get_onedrive_path('data'),\n",
    "                     'featureExtraction_jsons',\n",
    "                     'ftExtr_spectral_v1.json')\n",
    "with open(json_path, 'r') as json_data:\n",
    "    SETTINGS = json.load(json_data)\n",
    "\n",
    "windows_path = os.path.join(utilsFiles.get_project_path('data'),\n",
    "                    'windowed_data_classes_'\n",
    "                    f'{SETTINGS[\"WIN_LEN_sec\"]}s_'\n",
    "                    f'{SETTINGS[\"WIN_OVERLAP_part\"]}overlap',\n",
    "                    SETTINGS['DATA_VERSION'],\n",
    "                    f'sub-{sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dType in ephys_sources:\n",
    "    print(f'\\tstart {dType}')\n",
    "    # define path for windows of dType\n",
    "    dType_fname = (f'sub-{sub}_windows_'\n",
    "                    f'{SETTINGS[\"WIN_LEN_sec\"]}s_'\n",
    "                    f'{SETTINGS[\"DATA_VERSION\"]}_{dType}.P')\n",
    "    dType_win_path = os.path.join(windows_path, dType_fname)\n",
    "    \n",
    "    # check if windows are already available\n",
    "    if np.logical_and(use_stored_windows,\n",
    "                        os.path.exists(dType_win_path)):\n",
    "        print(f'load data from {windows_path}....')\n",
    "        windows = utilsFiles.load_class_pickle(dType_win_path)\n",
    "        print(f'\\tWINDOWS LOADED from {dType_fname} in {windows_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out none-ephys signals\n",
    "sel_chs = [c.startswith('LFP') or c.startswith('ECOG')\n",
    "            for c in windows.keys]\n",
    "print(f'GOT WINDOWS {dType}, shape: {windows.data.shape}, '\n",
    "        f'colnames: {windows.keys}')\n",
    "setattr(windows, 'data', windows.data[:, :, sel_chs])\n",
    "setattr(windows, 'keys', list(compress(windows.keys, sel_chs)))\n",
    "print(f'\\tWINDOWS {dType} ONLY EPHYS, shape: {windows.data.shape}, '\n",
    "        f'colnames: {windows.keys}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get fooof aperiodic as mean over all present channels\n",
    "\n",
    "# # loop over windows\n",
    "# for i_w, win_dat in enumerate(windows.data[:5]):\n",
    "#     win_dat = win_dat.astype(np.float64)    \n",
    "#     # select only rows without missing\n",
    "#     nan_rows = np.array([pd.isna(win_dat[:, i]).any()\n",
    "#                 for i in range(win_dat.shape[-1])])\n",
    "#     win_dat = win_dat[:, ~nan_rows]\n",
    "\n",
    "#     if dType.upper().startswith('LFP'): s = 'STN'\n",
    "#     elif dType.upper().startswith('ECOG'): s = 'ECOG'\n",
    "#     ap_offset, ap_exp, ap_fitr2 = spectral.get_aperiodic(\n",
    "#         data=win_dat.T, fs=windows.fs, method='fooof',\n",
    "#         method_params=SETTINGS['FOOOF_SETTINGS'][s],\n",
    "#     )\n",
    "#     ### TODO: FIX NOTCH CORRECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.get_ssd_data as ssd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT VISUAL SSD OVERVIEW\n",
    "\n",
    "# # loop over defined frequency bands\n",
    "# for bw in SETTINGS['SPECTRAL_BANDS']:\n",
    "#     f_range = SETTINGS['SPECTRAL_BANDS'][bw]\n",
    "    # check whether to perform SSD\n",
    "    # (ssd_filt_data,\n",
    "    #     ssd_pattern,\n",
    "    #     ssd_eigvals\n",
    "    # ) = ssd.get_SSD_component(\n",
    "    #     data_2d=win_dat.T,\n",
    "    #     fband_interest=f_range,\n",
    "    #     s_rate=windows.fs,\n",
    "    #     use_freqBand_filtered=True,\n",
    "    #     return_comp_n=0,\n",
    "    # )\n",
    "\n",
    "#     f, psd = signal.welch(ssd_filt_data, axis=-1,\n",
    "#                     nperseg=windows.fs, fs=windows.fs)\n",
    "#     plt.plot(f, psd, label=bw)\n",
    "\n",
    "        \n",
    "\n",
    "# plt.xlim(0, 100)\n",
    "# plt.title(f'WINDOW # {i_w} - {dType.upper()}')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get windowed bands of different dtypes per sub\n",
    "importlib.reload(ftHelp)\n",
    "importlib.reload(ssd)\n",
    "\n",
    "\n",
    "# call from feats_extract_multivar.py\n",
    "ssd_017 = ssd.get_subject_SSDs(\n",
    "    sub='017',\n",
    "    incl_stn=True,\n",
    "    incl_ecog=True,\n",
    "    ft_setting_fname='ftExtr_spectral_v3.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ssd)\n",
    "# loop over windows\n",
    "\n",
    "for i_w, win_dat in enumerate(windows.data[:5]):\n",
    "    win_dat = win_dat.astype(np.float64)    \n",
    "    # select only rows without missing\n",
    "    nan_rows = np.array([pd.isna(win_dat[:, i]).any()\n",
    "                for i in range(win_dat.shape[-1])])\n",
    "    win_dat = win_dat[:, ~nan_rows]\n",
    "    win_chnames = list(compress(windows.keys, ~nan_rows))\n",
    "    win_time = windows.win_starttimes[i_w]\n",
    "    \n",
    "    ssds = ssd.SSD_bands_per_window(\n",
    "        data=win_dat.T, s_rate=windows.fs,\n",
    "        freq_bands_incl=SETTINGS['SPECTRAL_BANDS'],\n",
    "    )\n",
    " \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase features to add:\n",
    "- local PAC from De Hempt (ECoG) (beta-phase, gamma-ampl)\n",
    "    - EEGLAB ASYMM PAC\n",
    "    - check calculation via entropy of amplitudes per bin\n",
    "    - or MI-inde\n",
    "- phase-phase: CHECK CAGNAN BURST WORK\n",
    "    - connectivity phase differences from Swann et al (phase-coherence) (angle STN versus angle ECoG, compare with imaginary-coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.phase_plotting as phaseplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(phaseplot)\n",
    "\n",
    "### phase difference\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# get both signals\n",
    "sig1 = ssds.lo_beta.copy()\n",
    "sig2 = ssd0.lo_beta.copy()\n",
    "# convert to analytic signal\n",
    "a1 = signal.hilbert(x=sig1,)\n",
    "a2 = signal.hilbert(x=sig2,)\n",
    "# get phase from analytical signal, convert from pi to degree\n",
    "rad1 = np.angle(a1)\n",
    "deg1 = np.rad2deg(rad1)\n",
    "rad2 = np.angle(a2)\n",
    "deg2 = np.rad2deg(rad2)\n",
    "# get difference, convert all to positive degrees (-90 -> +270)\n",
    "rad_diff = rad1 - rad2\n",
    "deg_diff = deg1 - deg2\n",
    "mask_deg = deg_diff < 0  # bool-array, 0 for values >= 0\n",
    "mask_rad = rad_diff < 0\n",
    "corr_rad = np.array([2 * np.pi] * len(rad_diff)) * mask_rad  # corr array is set 0 for pos diff-values\n",
    "rad_diff += corr_rad\n",
    "corr_deg = np.array([360] * len(deg_diff)) * mask_deg  # corr array is set 0 for pos diff-values\n",
    "deg_diff += corr_deg\n",
    "plt.plot(rad_diff, label='corr', alpha=.8, ls='dotted')\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(sig1)\n",
    "plt.plot(sig2)\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "phaseplot.plot_rose_axis(radians=rad_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_phase = ssd_014.ecog_right.lo_beta[10].copy()\n",
    "sig_ampl = ssd_014.ecog_right.broad_gamma[10].copy()\n",
    "# sig = ssds.lo_beta.copy()\n",
    "\n",
    "a_phase = signal.hilbert(x=sig_phase,)\n",
    "a_ampl = signal.hilbert(x=sig_ampl,)\n",
    "phase = np.angle(a_phase)\n",
    "phase_deg = np.rad2deg(phase)  #phase * (180 / np.pi)\n",
    "ampl = abs(a_ampl)\n",
    "plt.plot(phase)\n",
    "plt.plot(ampl)\n",
    "plt.xlim(0, 1000)\n",
    "plt.yticks([-np.pi, 0, np.pi],\n",
    "           labels=['-180', '0', '+180'],)\n",
    "plt.ylabel('Phase (degree)')\n",
    "plt.xlabel('time (samples)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpac import Pac\n",
    "import lfpecog_features.feats_phase_amp_coupling as fts_pac\n",
    "import lfpecog_features.extract_ssd_features as ssdFts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS = utilsFiles.load_ft_ext_cfg(cfg_fname='ftExtr_spectral_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(phase_fts)\n",
    "\n",
    "pac_values = fts_pac.calculate_PAC_matrix(\n",
    "    sig_pha=ssd_014.ecog_right.lo_beta,\n",
    "    sig_amp=ssd_014.ecog_right.narrow_gamma,\n",
    "    window_times=ssd_014.ecog_right.times,\n",
    "    fs=ssd_014.ecog_right.fs,\n",
    "    freq_range_pha=SETTINGS['SPECTRAL_BANDS']['lo_beta'],\n",
    "    freq_range_amp=SETTINGS['SPECTRAL_BANDS']['narrow_gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop phase-difference values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_deg = phase * (180 / np.pi)\n",
    "\n",
    "phase_bins = {}\n",
    "for bin_start in np.arange(-180, 180, 20):\n",
    "    bin_sel = np.logical_and(phase_deg > bin_start,\n",
    "                             phase_deg<(bin_start+20))\n",
    "    ampl_sel = ampl[bin_sel]\n",
    "\n",
    "    phase_bins[bin_start] = ampl_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin in phase_bins:\n",
    "    amps = phase_bins[bin]\n",
    "    plt.hist(amps,alpha=.3)\n",
    "    ent = stats.entropy(amps)\n",
    "    plt.title(f'{bin} degree: entropy {ent}')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fooof for spectral features\n",
    "\n",
    "for now decided to use knee-models\n",
    "\n",
    "Â´fm_knee = FOOOF(\n",
    "    peak_width_limits=(.5, 5),\n",
    "    peak_threshold=.5,\n",
    "    aperiodic_mode='knee', # fixed or knee\n",
    "    verbose=False,\n",
    ")`\n",
    "\n",
    "fm_knee.fit(f, pxx, [4, 148])\n",
    "\n",
    "params:\n",
    "- fm_knee.get_results().error  # error of the fit\n",
    "- fm_knee.get_results().r_squared  # r^2 (goodness) of fit\n",
    "- fm_knee.get_results().aperiodic_params  # offset, knee, exponent OR offset, exponent\n",
    "- fm_knee.get_results().peak_params  # 2d array with pro row one peak's [mid-f, power, bandwidth]\n",
    "- fm_knee.get_results().gaussian_params  # 2d array with Gaussian fits of peaks [mid-f, height, sd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooof import FOOOF\n",
    "\n",
    "\n",
    "fooof_ft_path = os.path.join(\n",
    "    get_project_path('results'),\n",
    "    'features',\n",
    "    'psds',\n",
    "    'fooofed_psds',\n",
    "    f'{data_version}_60sWin_50overlap',\n",
    "    'fooof_per_10sec'\n",
    ")\n",
    "if not os.path.exists(fooof_ft_path): os.makedirs(fooof_ft_path)\n",
    "\n",
    "fooof_fig_dir = os.path.join(fooof_ft_path, 'plot_checks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs = data.info['sfreq']\n",
    "nperseg = 1024\n",
    "fooof_range = [4, 98]  # wider window -> more accurate, more comp-time\n",
    "bw_ranges = {   'alpha': [8, 12],\n",
    "                'lo_beta': [12, 20],\n",
    "                'hi_beta': [20, 35],\n",
    "                'midgamma': [60, 90]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(specHelp)\n",
    "# importlib.reload(spectral)\n",
    "\n",
    "# save_csv = True\n",
    "# plot_examples = False\n",
    "\n",
    "# n_epochs2merge = 10 / .5  # desired epoch length / current epoch length\n",
    "\n",
    "\n",
    "# for i_win in np.arange(len(data.list_mne_objects))[4:]:\n",
    "#     # get spectral power value per window (60-sec)\n",
    "#     win_dat = data.list_mne_objects[i_win].get_data()  # epochs x channels x times\n",
    "#     chnames = data.list_mne_objects[i_win].ch_names\n",
    "\n",
    "#     epoch_feats, epoch_feats_lists = {}, {}\n",
    "#     fits = {}\n",
    "\n",
    "#     for i_ep in np.arange(0, win_dat.shape[0], int(n_epochs2merge)):\n",
    "#         # merge epochs\n",
    "#         tempdat = win_dat[i_ep, :, :]\n",
    "#         for i2 in np.arange(i_ep + 1, i_ep + n_epochs2merge):\n",
    "#             try:\n",
    "#                 tempdat = np.concatenate((tempdat, win_dat[i2, :, :]), axis=1)\n",
    "#             except IndexError:  # exceeds end of array bcs of blind + 20\n",
    "#                 pass\n",
    "\n",
    "#         (\n",
    "#             epoch_feats[i_ep],\n",
    "#             epoch_feats_lists[i_ep],\n",
    "#             fits[i_ep]\n",
    "#         ) = spectral.get_fooof_fts_per_epoch(\n",
    "#             epoch_dat=tempdat,\n",
    "#             ch_names=chnames,\n",
    "#             fs=fs,\n",
    "#             nperseg=nperseg,\n",
    "#             max_n_fooof_peaks=8,\n",
    "#             fooof_range=fooof_range,\n",
    "#             i_e=i_ep, fooof_fig_dir=fooof_fig_dir,\n",
    "#             plot_examples=plot_examples,\n",
    "#         )\n",
    "\n",
    "#     all_fits = []\n",
    "#     for i in fits.keys(): all_fits.extend(fits[i])\n",
    "        \n",
    "#     print(f'WIN {i_win}, ALL epochs: mean R2 {round(np.mean(all_fits), 2)} +/- {round(np.std(all_fits), 2)}')\n",
    "\n",
    "#     fname = f'fooofPowers_{sub}_{task}_win{i_win}.csv'\n",
    "\n",
    "#     winfeats = spectral.create_windowFrame_specFeats(\n",
    "#         epoch_feats, save_csv=save_csv,\n",
    "#         csv_path=fooof_ft_path, csv_fname=fname,\n",
    "#         fooof_fits=fits,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FOOOF(\n",
    "    peak_width_limits=(.5, 5),\n",
    "    peak_threshold=.5,\n",
    "    aperiodic_mode='knee',\n",
    "    verbose=False,\n",
    "    max_n_peaks=5,\n",
    ")\n",
    "\n",
    "win_dat = data.list_mne_objects[i_win].get_data()\n",
    "f, pxx = signal.welch(win_dat[5, 2, :], fs=fs, nperseg=nperseg,)\n",
    "pxx = specHelp.correct_notch_throughs(f, pxx, np.arange(50, 1201, 50))\n",
    "\n",
    "fm.report(f, pxx, [4, 98])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSD with meet toolbox (https://github.com/neurophysics/meet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meet.meet as meet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "i_win = 5\n",
    "win_dat = data.list_mne_objects[i_win].get_data()  # epochs x channels x times\n",
    "ch_names = data.list_mne_objects[i_win].ch_names\n",
    "fs = data.info['sfreq']\n",
    "nperseg = 1024\n",
    "bw_ranges = {   'alpha': [8, 12],\n",
    "                'lo_beta': [12, 20],\n",
    "                'hi_beta': [20, 35],\n",
    "                'beta': [12, 35],\n",
    "                'midgamma': [60, 90]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfpecog_features import feats_SSD as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and plot SSD functionality\n",
    "\n",
    "importlib.reload(ssd)\n",
    "\n",
    "SOURCE_SEL = 'ECOG'\n",
    "F_BAND_SEL = 'midgamma'\n",
    "epoch_i = 50\n",
    "plt.close()\n",
    "# select 2d data of one source (n-channels x n-samples)\n",
    "ch_sel = [n.startswith(SOURCE_SEL) for n in ch_names]\n",
    "epoch_dat = win_dat[epoch_i, ch_sel, :]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8,8))\n",
    "\n",
    "for F_BAND_SEL in ['lo_beta', 'hi_beta', 'beta', 'midgamma']:\n",
    "    ssd_filt_data, ssd_pattern, ssd_eigvals = ssd.get_SSD_component(\n",
    "        data_2d=epoch_dat,\n",
    "        fband_interest=bw_ranges[F_BAND_SEL],\n",
    "        s_rate=fs,\n",
    "        use_freqBand_filtered=True,\n",
    "        return_comp_n=0,\n",
    "    )\n",
    "    f, psd = signal.welch(ssd_filt_data, axis=-1, nperseg=fs, fs=fs)\n",
    "\n",
    "    axes[0].plot(ssd_filt_data, label=F_BAND_SEL)\n",
    "    axes[1].plot(f, psd, label=F_BAND_SEL)\n",
    "\n",
    "# psd of origin\n",
    "for i in range(epoch_dat.shape[0]):\n",
    "    f, psd = signal.welch(epoch_dat[i, :], nperseg=fs, fs=fs)\n",
    "    axes[2].plot(f, psd, label=F_BAND_SEL, c='k', alpha=.3,)\n",
    "\n",
    "axes[0].legend(ncol=4)\n",
    "axes[1].legend()\n",
    "axes[0].set_title('SSD filtered bands', fontsize=14, weight='bold',)\n",
    "axes[0].set_ylabel('LFP (a.u.)', fontsize=14,)\n",
    "axes[0].set_xlabel('Time (samples, 2048 Hz)', fontsize=14,)\n",
    "axes[1].set_title('Freq-specific PSD after SSD', fontsize=14, weight='bold',)\n",
    "axes[2].set_title('Original PSDs of channels', fontsize=14, weight='bold',)\n",
    "\n",
    "for ax in [1, 2]:\n",
    "    axes[ax].set_xlim(0, 100)\n",
    "    axes[ax].set_xlabel('Frequency (Hz)', fontsize=14,)\n",
    "    axes[ax].set_ylabel('Power (a.u.)', fontsize=14,)\n",
    "\n",
    "for ax in axes: ax.tick_params(axis='both', labelsize=10)\n",
    "plt.tight_layout()\n",
    "figname = 'SSD_example_timeseries_PSD'\n",
    "# plt.savefig(os.path.join(figpath, 'ft_exploration', 'SSD', figname),\n",
    "#             dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot SSD Components\n",
    "# for i, b in enumerate(SSD_beta):\n",
    "#     plt.plot(b, label=f'ch {i}',\n",
    "#              alpha=(1 - (i * .2)),\n",
    "#              lw=5 - i)\n",
    "# # beta1d = SSD_beta.T @ np.atleast_2d(SSD_eigvals).T  # combined signal, not relevant\n",
    "# # plt.plot(beta1d, label='product', c='k')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSD on 2D arrays to get info about spatial patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SSD # 1\n",
    "ssd_obj, ssd_sources = specHelp.SSD_on_array(\n",
    "    array=multi_arr, fs=fs,\n",
    "    freqband_to_optim=(14, 18)\n",
    ")\n",
    "\n",
    "# spec_ratio, sorter = ssd_obj.get_spectral_ratio(ssd_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(specHelp)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "xlabels = [1, 5, 10, 25, 50, 75, 100, 200, 400]\n",
    "\n",
    "freqs_ssd = (16, 20)\n",
    "longsig = np.ravel(ch_wins[:20:2, :])\n",
    "sig = np.ravel(ch_wins[18:20, :])\n",
    "\n",
    "ssd_sig = longsig\n",
    "\n",
    "f, Px = signal.welch(\n",
    "    ssd_sig, fs=fs, nperseg=nperseg,\n",
    ")\n",
    "f[0] = 1\n",
    "axes[0].plot(\n",
    "        np.log(f), np.log(Px),\n",
    "        alpha=.5, color='k',)\n",
    "axes[0].set_xticks(np.log(xlabels))\n",
    "axes[0].set_xticklabels(xlabels)\n",
    "axes[0].set_xlabel('Log-Freq (Hz)')\n",
    "axes[0].set_ylabel('Log-Power')\n",
    "axes[0].set_xlim(0, np.log(50))\n",
    "\n",
    "axes[0].set_title('Original')\n",
    "\n",
    "# Perform SSD # 1\n",
    "ssd_obj, ssd_sources = specHelp.SSD_on_array(\n",
    "    array=ssd_sig, fs=fs,\n",
    "    freqband_to_optim=freqs_ssd\n",
    ")\n",
    "print(ssd_sources.shape)\n",
    "psd, freqs = mne.time_frequency.psd_array_welch(\n",
    "    ssd_sources, sfreq=fs, n_fft=1024)\n",
    "\n",
    "freqs[0] = 1\n",
    "axes[1].plot(\n",
    "    np.log(freqs), np.log(np.ravel(psd)),\n",
    "    alpha=.5, color='k',)\n",
    "axes[1].set_xticks(np.log(xlabels))\n",
    "axes[1].set_xticklabels(xlabels)\n",
    "axes[1].set_xlabel('Log-Freq (Hz)')\n",
    "axes[1].set_ylabel('Log-Power')\n",
    "axes[1].set_xlim(0, np.log(50))\n",
    "\n",
    "for ax in axes:\n",
    "    ax.fill_betweenx(\n",
    "        y=ax.get_ylim(),\n",
    "        x1=np.log(freqs_ssd[0]), x2=np.log(freqs_ssd[1]),\n",
    "        color='orange', alpha=.2,)\n",
    "axes[1].set_title(f'After SSD on {freqs_ssd} Hz')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get fooof running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooof import FOOOF\n",
    "fm = FOOOF()\n",
    "\n",
    "# FOOOF peak definition -> MODULE\n",
    "beta_range = [13, 30]\n",
    "gamma_range = [60, 90]\n",
    "fm = FOOOF(\n",
    "    peak_width_limits=(.5, 5),\n",
    "    peak_threshold=.5,\n",
    "    aperiodic_mode='fixed',\n",
    "    verbose=False,\n",
    ")\n",
    "f_range = [3, 90]\n",
    "fm.fit(fx, psd, f_range)\n",
    "beta_f, beta_P, beta_w = get_band_peak_fm(fm, beta_range, select_highest=True)\n",
    "gamma_f, gamma_P, gamma_w = get_band_peak_fm(fm, gamma_range, select_highest=True)\n",
    "print(f'Peak frequencies:\\nBeta ({beta_range} Hz) peak: '\n",
    "    f'{np.round(beta_f, 1)} Hz\\nGamma ({gamma_range}) peak: '\n",
    "    f'{np.round(gamma_f, 1)} Hz')\n",
    "# fm.plot()\n",
    "# creating bandwidth around Gamma-peak\n",
    "gamma_frange_psd = [\n",
    "    np.argmin(abs(fx - (gamma_f - 5))),\n",
    "    np.argmin(abs(fx - gamma_f)),  # gamma peak freq in psd-frqs\n",
    "    np.argmin(abs(fx - (gamma_f + 5)))\n",
    "]  # gamma freq-range [-5 hz, peak Hz, +5 hz]\n",
    "gamma_peak_height = logpsd[gamma_frange_psd[1]] - np.mean([\n",
    "    logpsd[gamma_frange_psd[0]], logpsd[gamma_frange_psd[2]]\n",
    "])\n",
    "# creating bandwidth around Beta-peak\n",
    "beta_frange_psd = [\n",
    "    np.argmin(abs(fx - (beta_f - 5))),\n",
    "    np.argmin(abs(fx - beta_f)),  # gamma peak freq in psd-frqs\n",
    "    np.argmin(abs(fx - (beta_f + 5)))\n",
    "]  # gamma freq-range [-5 hz, peak Hz, +5 hz]\n",
    "beta_peak_height = logpsd[beta_frange_psd[1]] - np.mean([\n",
    "    logpsd[beta_frange_psd[0]], logpsd[beta_frange_psd[2]]\n",
    "])\n",
    "print(f'Local peak heights:\\nBeta: {beta_peak_height},\\n'\n",
    "    f'Gamma: {gamma_peak_height}')\n",
    "\n",
    "### PLOTTING\n",
    "fig, ax  = plt.subplots(1,1, figsize=(4, 4))\n",
    "ax.plot(fx, logpsd)\n",
    "ax.set_xlim(60, 95)\n",
    "\n",
    "ax.scatter(\n",
    "    fx[gamma_frange_psd],\n",
    "    logpsd[gamma_frange_psd]\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "## take psd plots from before\n",
    "## 4d polynominal fit for gamma peak detect (also beta peak)\n",
    "## beta-gamma power around peak\n",
    "## coherence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore spectral domain: Try out wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_log(time, Fs, sig):\n",
    "    '''\n",
    "    Morlet Wavelet and returns\n",
    "    logged values\n",
    "    Input:\n",
    "        - time: array with timesamples\n",
    "        - Fs: sample freq\n",
    "        - sig: 1d array of time series of interest\n",
    "    Returns:\n",
    "        - time: unchanged time\n",
    "        - freqs: arr of freq bins\n",
    "        - logpsd: calculated log-psd\n",
    "    '''\n",
    "    assert len(time) == len(sig), print(\n",
    "        '\\nERROR: Length of time and signal-array'\n",
    "        ' for wavelet do not match\\n###'\n",
    "    )\n",
    "    w = 8  # define number of depth/spaces\n",
    "    freqs = np.linspace(1, Fs / 2, 100)\n",
    "    widts = (Fs * w) / (2 * freqs * np.pi)\n",
    "    coefs = signal.cwt(  # wavelet coeff's\n",
    "        sig, signal.morlet2, widths=widts,\n",
    "        w=w, dtype='complex128')\n",
    "    psd = np.abs(coefs)\n",
    "    logpsd = np.log10(psd)\n",
    "\n",
    "    return time, freqs, logpsd\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ecog_dysk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
