{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Development Extraction: Neurophysiology [dyskinesia project]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b> Content </b>\n",
    "\n",
    "\n",
    "<b> Aperiodic estimates </b>\n",
    "Relevant literature:\n",
    "- Periodic and a-periodic components relevance and interaction, different reasons (per + a-per) for signal changes observed within a specific bandwidth. Aperiodic component (complicated) vs exponent (1/f) (Donoghue, ..., Shestyuk & Voytek, Nature Neurosc 2020 : https://www.nature.com/articles/s41593-020-00744-x)\n",
    "- cycle-by-cycle features: bycycle toolbox (Cole & Voytek, J of Neurophys 2019, https://journals.physiology.org/doi/full/10.1152/jn.00273.2019)\n",
    "- aperiodic component, PD severity, and cortico-subcortico-activity, Bush & Zou, Richardson, bioRxiv 2023 https://www.biorxiv.org/content/10.1101/2023.02.08.527719v1?rss=1\n",
    "\n",
    "<b> Periodic component analysis: </b> \n",
    "- Try Wavelet Dceomposition vs Welch (tapered) Spectral Decomposition\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from scipy.stats import pearsonr, mannwhitneyu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib import __version__ as plt_version\n",
    "from scipy import signal, stats\n",
    "# from array import array\n",
    "# import datetime as dt\n",
    "# #mne\n",
    "# import mne_bids\n",
    "# import mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.0 (default, Nov 15 2020, 08:30:55) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 1.4.4\n",
      "numpy 1.23.3\n",
      "sci-kit learn 1.1.3\n",
      "matplotlib 3.5.3\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "# print('mne', mne.__version__)\n",
    "# print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)\n",
    "print('matplotlib', plt_version)\n",
    "## FEB 2022:\n",
    "# Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
    "# [Clang 10.0.0 ]\n",
    "# pandas 1.3.4\n",
    "# numpy 1.20.3\n",
    "# mne_bids 0.9\n",
    "# mne 0.24.1\n",
    "# sci-py 1.7.1\n",
    "# sci-kit learn 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_features.feats_spectral_baseline as specBase\n",
    "import lfpecog_features.feats_spectral_features as spectral\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "import lfpecog_features.feats_helper_funcs as ftHelp\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "# import lfpecog_analysis.get_acc_derivs as accDerivs\n",
    "\n",
    "\n",
    "import lfpecog_plotting.plotHelpers as plotHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(plotHelp.get_colors().values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and Plot CDRS scores from both raters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traces\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores_bilat = []\n",
    "max_scores_ecoglat = []\n",
    "rater='Patricia'\n",
    "\n",
    "for s in ['008', '009', '010', '012',\n",
    "             '013', '014', '016', '017']:\n",
    "\n",
    "    t, scores = importClin.get_cdrs_specific(\n",
    "        sub=s, rater=rater, side='both')\n",
    "    max_scores_bilat.append(np.nanmax(scores))\n",
    "\n",
    "    t, scores = importClin.get_cdrs_specific(\n",
    "        sub=s, rater=rater, side='contra ecog')\n",
    "    max_scores_ecoglat.append(np.nanmax(scores))\n",
    "\n",
    "print('BILATERAL', max_scores_bilat, np.mean(max_scores_bilat))\n",
    "print('ECoG lat.', max_scores_ecoglat, np.mean(max_scores_ecoglat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(importClin)\n",
    "# CHECK CLINICAL RATINGS\n",
    "subs_incl = ['008', '009', '010', '012',\n",
    "             '013', '014', '016']\n",
    "\n",
    "clrs = colors\n",
    "styles = ['solid', 'dotted']\n",
    "fig, axes = plt.subplots(1,1, figsize=(12, 6))\n",
    "\n",
    "for i_sub, sub in enumerate(subs_incl):\n",
    "    reg_t, reg_scores = {}, {}\n",
    "    for i_r, rater in enumerate(['Patricia', 'Jeroen']):\n",
    "        t, scores = importClin.get_cdrs_specific(sub=sub, rater=rater)\n",
    "        axes.plot(t, scores,  # [0]\n",
    "                color=clrs[i_sub], ls=styles[i_r], lw=3, label=f'{sub} ({rater})')\n",
    "\n",
    "        # regularize scores\n",
    "        reg_t[i_r], reg_scores[i_r] = importClin.get_cdrs_specific(\n",
    "            sub=sub, rater=rater, regularize=True,)\n",
    "        # axes[1].plot(reg_t[i_r], reg_scores[i_r],\n",
    "        #         color=clrs[i_sub], ls=styles[i_r], lw=3, )\n",
    "    \n",
    "    # calculate correlations\n",
    "    # only take minutes present in both scores\n",
    "    t_start = max([reg_t[i_r][0] for i_r in [0, 1]])\n",
    "    t_stop = min([reg_t[i_r][-1] for i_r in [0, 1]])\n",
    "    sel0 = [time >= t_start and time <= t_stop for time in reg_t[0]]\n",
    "    sel1 = [time >= t_start and time <= t_stop for time in reg_t[1]]\n",
    "    \n",
    "    print(sub, pearsonr(reg_scores[0][sel0], reg_scores[1][sel1]))\n",
    "\n",
    "# axes[0].set_title('Inserted scores per timepoint', size=14)\n",
    "# axes[1].set_title('Interpolated scores (per 1 minute)', size=14)\n",
    "handles, labels = axes.get_legend_handles_labels()\n",
    "plt.legend(handles, labels, ncol=5, bbox_to_anchor=(.5, -.25),\n",
    "               loc='upper center', fontsize=14,)\n",
    "# for ax in axes:\n",
    "axes.set_ylabel('CDRS score', fontsize=14)\n",
    "axes.set_xlabel('Time (minutes vs LDOPA-intake)', fontsize=14)\n",
    "axes.tick_params(axis='both', labelsize=14, size=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "# figname = 'CDRS_scores_2rater_interpolation'\n",
    "# plt.savefig(os.path.join(figpath, 'clinical_scores', figname), dpi=150,\n",
    "#             facecolor='w',)\n",
    "# figname = 'CDRS_scores_2raters'\n",
    "# plt.savefig(os.path.join(figpath, 'clinical_scores', figname), dpi=150,\n",
    "#             facecolor='w',)\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load preprocessed and merged Sub-Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ACC pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_to_plot = [\n",
    "    '008', \n",
    "    # '009', '010', '012', \n",
    "    # '013', '014', '016'\n",
    "]\n",
    "\n",
    "data_version = 'v4.0'\n",
    "mins_recording = []\n",
    "\n",
    "for sub in subs_to_plot:\n",
    "    # load Acc-detected movement labels\n",
    "    acc = load_class_pickle(os.path.join(\n",
    "        get_project_path('data'),\n",
    "        'merged_sub_data', data_version, f'sub-{sub}',\n",
    "        f'{sub}_mergedData_{data_version}_accLeft.P'\n",
    "    ))\n",
    "    # acc = correct_acc_class(acc)\n",
    "\n",
    "    # mins_recording.append(acc.data.shape[0] / acc.fs / 60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ephys pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WINDOWED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_to_plot = [\n",
    "    # '008', '009', '010', '012', \n",
    "    # '013', '014',\n",
    "    '012',\n",
    "]\n",
    "task = 'rest'\n",
    "data_version = 'v3.0'\n",
    "mins_recording = []\n",
    "\n",
    "# for sub in subs_to_plot:\n",
    "#     # load Acc-detected movement labels\n",
    "#     data = load_class_pickle(os.path.join(\n",
    "#         get_project_path('data'), 'windowed_data_classes_60s',\n",
    "#         data_version, f'sub-{sub}', task,\n",
    "#         f'{sub}_mneEpochs_{task}_{data_version}_win60s_overlap0.5.P'\n",
    "#     ))\n",
    "#     # acc = correct_acc_class(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.list_mne_objects[0].times.shape\n",
    "\n",
    "data.list_mne_objects[0].ch_names\n",
    "\n",
    "data.list_mne_objects[0].get_data().shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGED DATA per DATATYPE (source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_incl = [\n",
    "    '013', \n",
    "    # '009', '010', '012', \n",
    "    # '013', '014',\n",
    "    # '012',\n",
    "]\n",
    "# task = 'rest'\n",
    "data_version = 'v3.0'\n",
    "\n",
    "# for sub in subs_incl:\n",
    "#     # load merged data class\n",
    "#     data = load_class_pickle(os.path.join(\n",
    "#         get_project_path('data'), 'merged_sub_data',\n",
    "#         data_version,\n",
    "#         f'{sub}_mergedDataClass_{data_version}.P'\n",
    "#     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '012'\n",
    "dat = {}\n",
    "dType = 'lfp_left'\n",
    "dat[dType] = load_class_pickle(os.path.join(\n",
    "        get_project_path('data'), 'merged_sub_data',\n",
    "        data_version, f'sub-{sub}',\n",
    "        f'{sub}_mergedData_{data_version}_{dType}.P'\n",
    "    ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_sources = ['lfp_left', ]  #'lfp_right', 'ecog_left', 'ecog_right']\n",
    "use_stored_windows = True\n",
    "\n",
    "sub = '019'\n",
    "json_path = os.path.join(utilsFiles.get_onedrive_path('data'),\n",
    "                     'featureExtraction_jsons',\n",
    "                     'ftExtr_spectral_v4.json')\n",
    "with open(json_path, 'r') as json_data:\n",
    "    SETTINGS = json.load(json_data)\n",
    "\n",
    "windows_path = os.path.join(utilsFiles.get_project_path('data'),\n",
    "                    'windowed_data_classes_'\n",
    "                    f'{SETTINGS[\"WIN_LEN_sec\"]}s_'\n",
    "                    f'{SETTINGS[\"WIN_OVERLAP_part\"]}overlap',\n",
    "                    SETTINGS['DATA_VERSION'],\n",
    "                    f'sub-{sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dType in ephys_sources:\n",
    "    print(f'\\tstart {dType}')\n",
    "    # define path for windows of dType\n",
    "    dType_fname = (f'sub-{sub}_windows_'\n",
    "                    f'{SETTINGS[\"WIN_LEN_sec\"]}s_'\n",
    "                    f'{SETTINGS[\"DATA_VERSION\"]}_{dType}.P')\n",
    "    dType_win_path = os.path.join(windows_path, dType_fname)\n",
    "    \n",
    "    # check if windows are already available\n",
    "    if np.logical_and(use_stored_windows,\n",
    "                        os.path.exists(dType_win_path)):\n",
    "        print(f'load data from {windows_path}....')\n",
    "        windows = utilsFiles.load_class_pickle(dType_win_path)\n",
    "        print(f'\\tWINDOWS LOADED from {dType_fname} in {windows_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(windows.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ssd'd Spectral Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.get_ssd_data as ssd\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_analysis.get_SSD_timefreqs as ssd_TimeFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avail_ssd_subs(\n",
    "    DATA_VERSION, IGNORE_PTS=[],\n",
    "    INCL_STN_ONLY_PTS=True,\n",
    "    WIN_LEN=10, WIN_OVERLAP=.5,\n",
    "    SSD_BROAD=True, \n",
    "):\n",
    "# get all available subs with features\n",
    "\n",
    "    ssd_folder = 'SSD_feats'\n",
    "    if SSD_BROAD: ssd_folder += '_broad'\n",
    "    ssd_path = os.path.join(get_project_path('results'), 'features',\n",
    "                            ssd_folder, DATA_VERSION,\n",
    "                            f'windows_{WIN_LEN}s_'\n",
    "                            f'{WIN_OVERLAP}overlap')\n",
    "    SUBS = list(set([name.split('_')[1]\n",
    "                    for name in os.listdir(ssd_path)]))\n",
    "\n",
    "    # remove ignore patients and e.g. STN onlys\n",
    "    remove_subs = []\n",
    "    if not INCL_STN_ONLY_PTS:\n",
    "        for sub in SUBS:\n",
    "            if sub.startswith('1'): remove_subs.append(sub)\n",
    "\n",
    "    for sub in IGNORE_PTS + remove_subs:\n",
    "        if sub in SUBS: SUBS.remove(sub)\n",
    "\n",
    "    return SUBS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SSD construction overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT VISUAL SSD OVERVIEW\n",
    "\n",
    "# # loop over defined frequency bands\n",
    "# for bw in SETTINGS['SPECTRAL_BANDS']:\n",
    "#     f_range = SETTINGS['SPECTRAL_BANDS'][bw]\n",
    "    # check whether to perform SSD\n",
    "    # (ssd_filt_data,\n",
    "    #     ssd_pattern,\n",
    "    #     ssd_eigvals\n",
    "    # ) = ssd.get_SSD_component(\n",
    "    #     data_2d=win_dat.T,\n",
    "    #     fband_interest=f_range,\n",
    "    #     s_rate=windows.fs,\n",
    "    #     use_freqBand_filtered=True,\n",
    "    #     return_comp_n=0,\n",
    "    # )\n",
    "\n",
    "#     f, psd = signal.welch(ssd_filt_data, axis=-1,\n",
    "#                     nperseg=windows.fs, fs=windows.fs)\n",
    "#     plt.plot(f, psd, label=bw)\n",
    "\n",
    "        \n",
    "\n",
    "# plt.xlim(0, 100)\n",
    "# plt.title(f'WINDOW # {i_w} - {dType.upper()}')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "new_subs = ['107', '020', '108', '109', '017', '019', '021', '105',]\n",
    "print(len(new_subs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSD time freq plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get windowed bands of different dtypes per sub\n",
    "importlib.reload(ftHelp)\n",
    "importlib.reload(ssd)\n",
    "importlib.reload(ssd_TimeFreq)\n",
    "\n",
    "sub = '016'\n",
    "\n",
    "# call from feats_extract_multivar.py\n",
    "ssd_subClass = ssd.get_subject_SSDs(\n",
    "    sub=sub,\n",
    "    incl_stn=True,\n",
    "    incl_ecog=True,\n",
    "    ft_setting_fname='ftExtr_spectral_v4.json',)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeFreq_xticks(x_times):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - xticks given in seconds\n",
    "    \n",
    "    Returns:\n",
    "        - xticks\n",
    "        - xticklabels (in minutes)\n",
    "    \"\"\"\n",
    "    # define first and last tick rounded on 10 minutes\n",
    "    first_xtick = np.ceil((x_times / 60 / 10)[0]) * 10\n",
    "    last_xtick = np.floor((x_times / 60 / 10)[-1]) * 10\n",
    "    # get ticklabels in 10 minute spacing\n",
    "    xticklabels = np.arange(first_xtick, last_xtick+1, 10).astype(int)\n",
    "    # find nearest indices in x_times for created labels\n",
    "    xticks = np.array([np.argmin(abs(x_times/60 - t)) for t in xticklabels])\n",
    "    # drop ticks and labels if they are too close (visually overwrite each other)\n",
    "    drop_close_ticks = np.append(np.array([False]), np.diff(xticks) < 150)\n",
    "    # drop too close ticks, labels\n",
    "    xticklabels = xticklabels[~drop_close_ticks]\n",
    "    xticks = xticks[~drop_close_ticks]\n",
    "\n",
    "    return xticks, xticklabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_timeFreqs_ssd_psds as plot_ssd_TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LEN=10\n",
    "WIN_OVERLAP=0.5\n",
    "DATA_VERSION='v4.0'\n",
    "FT_VERSION='v4'\n",
    "SSD_BROAD=True\n",
    "INCL_STN_ONLY_PTS=True\n",
    "IGNORE_PTS=['011',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ftProc)\n",
    "importlib.reload(importClin)\n",
    "importlib.reload(ssd_TimeFreq)\n",
    "importlib.reload(plot_ssd_TFs)\n",
    "\n",
    "# CONVERT ONLY STNS!!!!!\n",
    "SUBS = get_avail_ssd_subs(DATA_VERSION=DATA_VERSION)\n",
    "print(SUBS)\n",
    "\n",
    "for sub in SUBS:\n",
    "    # if sub not in new_subs: continue\n",
    "    # if sub in ['017', '019']: continue\n",
    "    try:\n",
    "        print(f'PLOT SUB-{sub}')\n",
    "        plot_ssd_TFs.plot_indiv_ssd_timefreq_allSources(sub,\n",
    "                                                        SAVE_PLOT=True)\n",
    "    except:\n",
    "        print(f'sub {sub} error')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSD PSD plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_descriptive_SSD_PSDs as plot_PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LEN=10\n",
    "WIN_OVERLAP=0.5\n",
    "DATA_VERSION='v4.0'\n",
    "FT_VERSION='v4'\n",
    "SSD_BROAD=True\n",
    "INCL_STN_ONLY_PTS=True\n",
    "IGNORE_PTS=['011', '017', '106']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['108', '008', '020', '017', '105', '107', '109', '014', '013', '103', '019', '102', '010', '016', '101', '012', '021', '009']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "SUBS = get_avail_ssd_subs(DATA_VERSION=DATA_VERSION)\n",
    "print(SUBS)\n",
    "print(len(SUBS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load existing powers for sub-108 (SSD_PSD_108.json)\n",
      "...loaded subject-108 Time-Frequency data\n",
      "load existing powers for sub-008 (SSD_PSD_008.json)\n",
      "...loaded subject-008 Time-Frequency data\n",
      "load existing powers for sub-020 (SSD_PSD_020.json)\n",
      "...loaded subject-020 Time-Frequency data\n",
      "load existing powers for sub-017 (SSD_PSD_017.json)\n",
      "...loaded subject-017 Time-Frequency data\n",
      "load existing powers for sub-105 (SSD_PSD_105.json)\n",
      "...loaded subject-105 Time-Frequency data\n",
      "load existing powers for sub-107 (SSD_PSD_107.json)\n",
      "...loaded subject-107 Time-Frequency data\n",
      "load existing powers for sub-109 (SSD_PSD_109.json)\n",
      "...loaded subject-109 Time-Frequency data\n",
      "load existing powers for sub-014 (SSD_PSD_014.json)\n",
      "...loaded subject-014 Time-Frequency data\n",
      "load existing powers for sub-013 (SSD_PSD_013.json)\n",
      "...loaded subject-013 Time-Frequency data\n",
      "load existing powers for sub-103 (SSD_PSD_103.json)\n",
      "...loaded subject-103 Time-Frequency data\n",
      "load existing powers for sub-019 (SSD_PSD_019.json)\n",
      "...loaded subject-019 Time-Frequency data\n",
      "load existing powers for sub-102 (SSD_PSD_102.json)\n",
      "...loaded subject-102 Time-Frequency data\n",
      "load existing powers for sub-010 (SSD_PSD_010.json)\n",
      "...loaded subject-010 Time-Frequency data\n",
      "load existing powers for sub-016 (SSD_PSD_016.json)\n",
      "...loaded subject-016 Time-Frequency data\n",
      "load existing powers for sub-101 (SSD_PSD_101.json)\n",
      "...loaded subject-101 Time-Frequency data\n",
      "load existing powers for sub-012 (SSD_PSD_012.json)\n",
      "...loaded subject-012 Time-Frequency data\n",
      "load existing powers for sub-021 (SSD_PSD_021.json)\n",
      "...loaded subject-021 Time-Frequency data\n",
      "load existing powers for sub-009 (SSD_PSD_009.json)\n",
      "...loaded subject-009 Time-Frequency data\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ssd_TimeFreq)\n",
    "\n",
    "\n",
    "TFs = ssd_TimeFreq.get_all_ssd_timeFreqs(SUBS=SUBS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '016' : check why short peak of CDRS 3 at beginning of LID?\n",
    "# check new SSD PSDs for 017 and 019\n",
    "# noisy data 106"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Group Results: Spectral changes over Time after L-Dopa, non-LID versus LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check sub-108\n",
      "sub-108 not included, no CDRS scores\n",
      "check sub-008\n",
      "check sub-020\n",
      "check sub-017\n",
      "skip sub-017\n",
      "check sub-105\n",
      "sub-105 not included, no CDRS scores\n",
      "check sub-107\n",
      "sub-107 not included, no CDRS scores\n",
      "check sub-109\n",
      "check sub-014\n",
      "check sub-013\n",
      "check sub-103\n",
      "check sub-019\n",
      "check sub-102\n",
      "check sub-010\n",
      "check sub-016\n",
      "check sub-101\n",
      "check sub-012\n",
      "check sub-021\n",
      "check sub-009\n"
     ]
    }
   ],
   "source": [
    "# make groups with and without occurence of LID\n",
    "subs_LID = []\n",
    "subs_noLID = []\n",
    "\n",
    "for sub in SUBS:\n",
    "    print(f'check sub-{sub}')\n",
    "    if sub in IGNORE_PTS:\n",
    "        \n",
    "        print(f'skip sub-{sub}')\n",
    "        continue\n",
    "    try:\n",
    "        max_score = max(ftProc.get_cdrs_specific(sub=sub,\n",
    "                                                rater='Jeroen',\n",
    "                                                side='both')[1])\n",
    "        if max_score > 0: subs_LID.append(sub)\n",
    "        else: subs_noLID.append(sub)\n",
    "    except ValueError:\n",
    "        print(f'sub-{sub} not included, no CDRS scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['109', '101']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs_noLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "# PM, needs: TFs = ssd_TimeFreq.get_all_ssd_timeFreqs(SUBS=SUBS)\n",
    "\n",
    "SAVE=True\n",
    "SHOW=False\n",
    "\n",
    "STN_or_ECOG='STN'\n",
    "ZSCORE_FREQS=False\n",
    "SMOOTH_FREQS=8\n",
    "LOG_POWER=False\n",
    "BASELINE_CORRECT=True\n",
    "\n",
    "n_subs_incl = len(subs_LID) + len(subs_noLID)\n",
    "\n",
    "fig_name = f'1408_{STN_or_ECOG}_PSDs_noLID_LID_vs_DopaTime_n{n_subs_incl}'\n",
    "if BASELINE_CORRECT: fig_name += '_blCorrPrc'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_PSD_vs_DopaTime(TFs['008']['lfp_left'])\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fsize=20\n",
    "\n",
    "# if None returned, dont use axes[0] to collect returned output\n",
    "if STN_or_ECOG == 'STN': ax_title = 'Bilateral STNs w/o Dyskinesia'\n",
    "elif STN_or_ECOG == 'ECOG': ax_title = 'ECoG w/o Dyskinesia'\n",
    "axes[0] = plot_PSDs.plot_PSD_vs_DopaTime(\n",
    "    TFs, sel_subs=subs_noLID,\n",
    "    STN_or_ECOG=STN_or_ECOG,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    plt_ax_to_return=axes[0], fsize=fsize, BREAK_X_AX=True,\n",
    "    ax_title=ax_title\n",
    ")\n",
    "\n",
    "\n",
    "if STN_or_ECOG == 'STN': ax_title = 'Bilateral STNs with Dyskinesia'\n",
    "elif STN_or_ECOG == 'ECOG': ax_title = 'ECoG with Dyskinesia'\n",
    "axes[1] = plot_PSDs.plot_PSD_vs_DopaTime(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    STN_or_ECOG=STN_or_ECOG,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    plt_ax_to_return=axes[1], fsize=fsize, BREAK_X_AX=True,\n",
    "    ax_title=ax_title\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# equalize axes\n",
    "ymin = min([min(ax.get_ylim()) for ax in axes])\n",
    "ymax = max([max(ax.get_ylim()) for ax in axes])\n",
    "for ax in axes: ax.set_ylim(ymin, ymax)\n",
    "\n",
    "for ax in axes: ax.tick_params(axis='both', size=fsize,\n",
    "                               labelsize=fsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "if SAVE:\n",
    "    plt.savefig(os.path.join(get_project_path('figures'), 'ft_exploration',\n",
    "                         DATA_VERSION, 'descr_PSDs', fig_name),\n",
    "                facecolor='w', dpi=300,)\n",
    "if SHOW: plt.show()\n",
    "else: plt.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot LID-Group Results: Laterality of LID in STN and ECoG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SEVERITY AND LATERALITY OF STN-changes during DYSKINESIA\n",
    "\n",
    "- LAT_UNI: plot laterality of unilateral LID\n",
    "- LAT_BILAT: plot laterality of only bilateral LID\n",
    "- SCALE: combine all uni- and bilateral LID\n",
    "    - PLOT_ONLY_MATCH == True: plot only STN contralateral to LID\n",
    "    - PLOT_ONLY_MATCH == False: plot contra-, ipsi-, and bi-lateral STN-LID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start plotting 2208_STN_PSDs_SCALE_LID_n12_blCorr_smooth8_SIGN_onlyMatch\n",
      "load significancies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_plotting\\plot_descriptive_SSD_PSDs.py:771: RuntimeWarning: Mean of empty slice\n",
      "  PSD[k] = [np.nanmean(PSD[k][np.logical_and(idx > (i_v - s_win),\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "# PM, needs: TFs = ssd_TimeFreq.get_all_ssd_timeFreqs(SUBS=SUBS)\n",
    "\n",
    "# 'LAT_UNI' , 'LAT_BILAT', 'SCALE', 'LAT_ALL_SCALE'\n",
    "LAT_or_SCALE = 'SCALE'\n",
    "\n",
    "SMOOTH_FREQS=8\n",
    "LOG_POWER=False\n",
    "BASELINE_CORRECT=True\n",
    "ZSCORE_FREQS=False\n",
    "SHOW_GAMMA = False\n",
    "SHOW_SIGN = True\n",
    "PLOT_ONLY_MATCH = True\n",
    "\n",
    "fig_name = f'2208_STN_PSDs_{LAT_or_SCALE}_LID_n{len(subs_LID)}'\n",
    "\n",
    "if BASELINE_CORRECT: fig_name += '_blCorr'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "# if SINGLE_LINE: fig_name += '_lines'\n",
    "if SHOW_GAMMA: fig_name += '_GAMMA'\n",
    "if SHOW_SIGN: fig_name += '_SIGN'\n",
    "if PLOT_ONLY_MATCH: fig_name += '_onlyMatch'\n",
    "\n",
    "fsize=14\n",
    "\n",
    "stn_stats = plot_PSDs.plot_STN_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    CDRS_RATER='Jeroen',\n",
    "    LAT_or_SCALE=LAT_or_SCALE,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    plt_ax_to_return=False,\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    "    fig_name=fig_name,\n",
    "    CALC_FREQ_CORR=False,\n",
    "    SHOW_ONLY_GAMMA=SHOW_GAMMA,\n",
    "    SHOW_SIGN=SHOW_SIGN,\n",
    "    PROCESS_STATS=False,\n",
    "    PLOT_ONLY_MATCH=PLOT_ONLY_MATCH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.psd_lid_stats as psdLID_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_path = os.path.join(get_project_path('results'), 'stats', 'STN_LMM_noLID_vs_LID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(psdLID_stats)\n",
    "\n",
    "\n",
    "plist = psdLID_stats.get_binary_p_perHz(return_ps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot SEVERITY AND LATERALITY OF ECoG-changes during DYSKINESIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...ADD match to PLOTONLYMATCH POWERS\n",
      "...SKIP nonmatch from PLOTONLYMATCH POWERS\n",
      "...ADD bi to PLOTONLYMATCH POWERS\n",
      "dict_keys(['all_match'])\n",
      "dict_keys(['all_match'])\n",
      "load significancies\n",
      "all_match\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_plotting\\plot_descriptive_SSD_PSDs.py:781: RuntimeWarning: Mean of empty slice\n",
      "  PSD[k] = [np.nanmean(PSD[k][np.logical_and(idx > (i_v - s_win),\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(psdLID_stats)\n",
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "# PM, needs: TFs = ssd_TimeFreq.get_all_ssd_timeFreqs(SUBS=SUBS)\n",
    "\n",
    "# 'LAT_UNI' , 'LAT_BILAT', 'SCALE', 'LAT_ALL_SCALE'\n",
    "LAT_or_SCALE = 'SCALE'\n",
    "SAVE_PLOT = True\n",
    "SHOW_PLOT = False\n",
    "\n",
    "SMOOTH_FREQS = 8\n",
    "LOG_POWER = False\n",
    "BASELINE_CORRECT = True\n",
    "ZSCORE_FREQS = False\n",
    "SINGLE_LINE = False\n",
    "SHOW_GAMMA = False\n",
    "PLOT_ONLY_MATCH = True\n",
    "SHOW_SIGN = True\n",
    "\n",
    "fig_name = f'2208_ECoG_PSDs_LID_{LAT_or_SCALE}_n{len(subs_LID)}'\n",
    "\n",
    "if BASELINE_CORRECT: fig_name += '_blCorr'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "if SINGLE_LINE: fig_name += '_lines'\n",
    "if SHOW_GAMMA: fig_name += '_GAMMA'\n",
    "if SHOW_SIGN: fig_name += '_SIGN'\n",
    "if PLOT_ONLY_MATCH: fig_name += '_onlyMatch'\n",
    "\n",
    "fsize=14\n",
    "\n",
    "plot_PSDs.plot_ECOG_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    LAT_or_SCALE=LAT_or_SCALE,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    plt_ax_to_return=False,\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    "    fig_name=fig_name,\n",
    "    single_sub_lines=SINGLE_LINE,\n",
    "    PLOT_ONLY_MATCH=PLOT_ONLY_MATCH,\n",
    "    SHOW_ONLY_GAMMA=SHOW_GAMMA,\n",
    "    SHOW_SIGN=SHOW_SIGN,\n",
    "    PROCESS_STATS=False,\n",
    "    p_SAVED_DATE='2208',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot LATERALITY during UNILATERAL dyskinesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "\n",
    "SAVE_PLOT = True\n",
    "SHOW_PLOT = False\n",
    "\n",
    "SMOOTH_FREQS=8\n",
    "LOG_POWER=False\n",
    "BASELINE_CORRECT=True\n",
    "ZSCORE_FREQS=False\n",
    "CDRS_RATER = 'Jeroen'\n",
    "\n",
    "fig_name = f'LATERALITY_STNandECOG_PSDs_unilatLID_n{len(SUBS)}'\n",
    "if BASELINE_CORRECT: fig_name += '_blCorr'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "fsize=14\n",
    "\n",
    "plot_PSDs.plot_STN_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    LAT_or_SCALE='LAT_UNI',  # LAT_UNI\n",
    "    CDRS_RATER=CDRS_RATER,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    plt_ax_to_return=axes[0],\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    ")\n",
    "plot_PSDs.plot_ECOG_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    LAT_or_SCALE='LAT_UNI',\n",
    "    CDRS_RATER=CDRS_RATER,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    plt_ax_to_return=axes[1],\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    ")\n",
    "\n",
    "# equalize axes\n",
    "ymin = min([min(ax.get_ylim()) for ax in axes])\n",
    "ymax = max([max(ax.get_ylim()) for ax in axes])\n",
    "for ax in axes: ax.set_ylim(ymin, ymax)\n",
    "\n",
    "for ax in axes: ax.tick_params(axis='both', size=fsize,\n",
    "                               labelsize=fsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "if SAVE_PLOT:\n",
    "    plt.savefig(os.path.join(get_project_path('figures'), 'ft_exploration',\n",
    "                         DATA_VERSION, 'descr_PSDs', fig_name),\n",
    "                facecolor='w', dpi=300,)\n",
    "if SHOW_PLOT: plt.show()\n",
    "else: plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot PSDs versus categorical CDRS severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STN SCALING shows only-contra; only-ipsilateral; merged-bilateral\n",
    "\"\"\"\n",
    "\n",
    "# importlib.reload(ftProc)\n",
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "fig_name = f'1408_STN_PSD_CDRS_scaling_n{len(subs_LID + subs_noLID)}'\n",
    "\n",
    "SAVE_PLOT = True\n",
    "SHOW_PLOT = False\n",
    "\n",
    "SMOOTH_FREQS=8\n",
    "LOG_POWER=False\n",
    "BASELINE_CORRECT=True\n",
    "ZSCORE_FREQS=False\n",
    "fsize=14\n",
    "\n",
    "if BASELINE_CORRECT: fig_name += '_blCorr'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "\n",
    "# plot internally due to difficulties of returning multiple axes\n",
    "plot_PSDs.plot_STN_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    LAT_or_SCALE='SCALE',\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    # plt_ax_to_return=axes,\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    "    fig_name=fig_name,\n",
    "    SINGLE_SUB_LINES=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ECoG SCALE shows unilateral scaling and merged-bilateral scaling\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# importlib.reload(ftProc)\n",
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "\n",
    "SAVE_PLOT = True\n",
    "SHOW_PLOT = False\n",
    "\n",
    "SMOOTH_FREQS=8\n",
    "LOG_POWER=False\n",
    "BASELINE_CORRECT=True\n",
    "ZSCORE_FREQS=False\n",
    "fsize=14\n",
    "fig_name = f'1408_ECOG_PSD_CDRS_scaling_n{len(subs_LID + subs_noLID)}'\n",
    "\n",
    "if BASELINE_CORRECT: fig_name += '_blCorr'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "\n",
    "# plot internally due to difficulties of returning multiple axes\n",
    "plot_PSDs.plot_ECOG_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    LAT_or_SCALE='SCALE',\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    # plt_ax_to_return=axes,\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    "    fig_name=fig_name,\n",
    "    # SINGLE_SUB_LINES=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Frequency-Correlation Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_PSDs)\n",
    "\n",
    "# PM, needs: TFs = ssd_TimeFreq.get_all_ssd_timeFreqs(SUBS=SUBS)\n",
    "# TODO: PLOT FREQ-CORR FOR OTHER DATA\n",
    "\n",
    "LAT_or_SCALE = 'LAT_BILAT'\n",
    "CALC_FREQ_CORR = True\n",
    "\n",
    "SMOOTH_FREQS=8\n",
    "LOG_POWER=False\n",
    "BASELINE_CORRECT=True\n",
    "ZSCORE_FREQS=False\n",
    "\n",
    "fig_name = f'1508_FREQCORR_STN_PSDs_{LAT_or_SCALE}_LID_n{len(SUBS)}'\n",
    "\n",
    "if BASELINE_CORRECT: fig_name += '_blCorr'\n",
    "if LOG_POWER: fig_name += '_log'\n",
    "if ZSCORE_FREQS: fig_name += '_Z'\n",
    "if SMOOTH_FREQS > 0: fig_name += f'_smooth{SMOOTH_FREQS}'\n",
    "\n",
    "fsize=14\n",
    "\n",
    "FrqCor = plot_PSDs.plot_STN_PSD_vs_LID(\n",
    "    TFs, sel_subs=subs_LID,\n",
    "    LAT_or_SCALE=LAT_or_SCALE,\n",
    "    LOG_POWER=LOG_POWER,\n",
    "    BASELINE_CORRECT=BASELINE_CORRECT,\n",
    "    SMOOTH_PLOT_FREQS=SMOOTH_FREQS,\n",
    "    ZSCORE_FREQS=ZSCORE_FREQS,\n",
    "    plt_ax_to_return=False,\n",
    "    fsize=fsize,\n",
    "    BREAK_X_AX=True,\n",
    "    fig_name=fig_name,\n",
    "    CALC_FREQ_CORR=CALC_FREQ_CORR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_FreqCorr as plt_FreqCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plt_FreqCorr)\n",
    "\n",
    "# calculate Rs\n",
    "FreqCorrs_results, freqs = plt_FreqCorr.calculate_Rs_FreqCorr(\n",
    "    FreqCorr_dict=FrqCor, mean_per_score=True,)\n",
    "\n",
    "# Plot mean Rs per state\n",
    "plt_FreqCorr.plot_FreqCorr(\n",
    "    FreqCorrs_results, freqs,\n",
    "    save_dir=os.path.join(get_project_path('figures'),\n",
    "                          'ft_exploration',\n",
    "                          DATA_VERSION,\n",
    "                          'FreqCorrPlots'),\n",
    "    fig_name='FreqCorr_STN_bilat_CDRS_meanSubScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check SSD extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicate SSD extraction\n",
    "\n",
    "importlib.reload(ssd)\n",
    "# loop over windows\n",
    "\n",
    "for i_w, win_dat in enumerate(windows.data[:5]):\n",
    "    win_dat = win_dat.astype(np.float64)    \n",
    "    # select only rows without missing\n",
    "    nan_rows = np.array([pd.isna(win_dat[:, i]).any()\n",
    "                for i in range(win_dat.shape[-1])])\n",
    "    win_dat = win_dat[:, ~nan_rows]\n",
    "    win_chnames = list(compress(windows.keys, ~nan_rows))\n",
    "    win_time = windows.win_starttimes[i_w]\n",
    "    \n",
    "    ssds = ssd.SSD_bands_per_window(\n",
    "        data=win_dat.T, s_rate=windows.fs,\n",
    "        freq_bands_incl=SETTINGS['SPECTRAL_BANDS'],\n",
    "    )\n",
    " \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase features to add:\n",
    "- local PAC from De Hempt (ECoG) (beta-phase, gamma-ampl)\n",
    "    - EEGLAB ASYMM PAC\n",
    "    - check calculation via entropy of amplitudes per bin\n",
    "    - or MI-inde\n",
    "- phase-phase: CHECK CAGNAN BURST WORK\n",
    "    - connectivity phase differences from Swann et al (phase-coherence) (angle STN versus angle ECoG, compare with imaginary-coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.phase_plotting as phaseplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(phaseplot)\n",
    "\n",
    "### phase difference\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# get both signals\n",
    "sig1 = ssds.lo_beta.copy()\n",
    "sig2 = ssd0.lo_beta.copy()\n",
    "# convert to analytic signal\n",
    "a1 = signal.hilbert(x=sig1,)\n",
    "a2 = signal.hilbert(x=sig2,)\n",
    "# get phase from analytical signal, convert from pi to degree\n",
    "rad1 = np.angle(a1)\n",
    "deg1 = np.rad2deg(rad1)\n",
    "rad2 = np.angle(a2)\n",
    "deg2 = np.rad2deg(rad2)\n",
    "# get difference, convert all to positive degrees (-90 -> +270)\n",
    "rad_diff = rad1 - rad2\n",
    "deg_diff = deg1 - deg2\n",
    "mask_deg = deg_diff < 0  # bool-array, 0 for values >= 0\n",
    "mask_rad = rad_diff < 0\n",
    "corr_rad = np.array([2 * np.pi] * len(rad_diff)) * mask_rad  # corr array is set 0 for pos diff-values\n",
    "rad_diff += corr_rad\n",
    "corr_deg = np.array([360] * len(deg_diff)) * mask_deg  # corr array is set 0 for pos diff-values\n",
    "deg_diff += corr_deg\n",
    "plt.plot(rad_diff, label='corr', alpha=.8, ls='dotted')\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(sig1)\n",
    "plt.plot(sig2)\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()\n",
    "\n",
    "phaseplot.plot_rose_axis(radians=rad_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_phase = ssd_014.ecog_right.lo_beta[10].copy()\n",
    "sig_ampl = ssd_014.ecog_right.broad_gamma[10].copy()\n",
    "# sig = ssds.lo_beta.copy()\n",
    "\n",
    "a_phase = signal.hilbert(x=sig_phase,)\n",
    "a_ampl = signal.hilbert(x=sig_ampl,)\n",
    "phase = np.angle(a_phase)\n",
    "phase_deg = np.rad2deg(phase)  #phase * (180 / np.pi)\n",
    "ampl = abs(a_ampl)\n",
    "plt.plot(phase)\n",
    "plt.plot(ampl)\n",
    "plt.xlim(0, 1000)\n",
    "plt.yticks([-np.pi, 0, np.pi],\n",
    "           labels=['-180', '0', '+180'],)\n",
    "plt.ylabel('Phase (degree)')\n",
    "plt.xlabel('time (samples)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate PAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpac import Pac\n",
    "import lfpecog_features.feats_phase_amp_coupling as fts_pac\n",
    "import lfpecog_features.extract_ssd_features as ssdFts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS = utilsFiles.load_ft_ext_cfg(cfg_fname='ftExtr_spectral_v1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(phase_fts)\n",
    "\n",
    "pac_values = fts_pac.calculate_PAC_matrix(\n",
    "    sig_pha=ssd_014.ecog_right.lo_beta,\n",
    "    sig_amp=ssd_014.ecog_right.narrow_gamma,\n",
    "    window_times=ssd_014.ecog_right.times,\n",
    "    fs=ssd_014.ecog_right.fs,\n",
    "    freq_range_pha=SETTINGS['SPECTRAL_BANDS']['lo_beta'],\n",
    "    freq_range_amp=SETTINGS['SPECTRAL_BANDS']['narrow_gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop phase-difference values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_deg = phase * (180 / np.pi)\n",
    "\n",
    "phase_bins = {}\n",
    "for bin_start in np.arange(-180, 180, 20):\n",
    "    bin_sel = np.logical_and(phase_deg > bin_start,\n",
    "                             phase_deg<(bin_start+20))\n",
    "    ampl_sel = ampl[bin_sel]\n",
    "\n",
    "    phase_bins[bin_start] = ampl_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin in phase_bins:\n",
    "    amps = phase_bins[bin]\n",
    "    plt.hist(amps,alpha=.3)\n",
    "    ent = stats.entropy(amps)\n",
    "    plt.title(f'{bin} degree: entropy {ent}')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSD with meet toolbox (https://github.com/neurophysics/meet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meet.meet as meet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "i_win = 5\n",
    "win_dat = data.list_mne_objects[i_win].get_data()  # epochs x channels x times\n",
    "ch_names = data.list_mne_objects[i_win].ch_names\n",
    "fs = data.info['sfreq']\n",
    "nperseg = 1024\n",
    "bw_ranges = {   'alpha': [8, 12],\n",
    "                'lo_beta': [12, 20],\n",
    "                'hi_beta': [20, 35],\n",
    "                'beta': [12, 35],\n",
    "                'midgamma': [60, 90]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfpecog_features import feats_SSD as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and plot SSD functionality\n",
    "\n",
    "importlib.reload(ssd)\n",
    "\n",
    "SOURCE_SEL = 'ECOG'\n",
    "F_BAND_SEL = 'midgamma'\n",
    "epoch_i = 50\n",
    "plt.close()\n",
    "# select 2d data of one source (n-channels x n-samples)\n",
    "ch_sel = [n.startswith(SOURCE_SEL) for n in ch_names]\n",
    "epoch_dat = win_dat[epoch_i, ch_sel, :]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8,8))\n",
    "\n",
    "for F_BAND_SEL in ['lo_beta', 'hi_beta', 'beta', 'midgamma']:\n",
    "    ssd_filt_data, ssd_pattern, ssd_eigvals = ssd.get_SSD_component(\n",
    "        data_2d=epoch_dat,\n",
    "        fband_interest=bw_ranges[F_BAND_SEL],\n",
    "        s_rate=fs,\n",
    "        use_freqBand_filtered=True,\n",
    "        return_comp_n=0,\n",
    "    )\n",
    "    f, psd = signal.welch(ssd_filt_data, axis=-1, nperseg=fs, fs=fs)\n",
    "\n",
    "    axes[0].plot(ssd_filt_data, label=F_BAND_SEL)\n",
    "    axes[1].plot(f, psd, label=F_BAND_SEL)\n",
    "\n",
    "# psd of origin\n",
    "for i in range(epoch_dat.shape[0]):\n",
    "    f, psd = signal.welch(epoch_dat[i, :], nperseg=fs, fs=fs)\n",
    "    axes[2].plot(f, psd, label=F_BAND_SEL, c='k', alpha=.3,)\n",
    "\n",
    "axes[0].legend(ncol=4)\n",
    "axes[1].legend()\n",
    "axes[0].set_title('SSD filtered bands', fontsize=14, weight='bold',)\n",
    "axes[0].set_ylabel('LFP (a.u.)', fontsize=14,)\n",
    "axes[0].set_xlabel('Time (samples, 2048 Hz)', fontsize=14,)\n",
    "axes[1].set_title('Freq-specific PSD after SSD', fontsize=14, weight='bold',)\n",
    "axes[2].set_title('Original PSDs of channels', fontsize=14, weight='bold',)\n",
    "\n",
    "for ax in [1, 2]:\n",
    "    axes[ax].set_xlim(0, 100)\n",
    "    axes[ax].set_xlabel('Frequency (Hz)', fontsize=14,)\n",
    "    axes[ax].set_ylabel('Power (a.u.)', fontsize=14,)\n",
    "\n",
    "for ax in axes: ax.tick_params(axis='both', labelsize=10)\n",
    "plt.tight_layout()\n",
    "figname = 'SSD_example_timeseries_PSD'\n",
    "# plt.savefig(os.path.join(figpath, 'ft_exploration', 'SSD', figname),\n",
    "#             dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot SSD Components\n",
    "# for i, b in enumerate(SSD_beta):\n",
    "#     plt.plot(b, label=f'ch {i}',\n",
    "#              alpha=(1 - (i * .2)),\n",
    "#              lw=5 - i)\n",
    "# # beta1d = SSD_beta.T @ np.atleast_2d(SSD_eigvals).T  # combined signal, not relevant\n",
    "# # plt.plot(beta1d, label='product', c='k')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ecog_dysk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
