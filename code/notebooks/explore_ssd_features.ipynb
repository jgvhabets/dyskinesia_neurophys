{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore extracted Features based on SSD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn as sk\n",
    "from scipy import signal, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n",
    "feat_path = os.path.join(projectpath, 'results', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_plotting.expl_plotting as expl_plot\n",
    "\n",
    "\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "import lfpecog_analysis.get_acc_derivs as accDerivs\n",
    "\n",
    "\n",
    "from lfpecog_plotting.plotHelpers import remove_duplicate_legend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTINGS = utilsFiles.load_ft_ext_cfg(cfg_fname='ftExtr_spectral_v1.json')\n",
    "\n",
    "# WIN_LEN_sec = 10\n",
    "# WIN_OVERLAP_part = 0.0\n",
    "ssd_ft_path = os.path.join(feat_path, 'SSD_feats',\n",
    "                           SETTINGS['DATA_VERSION'],\n",
    "                           f\"windows_{SETTINGS['WIN_LEN_sec']}s_\"\n",
    "                           f\"{SETTINGS['WIN_OVERLAP_part']}overlap\")\n",
    "IGNORE_PTS = ['010', ]\n",
    "\n",
    "LID_SCORE_INCL = 1  # from this score, features are labeled into LID+ group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available subs with features \n",
    "SUBS = list(set([name.split('_')[1] for name in os.listdir(ssd_ft_path)]))\n",
    "\n",
    "for sub in IGNORE_PTS:\n",
    "    if sub in SUBS: SUBS.remove(sub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try:\n",
    "- only include ECoG and ipsilateral STN LFP\n",
    "- exclude moments where was only Dyskinesia in body-side ipsilateral to ECoG (NOT CORRESPONDING WITH ECoG-hemisphere)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Load Clinical Scores\n",
    "\n",
    "Select moments with Dyskinesia at WRONG BODYSIDE (ipsilateral to ECoG) for removal later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '008'\n",
    "scores_P = importClin.read_clinical_scores(sub=sub, rater='Patricia')\n",
    "scores_J = importClin.read_clinical_scores(sub=sub, rater='Jeroen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = {}\n",
    "ECOG_SIDES = {}\n",
    "REMOVE_TIMES = {}  # remove moments with only 'WRONG SIDE' dyskinesia\n",
    "\n",
    "for sub in SUBS:\n",
    "        # # GET UNILATERAL (CONTRA ECOG) CDRS SCORES\n",
    "        # scores_temp = importClin.read_clinical_scores(sub=sub,\n",
    "        #                                               rater='Patricia')\n",
    "        #         # check if scores are present\n",
    "        # if type(scores_temp) == type(None):\n",
    "        #         print(f'None CDRS-scores loaded for sub {sub}')\n",
    "        #         continue\n",
    "\n",
    "        # # get ECoG-side\n",
    "        # ecog_side = importClin.get_ecog_side(sub)\n",
    "        # ECOG_SIDES[sub] = ecog_side\n",
    "        # # define CDRS of body-side to include\n",
    "        # if ecog_side == 'left': LID_side_incl = 'right'\n",
    "        # elif ecog_side == 'right': LID_side_incl = 'left'\n",
    "        \n",
    "        # # identify minutes to remove bcs only Dyskinesia at none-ECoG side\n",
    "        # REMOVE_TIMES[sub] = []\n",
    "        # for i, t in enumerate(scores_temp['dopa_time']):\n",
    "        #         if np.logical_and(scores_temp.iloc[i][f'CDRS_total_{LID_side_incl}'] < 1,\n",
    "        #                           scores_temp.iloc[i][f'CDRS_total_{ecog_side}'] > 0):\n",
    "        #                 REMOVE_TIMES[sub].append(t)\n",
    "\n",
    "        # # include selected CDRS\n",
    "        # SCORES[sub] = scores_temp[['dopa_time', f'CDRS_total_{LID_side_incl}']]\n",
    "        \n",
    "\n",
    "        # GET LID PRESENT OR NOT\n",
    "        temp = importClin.read_clinical_scores(sub=sub, rater='Patricia')\n",
    "        SCORES[sub] = temp[['dopa_time', 'CDRS_total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['012', '011', '016', '013', '014', '009', '008'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORES.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Load Features\n",
    "\n",
    "Only include ECoG and ECoG-sided STN-LFP for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ssd_powers(sub, feat_path):\n",
    "\n",
    "    sub_ft_files = [f for f in os.listdir(feat_path) if\n",
    "                    sub in f and 'spectralFeatures' in f]\n",
    "    df_out = None\n",
    "    for f in sub_ft_files:\n",
    "        for dType in ['lfp_left', 'lfp_right',\n",
    "                      'ecog_left', 'ecog_right']:\n",
    "            if dType not in f: continue\n",
    "\n",
    "            temp = pd.read_csv(join(feat_path, f), header=0, index_col=0)\n",
    "            \n",
    "            temp = temp.rename(columns={k: f'{dType}_{k}'\n",
    "                                        for k in temp.keys()})\n",
    "\n",
    "            if not isinstance(df_out, pd.DataFrame):\n",
    "                df_out = temp\n",
    "                continue\n",
    "            # add to existing df_out\n",
    "            df_out = pd.concat([df_out, temp], ignore_index=False, axis=1,)\n",
    "\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "localPAC = namedtuple('localPAC', 'times values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ssd_localPAC(\n",
    "    sub, feat_path, pac_freqs):\n",
    "\n",
    "    sub_ft_files = [f for f in os.listdir(feat_path) if\n",
    "                    sub in f and 'localPAC' in f]\n",
    "    dict_out = {}\n",
    "\n",
    "    for dType in ['lfp_left', 'lfp_right',\n",
    "                    'ecog_left', 'ecog_right']:\n",
    "        \n",
    "        dtype_files = [f for f in sub_ft_files if dType in f]\n",
    "        if len(dtype_files) == 0: continue  # skip for i.e. not-existing ecog side \n",
    "        \n",
    "        for pha_f, amp_f in pac_freqs:\n",
    "        \n",
    "            for f in dtype_files:\n",
    "                if f'{pha_f}_{amp_f}' not in f: continue\n",
    "        \n",
    "                if 'times' in f: \n",
    "                    times = np.loadtxt(join(feat_path, f), delimiter=',')\n",
    "                else:\n",
    "                    dat = np.load(join(feat_path, f), allow_pickle=True)\n",
    "            \n",
    "            assert len(times) == dat.shape[-1], (\n",
    "                f'loaded PACs times ({len(times)}) and data ({dat.shape})'\n",
    "                f' dont match for {dType}_{pha_f}_{amp_f}'\n",
    "            )\n",
    "            dict_out[f'{dType}_{pha_f}_{amp_f}'] = localPAC(times, dat)\n",
    "            del(times, dat)\n",
    "\n",
    "    return dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, exists\n",
    "\n",
    "@dataclass(init=True, repr=True)\n",
    "class ssdFeatures():\n",
    "    settings_json: str = 'ftExtr_spectral_v1.json'\n",
    "    sub_list: list = field(default_factory=lambda: [])\n",
    "    data_version: str = 'v3.0'\n",
    "    win_len_sec: int or float = 10\n",
    "    win_overlap_part: float = 0.0\n",
    "    incl_powers: bool = True\n",
    "    incl_localPAC: bool = True\n",
    "    incl_coherence: bool = True\n",
    "\n",
    "    def __post_init__(self,):\n",
    "        # load feature extraction settings\n",
    "        extract_settings = utilsFiles.load_ft_ext_cfg(cfg_fname=self.settings_json)\n",
    "\n",
    "        # define feature path and check existence\n",
    "        self.feat_path = join(get_project_path('results'),\n",
    "                    'features',\n",
    "                    'SSD_feats',\n",
    "                    self.data_version,\n",
    "                    f'windows_{self.win_len_sec}s_'\n",
    "                    f'{self.win_overlap_part}overlap')\n",
    "        assert exists(self.feat_path), f'feat_path ([{self.feat_path}]) does not exist'\n",
    "        # take all available subjects from feature path if sub_list is not defined\n",
    "        if self.sub_list == []:\n",
    "            self.sub_list = list(set([name.split('_')[1]\n",
    "                                      for name in os.listdir(self.feat_path)]))\n",
    "\n",
    "        keywords = vars(self)\n",
    "\n",
    "        for sub in self.sub_list:\n",
    "            print(f'\\nload SSDd features for sub-{sub}')\n",
    "            setattr(self,\n",
    "                    f'sub{sub}',\n",
    "                    ssdFeats_perSubject(sub=sub, feat_path=self.feat_path,\n",
    "                                        settings=keywords,\n",
    "                                        extract_settings=extract_settings),)\n",
    "            \n",
    "\n",
    "\n",
    "@dataclass(init=True, repr=True)\n",
    "class ssdFeats_perSubject:\n",
    "    sub: str = 'default'  # default given to prevent inheritance error\n",
    "    feat_path: str = 'default'\n",
    "    settings: dict = field(default_factory=lambda: {})\n",
    "    extract_settings: dict = field(default_factory=lambda: {})\n",
    "    verbose: bool = False\n",
    "\n",
    "    def __post_init__(self,):\n",
    "        \n",
    "        if self.settings['incl_powers']:\n",
    "            if self.verbose: print(f'load POWERS - {self.sub}')\n",
    "            self.powers = load_ssd_powers(sub, feat_path=self.feat_path)\n",
    "        \n",
    "        if self.settings['incl_localPAC']:\n",
    "            if self.verbose: print(f'load local PAC - {self.sub}')\n",
    "            pac_freqs = self.extract_settings['FEATS_INCL']['local_PAC_freqs']\n",
    "            self.localPAC = load_ssd_localPAC(sub, feat_path=self.feat_path,\n",
    "                                              pac_freqs=pac_freqs)\n",
    "        \n",
    "        if self.settings['incl_coherence']:\n",
    "            print(f'TODO: load COHERENCES - {self.sub}')\n",
    "            # self.powers = load_ssd_coherences(sub, feat_path=self.feat_path)\n",
    "\n",
    "        # TODO: LOAD CDRSB SCORES\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load SSDd features for sub-012\n",
      "TODO: load COHERENCES - 012\n",
      "\n",
      "load SSDd features for sub-011\n",
      "TODO: load COHERENCES - 011\n",
      "\n",
      "load SSDd features for sub-016\n",
      "TODO: load COHERENCES - 016\n",
      "\n",
      "load SSDd features for sub-013\n",
      "TODO: load COHERENCES - 013\n",
      "\n",
      "load SSDd features for sub-014\n",
      "TODO: load COHERENCES - 014\n",
      "\n",
      "load SSDd features for sub-009\n",
      "TODO: load COHERENCES - 009\n",
      "\n",
      "load SSDd features for sub-008\n",
      "TODO: load COHERENCES - 008\n"
     ]
    }
   ],
   "source": [
    "fts = ssdFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4, 333)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts.sub009.localPAC['ecog_right_lo_beta_narrow_gamma'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSDfeats_014_ecog_right_local_spectralFeatures.csv',\n",
       " 'SSDfeats_014_lfp_left_local_spectralFeatures.csv',\n",
       " 'SSDfeats_014_lfp_right_local_spectralFeatures.csv']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPECTRAL POWERS\n",
    "sub = '014'\n",
    "sub_ft_files = [f for f in os.listdir(ssd_ft_path) if sub in f]\n",
    "\n",
    "ft_name = 'localPAC'\n",
    "ft_name = 'spectralFeatures'\n",
    "[f for f in sub_ft_files if ft_name in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = {}\n",
    "for sub in SUBS:\n",
    "    ecog_side = ECOG_SIDES[sub]\n",
    "    # load ECog Features\n",
    "    ecog_fts = pd.read_csv(os.path.join(ssd_ft_path, f'SSDfeatures_{sub}_ecog_{ecog_side}.csv'),\n",
    "                            index_col=0, header=0)\n",
    "    # rename and add ECOG to ft-names\n",
    "    rename_cols = {}\n",
    "    for key in ecog_fts.keys(): rename_cols[key] = f'ECOG_{key}'\n",
    "    ecog_fts = ecog_fts.rename(columns=rename_cols)\n",
    "    \n",
    "    # load ECog Features\n",
    "    stn_fts = pd.read_csv(os.path.join(ssd_ft_path, f'SSDfeatures_{sub}_lfp_{ecog_side}.csv'),\n",
    "                            index_col=0, header=0)\n",
    "    # rename and add STN to ft-names\n",
    "    rename_cols = {}\n",
    "    for key in stn_fts.keys(): rename_cols[key] = f'STN_{key}'\n",
    "    stn_fts = stn_fts.rename(columns=rename_cols)\n",
    "\n",
    "    merged_fts = pd.concat([stn_fts, ecog_fts], axis=1, ignore_index=False)\n",
    "    merged_fts.index = merged_fts.index / 60  # convert to minutes to agree with CDRS score\n",
    "    FEATS[sub] = merged_fts\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Prepare Features and Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features to exclude and get CDRS scores to remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS DUE TO DYSKINESIA ONLY (!!) IN NONE-ECOG-SIDE\n",
    "for sub in SUBS:\n",
    "  ft_times = FEATS[sub].index\n",
    "  score_times = SCORES[sub]['dopa_time']\n",
    "\n",
    "  remove_ft_idx = []\n",
    "  # select feature-rows which are closest to a CDRS-moments which should be excluded\n",
    "  for ft_row, t in enumerate(ft_times):\n",
    "      t_diffs = abs(score_times - t)\n",
    "      i = np.argmin(t_diffs)\n",
    "\n",
    "      if score_times[i] in REMOVE_TIMES[sub]:\n",
    "        remove_ft_idx.append(ft_times[i])  \n",
    "          \n",
    "  FEATS[sub] = FEATS[sub].drop(remove_ft_idx, axis=0)\n",
    "  print(f'removed {len(remove_ft_idx)} rows in sub-{sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CDRS LABELS FOR FEATURE WINDOW TIMES\n",
    "FT_LABELS = {}\n",
    "\n",
    "for sub in SUBS:\n",
    "    ft_times = FEATS[sub].index\n",
    "\n",
    "    ft_scores = []\n",
    "\n",
    "    for t in ft_times:\n",
    "        t_diffs = abs(SCORES[sub]['dopa_time'] - t)\n",
    "        i = np.argmin(t_diffs)\n",
    "        ft_scores.append(SCORES[sub].iat[i, 1])  # take column 1, is CDRS score\n",
    "\n",
    "    FT_LABELS[sub] = ft_scores\n",
    "\n",
    "    assert FEATS[sub].shape[0] == len(FT_LABELS[sub]), (\n",
    "        'Feature DataFrame and Ft-Labels must have same length'\n",
    "    )\n",
    "# no_LID_sel = np.array(ft_scores) == 0\n",
    "# LID_sel = np.array(ft_scores) >= LID_SCORE_INCL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plotHelpers as pltHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = []\n",
    "y_total_binary = []\n",
    "y_total_scale = []\n",
    "sub_ids_total = []\n",
    "ft_times_total = []\n",
    "\n",
    "EXCL_CODE = 99\n",
    "\n",
    "TO_PLOT = False\n",
    "\n",
    "if TO_PLOT:\n",
    "    fig, axes = plt.subplots(len(SUBS), 1, figsize=(12, 16))\n",
    "    fs = 16\n",
    "\n",
    "\n",
    "for i_s, sub in enumerate(SUBS):\n",
    "    # create lists to store values for boxplotting\n",
    "    bp_LID_values_list = []\n",
    "    bp_noLID_values_list = []\n",
    "    bp_keys = []\n",
    "\n",
    "\n",
    "    ### Create Y-labels based on CDRS (FT_LABELS)\n",
    "    no_LID_sel = np.array(FT_LABELS[sub]) == 0\n",
    "    LID_sel = np.array(FT_LABELS[sub]) >= LID_SCORE_INCL\n",
    "\n",
    "    # create binary y-labels\n",
    "    sub_y_bin = []  # y as binary\n",
    "    for noLID, LID in zip(no_LID_sel, LID_sel):\n",
    "        if noLID: sub_y_bin.append(0)\n",
    "        elif LID: sub_y_bin.append(1)\n",
    "        else: sub_y_bin.append(EXCL_CODE)\n",
    "    # add full scaled y-labels\n",
    "    sub_y_scale = FT_LABELS[sub]\n",
    "\n",
    "    # append sub-codes to sub-id list\n",
    "    sub_ids_total.append([sub] * FEATS[sub].shape[0])  # add subject code, as many times as there are feature rows\n",
    "\n",
    "    # add subjects ft-times to list\n",
    "    ft_times_total.append(FEATS[sub].index.values)\n",
    "\n",
    "    ### Create X with standardised Feature-arrays\n",
    "    sub_X = np.zeros_like((FEATS[sub]))\n",
    "\n",
    "    for n_col, ft in enumerate(FEATS[sub].keys()):\n",
    "        values = FEATS[sub].values[:, n_col]\n",
    "        # split values on Dyskinesia\n",
    "        noLID_values = values[no_LID_sel]\n",
    "        LID_values = values[LID_sel]\n",
    "        \n",
    "        # define mean and std of no-LID for Z-SCORE\n",
    "        m = np.nanmean(noLID_values)\n",
    "        sd = np.nanstd(noLID_values)\n",
    "        # Z-SCORE values\n",
    "        Z_LID_values = (LID_values - m) / sd\n",
    "        Z_noLID_values = (noLID_values - m) / sd\n",
    "        Z_ALL_values = (values - m) / sd\n",
    "\n",
    "        # add feat and z-score values to lists for BOXPLOT (WITHOUT NaNs)\n",
    "        bp_LID_values_list.append(list(Z_LID_values[~np.isnan(LID_values)]))\n",
    "        bp_keys.append(ft)\n",
    "\n",
    "        # store all feats for pred-exploration\n",
    "        sub_X[:, n_col] = Z_ALL_values\n",
    "    \n",
    "    X_total.append(sub_X)\n",
    "    y_total_binary.append(sub_y_bin)\n",
    "    y_total_scale.append(sub_y_scale)\n",
    "\n",
    "    if TO_PLOT:\n",
    "        ##### PLOT BOXPLOT OF FEATURES ######\n",
    "        box = axes[i_s].boxplot(bp_LID_values_list)\n",
    "        plt.setp(box['fliers'], color='gray')\n",
    "        # plt.setp(box['whiskers'], color='red')\n",
    "\n",
    "        axes[i_s].axhline(y=0, xmin=0, xmax=24, color='k', alpha=.3)\n",
    "        for y_line in [-2, 2]: axes[i_s].axhline(y=y_line, xmin=0, xmax=24, color='r', alpha=.3)\n",
    "\n",
    "        axes[i_s].set_ylim(-6, 6)\n",
    "        axes[i_s].set_ylabel(f'z-scores\\nvs no-LID (a.u.)', fontsize=fs)\n",
    "        axes[i_s].set_title(f'Sub-{sub} (mean unilat. CDRS '\n",
    "                            f'{round(np.mean(FT_LABELS[sub]), 2)})',\n",
    "                            weight='bold', fontsize=fs)\n",
    "        axes[i_s].set_xticklabels(['mx', 'mn', 'cv'] * int(len(bp_keys) / 3),\n",
    "                                fontsize=fs,)\n",
    "\n",
    "        for side in ['top','right','bottom']:\n",
    "            axes[i_s].spines[side].set_visible(False)\n",
    "\n",
    "        ### fill colors\n",
    "        colors = {\n",
    "            'alpha': 'yellow',\n",
    "            'lo_beta': 'lightblue',\n",
    "            'hi_beta': 'darkblue',\n",
    "            'midgamma': 'green'\n",
    "        }\n",
    "        hatches = {\n",
    "            'STN': '',\n",
    "            'ECoG': '//'\n",
    "        }\n",
    "\n",
    "        x_fill_list = []\n",
    "        for x1 in np.arange(.5, len(bp_keys) + .5, 3):\n",
    "            x2 = x1 + 3\n",
    "            x_fill_list.append([x1, x2])\n",
    "\n",
    "        for i_x, (src, bw) in  enumerate(product(hatches.keys(), colors.keys())):\n",
    "            axes[i_s].fill_betweenx(\n",
    "                y=np.arange(-6, 6), x1=x_fill_list[i_x][0],\n",
    "                x2=x_fill_list[i_x][1], color=colors[bw], hatch=hatches[src],\n",
    "                label=f'{src} {bw}', alpha=.2, edgecolor='gray',)\n",
    "if TO_PLOT:\n",
    "    leg_content = plt.gca().get_legend_handles_labels()\n",
    "    handles, labels = pltHelp.remove_duplicate_legend(leg_content)\n",
    "    plt.legend(handles, labels, ncol=4, frameon=False,\n",
    "            loc='upper center', bbox_to_anchor=(0.5, -0.2),fancybox=False,\n",
    "            prop={'weight': 'bold', 'size': fs})\n",
    "\n",
    "    plt.suptitle('Individual Feature values during Dyskinesia\\n', weight='bold', fontsize=fs+4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    figname = 'LID_ssdFeatures_boxplots_indiv'\n",
    "    # plt.savefig(os.path.join(figpath, 'ft_exploration', 'SSD', figname),\n",
    "    #             dpi=300, facecolor='w',)\n",
    "    plt.close()\n",
    "\n",
    "print(f'FEATURES X-AXIS: {bp_keys}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_dysk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
