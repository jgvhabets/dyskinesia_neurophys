{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict CDRS based on SSD'd Spectral Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import sklearn as sk\n",
    "from scipy import signal, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n",
    "feat_path = os.path.join(projectpath, 'results', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "import lfpecog_analysis.stats_fts_lid_corrs as ftLidCorr\n",
    "import lfpecog_analysis.load_SSD_features as load_ssdFts\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_features.feats_helper_funcs as ftHelp\n",
    "from lfpecog_features.get_ssd_data import get_subject_SSDs\n",
    "import lfpecog_predict.prepare_predict_arrays as prep_pred_arrs\n",
    "\n",
    "from lfpecog_plotting.plotHelpers import get_colors\n",
    "import lfpecog_plotting.plotHelpers as pltHelp\n",
    "import lfpecog_plotting.plot_FreqCorr as plotFtCorrs\n",
    "import lfpecog_plotting.plot_SSD_feat_descriptives as plot_ssd_descr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_VERSION = 'v4.2'    # v4.0: new artef-rem, no reref; v3.0 multiple re-ref\n",
    "FT_VERSION = 'v7'  # v4: broad-flanks, bursts; v3: broad-flanked SSD\n",
    "INCL_PSD_FTS=['mean_psd', 'variation']\n",
    "IGNORE_PTS = ['011', '104', '106']\n",
    "\n",
    "CDRS_RATER = 'Jeroen'\n",
    "ANALYSIS_SIDE = 'BILAT'\n",
    "INCL_CORE_CDRS = True\n",
    "CATEGORICAL_CDRS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available subs with features\n",
    "SUBS = utilsFiles.get_avail_ssd_subs(DATA_VERSION=DATA_VERSION,\n",
    "                                     FT_VERSION=FT_VERSION,\n",
    "                                     IGNORE_PTS=IGNORE_PTS)\n",
    "print(f'SUBS: n={len(SUBS)} ({SUBS})')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- only include ECoG and ipsilateral STN LFP\n",
    "- exclude moments where was only Dyskinesia in body-side ipsilateral to ECoG (NOT CORRESPONDING WITH ECoG-hemisphere)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Prepare Neurophysiological and Clinical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(load_ssdFts)\n",
    "\n",
    "# use as single ft example to debug/develop\n",
    "sub_fts = load_ssdFts.ssdFeatures(\n",
    "    sub_list=['023'],\n",
    "    settings_json=f'ftExtr_spectral_{FT_VERSION}.json',\n",
    "    data_version=DATA_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize categorical CDRS conversion\n",
    "# importlib.reload(ftProc)\n",
    "# importlib.reload(load_ssdFts)\n",
    "\n",
    "# sub='012'\n",
    "\n",
    "# plt.plot(FEATS[sub].index, FT_LABELS[sub], label='CDRS')\n",
    "\n",
    "# mc_y = ftProc.categorical_CDRS(\n",
    "#     y_full_scale=FT_LABELS[sub],\n",
    "#     time_minutes=FEATS[sub].index,\n",
    "#     preLID_minutes=10,\n",
    "#     preLID_separate=True,\n",
    "#     convert_inBetween_zeros='mild',\n",
    "# )\n",
    "# plt.plot(FEATS[sub].index, mc_y, label='categ')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Class with FEATS and CDRS-LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBS: n=22 (['009', '103', '017', 'ACC', '014', '023', '022', '107', '102', '010', '019', '109', '008', '101', '012', '016', '110', '020', '021', '105', '013', '108'])\n",
      "load 009\n",
      "load 103\n",
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\merged_sub_data\\v4.0\\sub-103\\103_mergedData_v4.0_acc_left.P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\merged_sub_data\\v4.0\\sub-103\\103_mergedData_v4.0_acc_right.P\n",
      "load 017\n",
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\merged_sub_data\\v4.0\\sub-017\\017_mergedData_v4.0_acc_left.P\n",
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\merged_sub_data\\v4.0\\sub-017\\017_mergedData_v4.0_acc_right.P\n",
      "load ACC\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'sub-ACC' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\notebooks\\predict_ssd_features.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m MILD_CDRS \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m SEV_CDRS \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m FeatLid \u001b[39m=\u001b[39m ftProc\u001b[39m.\u001b[39;49mFeatLidClass(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     FT_VERSION\u001b[39m=\u001b[39;49mFT_VERSION,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     INCL_ECOG\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     INCL_ACC_RMS\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     CATEGORICAL_CDRS\u001b[39m=\u001b[39;49mCATEG_CDRS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     CORR_TARGET\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCDRS\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     cutMild\u001b[39m=\u001b[39;49mMILD_CDRS, cutSevere\u001b[39m=\u001b[39;49mSEV_CDRS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     TO_CALC_CORR\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/predict_ssd_features.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[1;32m<string>:20\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, FT_VERSION, CDRS_RATER, ANALYSIS_SIDE, INCL_STN, INCL_ECOG, EXCL_IPSI_ECOG, INCL_CORE_CDRS, INCL_PSD_FTS, INCL_ACC_RMS, IGNORE_PTS, CATEGORICAL_CDRS, cutMild, cutSevere, WIN_LEN_sec, WIN_OVERLAP_part, TO_CALC_CORR, CORR_TARGET)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_analysis\\ft_processing_helpers.py:72\u001b[0m, in \u001b[0;36mFeatLidClass.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m# LOAD MERGED NEUROPHYS FEATURES\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFEATS[sub] \u001b[39m=\u001b[39m load_feature_df_for_pred(\n\u001b[0;32m     73\u001b[0m     sub,\n\u001b[0;32m     74\u001b[0m     INCL_PSD\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mINCL_PSD_FTS,\n\u001b[0;32m     75\u001b[0m     LATERALITY\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mANALYSIS_SIDE,\n\u001b[0;32m     76\u001b[0m     EXCL_IPSI_ECOG\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mEXCL_IPSI_ECOG,\n\u001b[0;32m     77\u001b[0m     INCL_STN\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mINCL_STN,\n\u001b[0;32m     78\u001b[0m     INCL_ECOG\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mINCL_ECOG,\n\u001b[0;32m     79\u001b[0m     FT_VERSION\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mFT_VERSION,\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[39m# LOAD CLINICAL SCORES AND CORRESPONDING WINDOW SELECTION\u001b[39;00m\n\u001b[0;32m     83\u001b[0m ecog_related_cdrs \u001b[39m=\u001b[39m find_select_nearest_CDRS_for_ephys(\n\u001b[0;32m     84\u001b[0m     sub\u001b[39m=\u001b[39msub, ft_times\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFEATS[sub]\u001b[39m.\u001b[39mindex,\n\u001b[0;32m     85\u001b[0m     cdrs_rater\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCDRS_RATER,\n\u001b[0;32m     86\u001b[0m     side\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mANALYSIS_SIDE,\n\u001b[0;32m     87\u001b[0m     INCL_CORE_CDRS\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mINCL_CORE_CDRS,\n\u001b[0;32m     88\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_analysis\\ft_processing_helpers.py:187\u001b[0m, in \u001b[0;36mload_feature_df_for_pred\u001b[1;34m(sub, LATERALITY, INCL_PSD, INCL_COH, INCL_BURSTS, sel_bandwidths, INCL_STN, INCL_ECOG, EXCL_IPSI_ECOG, FT_VERSION, verbose)\u001b[0m\n\u001b[0;32m    185\u001b[0m settings_json \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mftExtr_spectral_\u001b[39m\u001b[39m{\u001b[39;00mFT_VERSION\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[39m# load all features\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m fts \u001b[39m=\u001b[39m ssdFeatures(sub_list\u001b[39m=\u001b[39;49m[sub],\n\u001b[0;32m    188\u001b[0m                   settings_json\u001b[39m=\u001b[39;49msettings_json,\n\u001b[0;32m    189\u001b[0m                   incl_bursts\u001b[39m=\u001b[39;49mINCL_BURSTS,)\n\u001b[0;32m    190\u001b[0m incl_bws \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(fts\u001b[39m.\u001b[39mftExtract_settings[\u001b[39m'\u001b[39m\u001b[39mSPECTRAL_BANDS\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m    191\u001b[0m sub_fts \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fts, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msub\u001b[39m\u001b[39m{\u001b[39;00msub\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)  \u001b[39m# get sub-specific feature-class\u001b[39;00m\n",
      "File \u001b[1;32m<string>:10\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, settings_json, sub_list, incl_powers, incl_localPAC, incl_bursts, incl_coherence, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_analysis\\load_SSD_features.py:116\u001b[0m, in \u001b[0;36mssdFeatures.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m sub \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msub_list:\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose: \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mload SSDd features for sub-\u001b[39m\u001b[39m{\u001b[39;00msub\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    114\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    115\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msub\u001b[39m\u001b[39m{\u001b[39;00msub\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m--> 116\u001b[0m             ssdFeats_perSubject(sub\u001b[39m=\u001b[39;49msub, feat_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeat_path,\n\u001b[0;32m    117\u001b[0m                                 settings\u001b[39m=\u001b[39;49mkeywords,\n\u001b[0;32m    118\u001b[0m                                 ftExtract_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mftExtract_settings),)\n",
      "File \u001b[1;32m<string>:8\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, sub, feat_path, settings, ftExtract_settings, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_analysis\\load_SSD_features.py:134\u001b[0m, in \u001b[0;36mssdFeats_perSubject.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m dysk_rater \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mPatricia\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msub \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m019\u001b[39m\u001b[39m'\u001b[39m: dysk_rater \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mJeroen\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 134\u001b[0m scores \u001b[39m=\u001b[39m read_clinical_scores(sub\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msub, rater\u001b[39m=\u001b[39;49mdysk_rater)\n\u001b[0;32m    136\u001b[0m \u001b[39m# add scores as namedtuple (times, left, right, total)\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscores \u001b[39m=\u001b[39m CDRS_scores(\n\u001b[0;32m    138\u001b[0m     scores[\u001b[39m'\u001b[39m\u001b[39mdopa_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m    139\u001b[0m     scores[\u001b[39m'\u001b[39m\u001b[39mCDRS_total_left\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m    140\u001b[0m     scores[\u001b[39m'\u001b[39m\u001b[39mCDRS_total_right\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m    141\u001b[0m     scores[\u001b[39m'\u001b[39m\u001b[39mCDRS_total\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    142\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_preproc\\preproc_import_scores_annotations.py:109\u001b[0m, in \u001b[0;36mread_clinical_scores\u001b[1;34m(sub, rater, data_path)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m sub \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m019\u001b[39m\u001b[39m'\u001b[39m]: rater \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mJeroen\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    108\u001b[0m scores_fname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDyskinesia_Ratings_\u001b[39m\u001b[39m{\u001b[39;00mrater\u001b[39m}\u001b[39;00m\u001b[39m.xlsx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 109\u001b[0m scores \u001b[39m=\u001b[39m read_excel(\n\u001b[0;32m    110\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_path, \u001b[39m'\u001b[39;49m\u001b[39mclinical scores\u001b[39;49m\u001b[39m'\u001b[39;49m, scores_fname),\n\u001b[0;32m    111\u001b[0m     sheet_name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msub-\u001b[39;49m\u001b[39m{\u001b[39;49;00msub\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[39m# delete redundant rows with text-explanation\u001b[39;00m\n\u001b[0;32m    115\u001b[0m row \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\pandas\\io\\excel\\_base.py:465\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    464\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mparse(\n\u001b[0;32m    466\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m    467\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m    468\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    469\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m    470\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[0;32m    471\u001b[0m         squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m    472\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    473\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m    474\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[0;32m    475\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[0;32m    476\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m    477\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    478\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m    479\u001b[0m         keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m    480\u001b[0m         na_filter\u001b[39m=\u001b[39;49mna_filter,\n\u001b[0;32m    481\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    482\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m    483\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[0;32m    484\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m    485\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m    486\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[0;32m    487\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[0;32m    488\u001b[0m         convert_float\u001b[39m=\u001b[39;49mconvert_float,\n\u001b[0;32m    489\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39;49mmangle_dupe_cols,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1458\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m   1425\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1426\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1446\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1447\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mparse(\n\u001b[0;32m   1459\u001b[0m         sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[0;32m   1460\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   1461\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m   1462\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   1463\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m   1464\u001b[0m         squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[0;32m   1465\u001b[0m         converters\u001b[39m=\u001b[39mconverters,\n\u001b[0;32m   1466\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m   1467\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m   1468\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m   1469\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m   1470\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m   1471\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m   1472\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m   1473\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m   1474\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m   1475\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m   1476\u001b[0m         convert_float\u001b[39m=\u001b[39mconvert_float,\n\u001b[0;32m   1477\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m   1478\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1479\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\pandas\\io\\excel\\_base.py:634\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReading sheet \u001b[39m\u001b[39m{\u001b[39;00masheetname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(asheetname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_sheet_by_name(asheetname)\n\u001b[0;32m    635\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sheet_by_index(asheetname)\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:545\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sheet_by_name\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 545\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraise_if_bad_sheet_by_name(name)\n\u001b[0;32m    546\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbook[name]\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Anaconda3\\envs\\ecog_dysk\\lib\\site-packages\\pandas\\io\\excel\\_base.py:570\u001b[0m, in \u001b[0;36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_if_bad_sheet_by_name\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msheet_names:\n\u001b[1;32m--> 570\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWorksheet named \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Worksheet named 'sub-ACC' not found"
     ]
    }
   ],
   "source": [
    "# LOAD FEATURE via FeatureClass containing all features\n",
    "importlib.reload(utilsFiles)\n",
    "importlib.reload(ftProc)\n",
    "importlib.reload(importClin)\n",
    "importlib.reload(load_ssdFts)\n",
    "importlib.reload(ftLidCorr)\n",
    "\n",
    "\n",
    "FT_VERSION = 'v6'\n",
    "INCL_CORE_CDRS = True\n",
    "CATEG_CDRS = False\n",
    "MILD_CDRS = 4\n",
    "SEV_CDRS = 8\n",
    "\n",
    "FeatLid = ftProc.FeatLidClass(\n",
    "    FT_VERSION=FT_VERSION,\n",
    "    INCL_ECOG=False,\n",
    "    INCL_ACC_RMS=True,\n",
    "    CATEGORICAL_CDRS=CATEG_CDRS,\n",
    "    CORR_TARGET='CDRS',\n",
    "    cutMild=MILD_CDRS, cutSevere=SEV_CDRS,\n",
    "    TO_CALC_CORR=True,\n",
    ")\n",
    "\n",
    "# print(f'features included: {FEATS[sub].keys()}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted class saved as c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\prediction_data\\featLabelClasses\\featLabels_ftv7_Cdrs.P\n"
     ]
    }
   ],
   "source": [
    "# SAVE FeatLabelClass as pickle\n",
    "\n",
    "featLabPath = os.path.join(utilsFiles.get_project_path('data'),\n",
    "                           'prediction_data',\n",
    "                           'featLabelClasses')\n",
    "className = f'featLabels_ft{FT_VERSION}'\n",
    "if FeatLid.CORR_TARGET == 'LID': className += '_Lid'\n",
    "elif FeatLid.CATEGORICAL_CDRS == True: className += '_CatCdrs'\n",
    "else: className += '_Cdrs'\n",
    "utilsFiles.save_class_pickle(class_to_save=FeatLid,\n",
    "                             path=featLabPath,\n",
    "                             filename=className)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\prediction_data\\featLabelClasses\\featLabels_ftv6_Cdrs.P\n",
      "c:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\data\\prediction_data\\featLabelClasses\\featLabels_ftv7_Cdrs.P\n"
     ]
    }
   ],
   "source": [
    "# LOAD existing classes with features and labels\n",
    "predData_6 = utilsFiles.load_class_pickle(\n",
    "    os.path.join(featLabPath, 'featLabels_ftv6_Cdrs.P'),\n",
    "    convert_float_np64=True\n",
    ")\n",
    "\n",
    "predData_7 = utilsFiles.load_class_pickle(\n",
    "    os.path.join(featLabPath, 'featLabels_ftv7_Cdrs.P'),\n",
    "    convert_float_np64=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Heatmap Feature versus Dyskinesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pltHelp)\n",
    "\n",
    "importlib.reload(plotFtCorrs)\n",
    "\n",
    "INCL_STN=True\n",
    "INCL_ECOG=True\n",
    "\n",
    "ftCorrSetts = [\n",
    "    {'FT_VERSION': 'v6',\n",
    "     'CORR_TARGET': 'LID',\n",
    "     'CATEG_CDRS': False,\n",
    "     'INCL_STN': INCL_STN,\n",
    "     'INCL_ECOG': INCL_ECOG},\n",
    "     \n",
    "    {'FT_VERSION': 'v6',\n",
    "     'CORR_TARGET': 'CDRS',\n",
    "     'CATEG_CDRS': True,\n",
    "     'INCL_STN': INCL_STN,\n",
    "     'INCL_ECOG': INCL_ECOG},\n",
    "     \n",
    "    {'FT_VERSION': 'v6',\n",
    "     'CORR_TARGET': 'CDRS',\n",
    "     'CATEG_CDRS': False,\n",
    "     'INCL_STN': INCL_STN,\n",
    "     'INCL_ECOG': INCL_ECOG},\n",
    "     \n",
    "    {'FT_VERSION': 'v7',\n",
    "     'CORR_TARGET': 'LID',\n",
    "     'CATEG_CDRS': False,\n",
    "     'INCL_STN': INCL_STN,\n",
    "     'INCL_ECOG': INCL_ECOG},\n",
    "     \n",
    "    {'FT_VERSION': 'v7',\n",
    "     'CORR_TARGET': 'CDRS',\n",
    "     'CATEG_CDRS': True,\n",
    "     'INCL_STN': INCL_STN,\n",
    "     'INCL_ECOG': INCL_ECOG},\n",
    "     \n",
    "    {'FT_VERSION': 'v7',\n",
    "     'CORR_TARGET': 'CDRS',\n",
    "     'CATEG_CDRS': False,\n",
    "     'INCL_STN': INCL_STN,\n",
    "     'INCL_ECOG': INCL_ECOG},\n",
    "]\n",
    "\n",
    "plotFtCorrs.plot_heatmap_ftSettings_vs_Dyskinesia(\n",
    "    settingsDict=ftCorrSetts,\n",
    "    fig_name='CorrMap_6settings_ECoG_v4'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Explore features vs Dyskinesia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import mixedlm\n",
    "import gpboost as gpb\n",
    "from scipy.stats import norm as norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# check distributions\n",
    "ks = [f for f in FeatLid.stat_df.keys()\n",
    " if sum(FeatLid.stat_df[f] < 0) > 1]\n",
    "\n",
    "print(ks)\n",
    "\n",
    "for k in ks:\n",
    "    plt.hist(FeatLid.stat_df[k])\n",
    "    plt.title(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot violin or boxplots for features in different CDRS scores/categories\n",
    "\n",
    "INCLUDE PREDYSKINETIC MOMENTS AS NEXT STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT BINARY FEATURE DIFFERENCES\n",
    "# INCLUDE PREDYSKINETIC MOMENTS AS NEXT STEP\n",
    "\n",
    "importlib.reload(plot_ssd_descr)\n",
    "\n",
    "incl_ft_sources = 'ECOG'  # 'ECOG', 'ALL'\n",
    "sign_test = 'glmm'\n",
    "\n",
    "fig_path = os.path.join(figpath, 'prediction', ANALYSIS_SIDE.lower(),\n",
    "                                 f'ft_version_{FT_VERSION}',\n",
    "                                 f'n_is_{len(SUBS)}')\n",
    "\n",
    "fig_name = f'violinFeats{incl_ft_sources}_ftV4_powCoh_binaryLID_{sign_test}'\n",
    "if SSD_broad_flanks: fig_name += '_broadbandSSD'\n",
    "fig_name += f'_n{len(SUBS)}'\n",
    "\n",
    "plot_ssd_descr.plot_binary_featViolins(\n",
    "    X_all, y_all_scale, sub_ids, ft_names,\n",
    "    incl_ft_sources = incl_ft_sources,\n",
    "    SHOW_PLOT=False, SAVE_PLOT=False,\n",
    "    fig_name=fig_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT CATEGORICAL FEATURE DIFFERENCES\n",
    "# INCLUDE PREDYSKINETIC MOMENTS AS NEXT STEP\n",
    "\n",
    "importlib.reload(plot_ssd_descr)\n",
    "\n",
    "incl_ft_sources = 'STN'  # 'ECOG', 'ALL'\n",
    "sign_test = 'pearson'\n",
    "\n",
    "fig_path = os.path.join(figpath, 'ft_exploration', 'v4.0',\n",
    "                        # ANALYSIS_SIDE.lower(),\n",
    "                        #          f'ft_version_{FT_VERSION}',\n",
    "                        #          f'n_is_{len(SUBS)}'\n",
    ")\n",
    "\n",
    "fig_name_ftBox = f'boxFeats{incl_ft_sources}_ftV4_powCoh_categLID2meanPJ_{sign_test}'\n",
    "if SSD_broad_flanks: fig_name_ftBox += '_broadbandSSD'\n",
    "fig_name_ftBox += f'_n{len(SUBS)}'\n",
    "\n",
    "fig_name_corrBar = f'barCorrs{incl_ft_sources}_ftV4_powCoh_categLID_{sign_test}'\n",
    "if SSD_broad_flanks: fig_name_corrBar += '_broadbandSSD'\n",
    "fig_name_corrBar += f'_n{len(SUBS)}'\n",
    "\n",
    "plot_ssd_descr.plot_feats_on_categLID(\n",
    "    X_all, y_all_scale, sub_ids, ft_names,\n",
    "    incl_ft_sources = incl_ft_sources,\n",
    "    sign_test='glmm',\n",
    "    SHOW_FT_BOXPLOT=False,\n",
    "    SAVE_FT_BOXPLOT=True,\n",
    "    SHOW_CORR_BARPLOT=False,\n",
    "    SAVE_CORR_BARPLOT=False,\n",
    "    SAVE_COEF_FIGS=False,\n",
    "    fig_name_ftBox=fig_name_ftBox,\n",
    "    fig_name_corrBar=fig_name_corrBar,\n",
    "    fig_path=fig_path,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Prepare prediction arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays per subject based on features and labels\n",
    "\n",
    "importlib.reload(prep_pred_arrs)\n",
    "\n",
    "(X_total, y_total_binary,\n",
    " y_total_scale, sub_ids_total,\n",
    " ft_times_total, ft_names) = prep_pred_arrs.get_group_arrays_for_prediction(\n",
    "    feat_dict=FEATS,\n",
    "    label_dict=FT_LABELS,\n",
    "    CDRS_CODING='binary',  # categorical\n",
    "    CDRS_THRESHOLD=.1,\n",
    "    TO_PLOT = False)\n",
    "\n",
    "# Merge subject-arrays to one group array for prediction\n",
    "(X_all, y_all_binary,\n",
    " y_all_scale, sub_ids,\n",
    " ft_times_all) = prep_pred_arrs.merge_group_arrays(X_total=X_total,\n",
    "                                    y_total_binary=y_total_binary,\n",
    "                                    y_total_scale=y_total_scale,\n",
    "                                    sub_ids_total=sub_ids_total,\n",
    "                                    ft_times_total=ft_times_total)\n",
    "\n",
    "\n",
    "print(f'Subjects included: {np.unique(sub_ids)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gpboost as gpb\n",
    "# performance\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score,\n",
    "    confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay,\n",
    "    auc, roc_curve, RocCurveDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_predict.predict_helpers as predHelpers\n",
    "import lfpecog_plotting.plot_pred_standards as plotPredStd\n",
    "import lfpecog_plotting.plot_pred_standards as plotPred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over predictions with different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ftProc)\n",
    "\n",
    "total_sub_AUC, total_sub_acc = {}, {}\n",
    "total_group_AUC, total_group_acc = {}, {}\n",
    "\n",
    "feat_sources = ['all', 'lfp', 'ecog']\n",
    "feat_bwidths = ['all', 'alpha', 'lo_beta', 'hi_beta', 'gamma']\n",
    "\n",
    "# LOOP OVER BANDWIDTHS AND FT-SOURCES TO INCLUDE\n",
    "for source in feat_sources:\n",
    "    total_sub_AUC[source], total_sub_acc[source] = {}, {}\n",
    "    total_group_AUC[source], total_group_acc[source] = {}, {}\n",
    "    \n",
    "    for bw in feat_bwidths:\n",
    "        print(f'start {source.upper()}, {bw.upper()}')\n",
    "        temp_FEATS = {}\n",
    "        temp_LABELS = {}\n",
    "        # get specified features per subject\n",
    "        for sub in SUBS:\n",
    "            # LOAD MERGED NEUROPHYS FEATURES\n",
    "            temp_FEATS[sub] = ftProc.load_feature_df_for_pred(\n",
    "                sub, INCL_POWER = True, INCL_COH_UNILAT = True,\n",
    "                sel_bandwidths=[bw],\n",
    "                sel_source=source,\n",
    "                settings_json='ftExtr_spectral_v3.json',  # v3 is broadband-flanked SSD\n",
    "                verbose=False,\n",
    "            )\n",
    "            # LOAD CLINICAL SCORES AND CORRESPONDING WINDOW SELECTION\n",
    "            (\n",
    "                select_bool, ecog_related_cdrs\n",
    "            ) = ftProc.find_select_nearest_CDRS_for_ephys(\n",
    "                sub=sub,\n",
    "                ft_times=temp_FEATS[sub].index,\n",
    "                cdrs_rater=CDRS_RATER,\n",
    "            )\n",
    "            # select features and clinical scores to include\n",
    "            temp_FEATS[sub] = temp_FEATS[sub].iloc[select_bool]\n",
    "            temp_LABELS[sub] = ecog_related_cdrs[select_bool]\n",
    "            \n",
    "            \n",
    "        # Merge subject-arrays to one group array for prediction\n",
    "        (X_total, y_total_binary,\n",
    "        y_total_scale, sub_ids_total,\n",
    "        ft_times_total, ft_names) = prep_pred_arrs.get_group_arrays_for_prediction(\n",
    "            feat_dict=temp_FEATS,\n",
    "            label_dict=temp_LABELS,\n",
    "            CDRS_THRESHOLD=.1,\n",
    "            TO_PLOT = False)\n",
    "\n",
    "        (X_all, y_all_binary,\n",
    "        y_all_scale, sub_ids,\n",
    "        ft_times_all) = prep_pred_arrs.merge_group_arrays(\n",
    "            X_total=X_total, y_total_binary=y_total_binary,\n",
    "            y_total_scale=y_total_scale, sub_ids_total=sub_ids_total,\n",
    "            ft_times_total=ft_times_total)\n",
    "\n",
    "        # REAL PREDICTIONS returned per Subject\n",
    "        preds_subs, importances_sub = predHelpers.perform_prediction(\n",
    "            X=X_all.copy(),\n",
    "            y=y_all_binary.copy(),\n",
    "            groups=sub_ids.ravel(),\n",
    "            cv_method=LeaveOneGroupOut,\n",
    "            clf_method='lda',\n",
    "            perform_random_perm = False,\n",
    "            n_perms = 0,\n",
    "            verbose = False,\n",
    "            return_dict_per_sub=True\n",
    "        )\n",
    "        temp_auc_scores, temp_acc_scores = [], []\n",
    "        for sub in preds_subs.keys():\n",
    "            \n",
    "            fpr, tpr, _ = roc_curve(preds_subs[sub]['true'],\n",
    "                                preds_subs[sub]['proba'][:, 1],)\n",
    "            auc_score = round(auc(fpr, tpr), 3)\n",
    "            acc_score = accuracy_score(preds_subs[sub]['true'],\n",
    "                                    preds_subs[sub]['pred'])\n",
    "\n",
    "            temp_auc_scores.append(auc_score)\n",
    "            temp_acc_scores.append(acc_score)\n",
    "\n",
    "        total_sub_AUC[source][bw] = temp_auc_scores\n",
    "        total_sub_acc[source][bw] = temp_acc_scores\n",
    "\n",
    "        \n",
    "        # REAL PREDICT as one merged group\n",
    "        y_true_all, y_pred_all, y_pred_conf_all, importances = predHelpers.perform_prediction(\n",
    "            X=X_all.copy(),\n",
    "            y=y_all_binary.copy(),\n",
    "            groups=sub_ids.ravel(),\n",
    "            cv_method=LeaveOneGroupOut,\n",
    "            clf_method='lda',\n",
    "            perform_random_perm = False,\n",
    "            n_perms = 0,\n",
    "            verbose = True,\n",
    "            ft_names=ft_names\n",
    "        )\n",
    "        fpr, tpr, _ = roc_curve(y_true_all,\n",
    "                                y_pred_conf_all)\n",
    "        auc_score = round(auc(fpr, tpr), 3)\n",
    "        acc_score = accuracy_score(preds_subs[sub]['true'],\n",
    "                                    preds_subs[sub]['pred'])\n",
    "        total_group_AUC[source][bw] = auc_score\n",
    "        total_group_acc[source][bw] = acc_score\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DIFFERENCE LFP AND ALL PREDITIVE OUTCOMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = list(get_colors().values())\n",
    "fsize=18\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# plot sources as different bars\n",
    "# plot ECoG AND STN\n",
    "ax.bar(np.arange(len(feat_bwidths)) - .3,\n",
    "       list(total_group_AUC['all'].values()),\n",
    "       color=clrs[:len(feat_bwidths)],\n",
    "       width=.25, alpha=.75, align='center',)\n",
    "# for legend\n",
    "ax.bar([0], [-1], color='gray', alpha=.8,\n",
    "       label='STN LFP + ECoG',)\n",
    "\n",
    "# plot only ECoG\n",
    "ax.bar(np.arange(len(feat_bwidths)),\n",
    "       list(total_group_AUC['ecog'].values()),\n",
    "       color=clrs[:len(feat_bwidths)],\n",
    "       width=.25, alpha=.75, align='center',\n",
    "       hatch='*',)\n",
    "ax.bar([0], [-1], color='gray', alpha=.8,\n",
    "       label='ECoG only', hatch='*')\n",
    "# plot only STN\n",
    "ax.bar(np.arange(len(feat_bwidths)) + .3,\n",
    "       list(total_group_AUC['lfp'].values()),\n",
    "       color=clrs[:len(feat_bwidths)],\n",
    "       width=.25, alpha=.75, align='center',\n",
    "       hatch='//',)\n",
    "ax.bar([0], [-1], color='gray', alpha=.8,\n",
    "       label='STN LFP only', hatch='//')\n",
    "\n",
    "ax.set_ylim(0 ,1)\n",
    "ax.set_ylabel('Area Under ROC (a.u.)',\n",
    "              fontsize=fsize,)\n",
    "ax.set_xlabel('Feature selection',\n",
    "              fontsize=fsize,)\n",
    "ax.set_xticks(np.arange(len(feat_bwidths)),)\n",
    "ax.set_xticklabels(feat_bwidths,\n",
    "                   fontsize=fsize)\n",
    "\n",
    "ax.legend(fontsize=fsize, ncol=3)\n",
    "ax.set_title('Predictive performance: different feature'\n",
    "             ' frequencies and sources',\n",
    "             fontsize=fsize+4, weight='bold')\n",
    "             \n",
    "plt.tick_params(axis='both', size=fsize,\n",
    "                labelsize=fsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = 'LID_binary_differentFeatSources_AUCs'\n",
    "if SSD_broad_flanks: figname += '_broadbandSSD'\n",
    "figname += f'_n{len(SUBS)}'\n",
    "plt.savefig(os.path.join(figpath, 'prediction', f'n_is_{len(SUBS)}', figname),\n",
    "            facecolor='w', dpi=300,)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'AUCs per subject: {total_sub_AUC}')\n",
    "\n",
    "print(f'AUCs for group: {total_group_AUC}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform single 'best' prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# REAL PREDICT\n",
    "y_true_all, y_pred_all, y_pred_conf_all, importances = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='lda',\n",
    "    perform_random_perm = False,\n",
    "    n_perms = 0,\n",
    "    verbose = True,\n",
    "    ft_names=ft_names\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot mean feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(18, 12))\n",
    "\n",
    "fsize=20\n",
    "\n",
    "sort_idx = np.argsort(np.mean(importances, axis=0))\n",
    "temp_ftnames = plot_ssd_descr.readable_ftnames(ft_names)\n",
    "\n",
    "ax.bar(np.arange(importances.shape[1]),\n",
    "       np.mean(importances, axis=0)[sort_idx],)\n",
    "\n",
    "ax.set_xticks(np.arange(len(ft_names)))\n",
    "ax.set_xticklabels(np.array(temp_ftnames)[sort_idx],\n",
    "                   rotation=60, ha='right', size=fsize)\n",
    "ax.set_ylabel('importances (a.u.)', size=fsize + 8)\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.tick_params(axis='both', size=fsize, labelsize=fsize+2)\n",
    "plt.tight_layout()\n",
    "\n",
    "fname = f'binaryLID_pred_ftImportances_ftsV4_lda'\n",
    "# plt.savefig(os.path.join(figpath, 'prediction', fname),\n",
    "#             facecolor='w', dpi=300,)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# PERMUTATIONS\n",
    "perm_tpr, perm_fpr = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='lda',\n",
    "    perform_random_perm=True,\n",
    "    n_perms=100,\n",
    "    perm_return_ROC=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot AUROC\n",
    "\n",
    "auc_perms = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
    "fs = 18\n",
    "for x_p, y_p in zip(perm_fpr, perm_tpr):\n",
    "    ax.plot(x_p, y_p, alpha=.2, lw=.5, c='k',)\n",
    "    auc_perms.append(auc(x_p, y_p))\n",
    "\n",
    "alpha01 = np.percentile(auc_perms, 99)\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_pred_conf_all,)\n",
    "auc_score = round(auc(fpr, tpr), 2)\n",
    "ax.plot(fpr, tpr, c='darkgreen', lw=2,\n",
    "        label=f'Prediction\\n(AUC: {auc_score})',\n",
    ")\n",
    "ax.plot(0, 0, c='k', label=f'Permutations (n=500)\\nalpha 0.01: {round(alpha01, 2)})')\n",
    "ax.plot([0, 1], [0, 1], lw=3,  c='orange', label='Chance level (50/50)')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=fs, weight='bold',)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=fs, weight='bold',)\n",
    "ax.set_title('Dyskinesia Prediction - Receiver Operator Curve'\n",
    "            '\\nLeave-One-Subject-Out cross-validation',\n",
    "            fontsize=fs)\n",
    "\n",
    "ax.legend(frameon=False, fontsize=fs, loc='lower right')\n",
    "plt.tick_params(axis='both', labelsize=fs)\n",
    "plt.tight_layout()\n",
    "fname = f'Group_LID_PRED_LDA_PowCoh'\n",
    "fname += '_broadbSSD'\n",
    "# plt.savefig(os.path.join(figpath, 'prediction', fname),\n",
    "#             facecolor='w', dpi=300,)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotPred)\n",
    "\n",
    "# Leave-One_subject-Out\n",
    "\n",
    "# show metrics summary\n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "\n",
    "# show confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "cm_figname = 'Group_LID_Pred_LDA_powCoh_confMatrix'\n",
    "# plotPred.plot_confMatrix(cm, fig_path=figpath, fig_name=cm_figname,\n",
    "#                          to_show=False, to_save=True)\n",
    "\n",
    "# show Receiver Operator Cruve\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_pred_conf_all,)\n",
    "auc_score = auc(fpr, tpr)\n",
    "acc_score = accuracy_score(y_true_all, y_pred_all)\n",
    "print(f'AUC: {round(auc_score, 3)}, Accuracy: {round(acc_score, 3)}')\n",
    "# roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show individual prediction course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# REAL PREDICTIONS returned per Subject\n",
    "preds_subs, importances_sub = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(),\n",
    "    y=y_all_binary.copy(),\n",
    "    # y=y_all_scale.copy(),\n",
    "    groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='lda',\n",
    "    perform_random_perm = False,\n",
    "    n_perms = 0,\n",
    "    verbose = False,\n",
    "    return_dict_per_sub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_LID_predictions as plot_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_preds)\n",
    "\n",
    "figname = f'Indiv_scaleLID_predict_lfpPows_{CDRS_RATER}'\n",
    "figname += '_broadbSSD'\n",
    "\n",
    "pred_fig_dir = os.path.join(figpath, 'prediction', ANALYSIS_SIDE.lower(),\n",
    "                            f'ft_version_{FT_VERSION}',\n",
    "                            f'n{len(SUBS)}')\n",
    "\n",
    "plot_preds.plot_sub_gradual_preds(\n",
    "    preds_subs=preds_subs, SUBS=SUBS,\n",
    "    sub_ids=sub_ids,\n",
    "    ft_times_all=ft_times_all,\n",
    "    PLOT_FIG=True,\n",
    "    SAVE_FIG=False,\n",
    "    smooth_pred_samples=10,\n",
    "    fig_name=figname, fig_dir=pred_fig_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(plot_preds)\n",
    "\n",
    "figname = f'Indiv_binLID_predict_v4Set2_{CDRS_RATER}'\n",
    "figname += '_broadbSSD'\n",
    "\n",
    "pred_fig_dir = os.path.join(figpath, 'prediction', ANALYSIS_SIDE.lower(),\n",
    "                            f'ft_version_{FT_VERSION}',\n",
    "                            f'n{len(SUBS)}')\n",
    "\n",
    "plot_preds.plot_sub_binary_preds(\n",
    "    preds_subs=preds_subs, SUBS=SUBS,\n",
    "    sub_ids=sub_ids,\n",
    "    y_all_scale=y_all_scale,\n",
    "    ft_times_all=ft_times_all,\n",
    "    PLOT_FIG=False,\n",
    "    SAVE_FIG=False,\n",
    "    fig_name=figname, fig_dir=pred_fig_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse Movement percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(accDerivs)\n",
    "accs, labels = {}, {}\n",
    "for sub in FT_LABELS.keys():\n",
    "    print(f'start sub {sub}')\n",
    "    accs[sub], labels[sub] = accDerivs.load_acc_and_task(\n",
    "        sub=sub, dataversion='v3.0', resample_freq=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot polar plot movement percentages in binary Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ACT = {}\n",
    "\n",
    "fig, axes = plt.subplots(len(FEATS.keys()), 1,\n",
    "                         figsize=(8, len(FEATS.keys()) * 2))\n",
    "\n",
    "for i_s, sub in enumerate(FEATS.keys()):\n",
    "\n",
    "    sub_preds = preds_subs[sub]['pred']\n",
    "    # if PLOT_PROBA: plot_probas = preds_subs[sub]['proba'][:, 1]\n",
    "    # select labels and times for sub (included in prediction)\n",
    "    sub_sel = sub_ids == sub\n",
    "    sub_cdrs = y_all_scale[sub_sel]  # get CDRS as full scale\n",
    "    sub_LID = y_all_binary[sub_sel]  # get binary LID\n",
    "    sub_fttimes = ft_times_all[sub_sel]\n",
    "\n",
    "    # get accelerometer info\n",
    "    ecog_side = importClin.get_ecog_side(sub=sub)\n",
    "    if ecog_side == 'right': body_side = 'left'\n",
    "    elif ecog_side == 'left': body_side = 'right'\n",
    "\n",
    "    acc_sub = []  # list to store\n",
    "\n",
    "    for t in sub_fttimes:\n",
    "        t = t * 60  # convert to seconds for acc-data\n",
    "        idx_sel = np.logical_and(labels[sub].index.values > t,\n",
    "                                 labels[sub].index.values < (t + WIN_LEN_sec))\n",
    "        act = labels[sub][idx_sel][[f'{body_side}_tap', f'{body_side}_move']]\n",
    "        acc_sub.append(sum(np.max(act, axis=1).values) / act.shape[0] * 100)\n",
    "\n",
    "    ACT[sub] = np.array(acc_sub)\n",
    "\n",
    "    assert len(ACT[sub]) == len(sub_LID) == len(sub_preds), (\n",
    "        f'ACC ({len(ACT[sub])}), feat lengths ({len(sub_LID)})'\n",
    "        f', and pred lengths ({len(sub_preds)}) not equal')\n",
    "    \n",
    "    axes[i_s].plot(acc_sub, label='activitiy %')\n",
    "    axes[i_s].fill_between(x=np.arange(len(sub_LID)), y1=0, y2=10,\n",
    "                     label='true LID binary',\n",
    "                     where=sub_LID, color='orange', alpha=.5,)\n",
    "    axes[i_s].set_title(sub)\n",
    "    axes[i_s].set_ylabel('unilateral activitiy-%')\n",
    "    axes[i_s].set_xlabel(f'{WIN_LEN_sec}s-windows')\n",
    "    axes[i_s].legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "figname = 'indivMovement_vs_BinaryLID'\n",
    "plt.savefig(os.path.join(figpath, 'prediction', figname),\n",
    "        dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = list(get_colors().values())\n",
    "\n",
    "total_act_prc = {'Dyskinesia ABSENT': {'all': [],\n",
    "                                       'predicted present': [],\n",
    "                                       'predicted absent': []},\n",
    "                 'Dyskinesia PRESENT': {'all': [],\n",
    "                                       'predicted present': [],\n",
    "                                       'predicted absent': []}}\n",
    "\n",
    "fig, axes = plt.subplots(len(FEATS.keys()), 2,\n",
    "                         figsize=(8, len(FEATS.keys()) * 3))\n",
    "\n",
    "for i_sub, sub in enumerate(FEATS.keys()):\n",
    "\n",
    "    for LID_BIN, LID_NAME  in enumerate(['Dyskinesia ABSENT', 'Dyskinesia PRESENT']):\n",
    "        sub_sel = sub_ids == sub\n",
    "        sub_LID = y_all_binary[sub_sel]  # get TRUE binary LID\n",
    "        true_lid_mask = sub_LID == LID_BIN\n",
    "        act_only_TRUE_LID_sel = ACT[sub][true_lid_mask]\n",
    "        \n",
    "        axes[i_sub, LID_BIN].hist(act_only_TRUE_LID_sel,\n",
    "                           label=f'all true {LID_NAME}',\n",
    "                           color=clrs[0], alpha=.3,)\n",
    "        total_act_prc[LID_NAME]['all'].extend(act_only_TRUE_LID_sel)  # store in total dict\n",
    "\n",
    "        sub_preds = preds_subs[sub]['pred']  # get PREDICTED binary labels\n",
    "        preds_only_TRUE_LID_sel = sub_preds[true_lid_mask]\n",
    "\n",
    "        \n",
    "        pred_mask = preds_only_TRUE_LID_sel == 1\n",
    "\n",
    "        if True in pred_mask:\n",
    "\n",
    "            axes[i_sub, LID_BIN].hist(act_only_TRUE_LID_sel[~pred_mask],\n",
    "                            label=f'no-LID-predicted',\n",
    "                            color=clrs[5], alpha=.5, align='left',)\n",
    "            total_act_prc[LID_NAME]['predicted absent'].extend(\n",
    "                act_only_TRUE_LID_sel[~pred_mask])  # store in total dict\n",
    "\n",
    "        if False in pred_mask:\n",
    "\n",
    "            axes[i_sub, LID_BIN].hist(act_only_TRUE_LID_sel[pred_mask],\n",
    "                            label=f'LID-predicted',\n",
    "                            color=clrs[2], alpha=.5, align='right',)\n",
    "            total_act_prc[LID_NAME]['predicted present'].extend(\n",
    "                act_only_TRUE_LID_sel[pred_mask])  # store in total dict\n",
    "                \n",
    "        axes[i_sub, LID_BIN].set_title(f'sub-{sub}: expert-rated {LID_NAME}')\n",
    "        axes[i_sub, LID_BIN].set_ylabel('observations')\n",
    "        axes[i_sub, LID_BIN].set_xlabel('Activity per window (%)')\n",
    "        axes[i_sub, LID_BIN].legend()\n",
    "    \n",
    "plt.tight_layout()  \n",
    "\n",
    "\n",
    "figname = 'binaryLID_pred_INDIVmovementDistribution'\n",
    "plt.savefig(os.path.join(figpath, 'prediction', figname),\n",
    "            dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for LID_BIN, LID_NAME  in enumerate(['Dyskinesia ABSENT', 'Dyskinesia PRESENT']):\n",
    "    \n",
    "    axes[LID_BIN].hist(total_act_prc[LID_NAME]['all'],\n",
    "                        label=f'all true {LID_NAME}',\n",
    "                        color=clrs[0], alpha=.3,)\n",
    "    \n",
    "    for i2, PRED_NAME in enumerate(['predicted absent', 'predicted present']):\n",
    "        aligns = ['left', 'right']\n",
    "        axes[LID_BIN].hist(total_act_prc[LID_NAME][PRED_NAME],\n",
    "                            label=PRED_NAME,\n",
    "                            color=clrs[5-i2*3], alpha=.5, align=aligns[i2],)\n",
    "    \n",
    "    axes[LID_BIN].set_title(f'expert-rated {LID_NAME}')\n",
    "    axes[LID_BIN].set_ylabel('observations')\n",
    "    axes[LID_BIN].set_xlabel('Activity per window (%)')\n",
    "    axes[LID_BIN].legend()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polar plot for mvoement distribution during LID and true/false predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8),\n",
    "                       subplot_kw={\"projection\": \"polar\"},\n",
    "                       )\n",
    "\n",
    "fontsize = 14\n",
    "false_colors = np.array(clrs)[[0, 2]]\n",
    "correct_colors = np.array(clrs)[[3, 5]]\n",
    "\n",
    "\n",
    "for LID_BIN, TRUE_LID_NAME  in enumerate(['Dyskinesia ABSENT',\n",
    "                                          'Dyskinesia PRESENT']):\n",
    "    \n",
    "    if 'present' in TRUE_LID_NAME.lower():\n",
    "        preds_correct = total_act_prc[TRUE_LID_NAME]['predicted present']\n",
    "        preds_false = total_act_prc[TRUE_LID_NAME]['predicted absent']\n",
    "    elif 'absent' in TRUE_LID_NAME.lower():\n",
    "        preds_correct = total_act_prc[TRUE_LID_NAME]['predicted absent']\n",
    "        preds_false = total_act_prc[TRUE_LID_NAME]['predicted present']\n",
    "    else:\n",
    "        raise ValueError('no present absent found')\n",
    "\n",
    "    n_bins = len(preds_correct) + len(preds_false)\n",
    "\n",
    "    ANGLES = np.linspace(0, 2 * np.pi, n_bins, endpoint=False) + (np.pi/2)\n",
    "    WIDTH = 2 * np.pi / n_bins\n",
    "\n",
    "    ACT_PRCS = list(preds_correct) + list(preds_false)\n",
    "\n",
    "    axes[LID_BIN].bar(x=ANGLES[:len(preds_correct)],\n",
    "                      height=np.array(preds_correct) + 5, #bottom=-10,\n",
    "                    #   height=sorted(np.array(preds_correct) + 5, reverse=True), #bottom=-10,\n",
    "                      color=false_colors[LID_BIN], alpha=0.8,\n",
    "                      width=WIDTH,\n",
    "                      label=f'preds correct ({round(len(preds_correct)/n_bins*100)}%)')\n",
    "    axes[LID_BIN].bar(x=ANGLES[len(preds_correct):],\n",
    "                      height=np.array(preds_false) + 5, #bottom=-10,  # plus 5 to show zeros\n",
    "                    #   height=sorted(np.array(preds_false) + 5), #bottom=-10,  # plus 5 to show zeros\n",
    "                      color=correct_colors[LID_BIN], alpha=0.8,\n",
    "                      width=WIDTH,\n",
    "                      label=f'preds false ({round(len(preds_false)/n_bins*100)} %)')\n",
    "\n",
    "    axes[LID_BIN].set_ylim(0, 35)\n",
    "    axes[LID_BIN].set_yticks(np.arange(0, 31, 5))\n",
    "    axes[LID_BIN].set_yticklabels([' '] + [f'{y}%' for y in np.arange(0, 26, 5)],\n",
    "                                  fontsize=fontsize)\n",
    "    axes[LID_BIN].set_xticks([])\n",
    "    axes[LID_BIN].set_xticklabels([], )\n",
    "\n",
    "    axes[LID_BIN].set_title(f'{TRUE_LID_NAME} (expert-rated)',\n",
    "                            fontsize=fontsize + 4, weight='bold')\n",
    "    axes[LID_BIN].set_ylabel(f'Activity per {WIN_LEN_sec}s-window (%)',\n",
    "                             fontsize=fontsize + 4)\n",
    "    axes[LID_BIN].legend(fontsize=fontsize + 4,\n",
    "                         frameon=False, ncol=2, loc='upper center',\n",
    "                         bbox_to_anchor=(.5, -.05))\n",
    "\n",
    "    print('plotted', TRUE_LID_NAME)\n",
    "\n",
    "figname = 'binaryLID_pred_movementDistribution'\n",
    "plt.savefig(os.path.join(figpath, 'prediction', figname),\n",
    "            dpi=300, facecolor='w',)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_dysk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
