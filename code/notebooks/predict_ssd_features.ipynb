{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict CDRS based on SSD'd Spectral Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn as sk\n",
    "from scipy import signal, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n",
    "feat_path = os.path.join(projectpath, 'results', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_plotting.expl_plotting as expl_plot\n",
    "import lfpecog_features.feats_spectral_baseline as specBase\n",
    "import lfpecog_features.feats_spectral_features as spectral\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "import lfpecog_analysis.get_acc_derivs as accDerivs\n",
    "\n",
    "\n",
    "from lfpecog_plotting.plotHelpers import remove_duplicate_legend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LEN_sec = 10\n",
    "WIN_OVERLAP_part = 0.0\n",
    "ssd_path = os.path.join(feat_path, 'SSD_powers',\n",
    "                        f'windows_{WIN_LEN_sec}s_'\n",
    "                        f'{WIN_OVERLAP_part}overlap')\n",
    "IGNORE_PTS = ['010', ]\n",
    "\n",
    "LID_SCORE_INCL = 1  # from this score, features are labeled into LID+ group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available subs with features \n",
    "SUBS = list(set([name.split('_')[1] for name in os.listdir(ssd_path)]))\n",
    "\n",
    "for sub in IGNORE_PTS:\n",
    "    SUBS.remove(sub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try:\n",
    "- only include ECoG and ipsilateral STN LFP\n",
    "- exclude moments where was only Dyskinesia in body-side ipsilateral to ECoG (NOT CORRESPONDING WITH ECoG-hemisphere)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Load Clinical Scores\n",
    "\n",
    "Select moments with Dyskinesia at WRONG BODYSIDE (ipsilateral to ECoG) for removal later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = {}\n",
    "ECOG_SIDES = {}\n",
    "REMOVE_TIMES = {}  # remove moments with only 'WRONG SIDE' dyskinesia\n",
    "\n",
    "for sub in SUBS:\n",
    "        # get CDRS\n",
    "        scores_temp = importClin.run_import_clinInfo(sub=sub)\n",
    "                # check if scores are present\n",
    "        if type(scores_temp) == type(None):\n",
    "                print(f'None CDRS-scores loaded for sub {sub}')\n",
    "                continue\n",
    "\n",
    "        # get ECoG-side\n",
    "        ecog_side = importClin.get_ecog_side(sub)\n",
    "        ECOG_SIDES[sub] = ecog_side\n",
    "        # define CDRS of body-side to include\n",
    "        if ecog_side == 'left': LID_side_incl = 'right'\n",
    "        elif ecog_side == 'right': LID_side_incl = 'left'\n",
    "        \n",
    "        # identify minutes to remove bcs only Dyskinesia at none-ECoG side\n",
    "        REMOVE_TIMES[sub] = []\n",
    "        for i, t in enumerate(scores_temp['dopa_time']):\n",
    "                if np.logical_and(scores_temp.iloc[i][f'CDRS_total_{LID_side_incl}'] < 1,\n",
    "                                scores_temp.iloc[i][f'CDRS_total_{ecog_side}'] > 0):\n",
    "                        REMOVE_TIMES[sub].append(t)\n",
    "\n",
    "        # include selected CDRS\n",
    "        SCORES[sub] = scores_temp[['dopa_time', f'CDRS_total_{LID_side_incl}']]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Load Features\n",
    "\n",
    "Only include ECoG and ECoG-sided STN-LFP for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS = {}\n",
    "for sub in SUBS:\n",
    "    ecog_side = ECOG_SIDES[sub]\n",
    "    # load ECog Features\n",
    "    ecog_fts = pd.read_csv(os.path.join(ssd_path, f'SSDfeatures_{sub}_ecog_{ecog_side}.csv'),\n",
    "                            index_col=0, header=0)\n",
    "    # rename and add ECOG to ft-names\n",
    "    rename_cols = {}\n",
    "    for key in ecog_fts.keys(): rename_cols[key] = f'ECOG_{key}'\n",
    "    ecog_fts = ecog_fts.rename(columns=rename_cols)\n",
    "    \n",
    "    # load ECog Features\n",
    "    stn_fts = pd.read_csv(os.path.join(ssd_path, f'SSDfeatures_{sub}_lfp_{ecog_side}.csv'),\n",
    "                            index_col=0, header=0)\n",
    "    # rename and add STN to ft-names\n",
    "    rename_cols = {}\n",
    "    for key in stn_fts.keys(): rename_cols[key] = f'STN_{key}'\n",
    "    stn_fts = stn_fts.rename(columns=rename_cols)\n",
    "\n",
    "    merged_fts = pd.concat([stn_fts, ecog_fts], axis=1, ignore_index=False)\n",
    "    merged_fts.index = merged_fts.index / 60  # convert to minutes to agree with CDRS score\n",
    "    FEATS[sub] = merged_fts\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Prepare Features and Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features to exclude and get CDRS scores to remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ROWS DUE TO DYSKINESIA ONLY (!!) IN NONE-ECOG-SIDE\n",
    "for sub in SUBS:\n",
    "  ft_times = FEATS[sub].index\n",
    "  score_times = SCORES[sub]['dopa_time']\n",
    "\n",
    "  remove_ft_idx = []\n",
    "  # select feature-rows which are closest to a CDRS-moments which should be excluded\n",
    "  for ft_row, t in enumerate(ft_times):\n",
    "      t_diffs = abs(score_times - t)\n",
    "      i = np.argmin(t_diffs)\n",
    "\n",
    "      if score_times[i] in REMOVE_TIMES[sub]:\n",
    "        remove_ft_idx.append(ft_times[i])  \n",
    "          \n",
    "  FEATS[sub] = FEATS[sub].drop(remove_ft_idx, axis=0)\n",
    "  print(f'removed {len(remove_ft_idx)} rows in sub-{sub}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CDRS LABELS FOR FEATURE WINDOW TIMES\n",
    "FT_LABELS = {}\n",
    "\n",
    "for sub in SUBS:\n",
    "    ft_times = FEATS[sub].index\n",
    "\n",
    "    ft_scores = []\n",
    "\n",
    "    for t in ft_times:\n",
    "        t_diffs = abs(SCORES[sub]['dopa_time'] - t)\n",
    "        i = np.argmin(t_diffs)\n",
    "        ft_scores.append(SCORES[sub].iat[i, 1])  # take column 1, is CDRS score\n",
    "\n",
    "    FT_LABELS[sub] = ft_scores\n",
    "\n",
    "    assert FEATS[sub].shape[0] == len(FT_LABELS[sub]), (\n",
    "        'Feature DataFrame and Ft-Labels must have same length'\n",
    "    )\n",
    "# no_LID_sel = np.array(ft_scores) == 0\n",
    "# LID_sel = np.array(ft_scores) >= LID_SCORE_INCL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plotHelpers as pltHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = []\n",
    "y_total_binary = []\n",
    "y_total_scale = []\n",
    "sub_ids_total = []\n",
    "ft_times_total = []\n",
    "\n",
    "EXCL_CODE = 99\n",
    "\n",
    "TO_PLOT = False\n",
    "\n",
    "if TO_PLOT:\n",
    "    fig, axes = plt.subplots(len(SUBS), 1, figsize=(12, 16))\n",
    "    fs = 16\n",
    "\n",
    "\n",
    "for i_s, sub in enumerate(SUBS):\n",
    "    # create lists to store values for boxplotting\n",
    "    bp_LID_values_list = []\n",
    "    bp_noLID_values_list = []\n",
    "    bp_keys = []\n",
    "\n",
    "\n",
    "    ### Create Y-labels based on CDRS (FT_LABELS)\n",
    "    no_LID_sel = np.array(FT_LABELS[sub]) == 0\n",
    "    LID_sel = np.array(FT_LABELS[sub]) >= LID_SCORE_INCL\n",
    "\n",
    "    # create binary y-labels\n",
    "    sub_y_bin = []  # y as binary\n",
    "    for noLID, LID in zip(no_LID_sel, LID_sel):\n",
    "        if noLID: sub_y_bin.append(0)\n",
    "        elif LID: sub_y_bin.append(1)\n",
    "        else: sub_y_bin.append(EXCL_CODE)\n",
    "    # add full scaled y-labels\n",
    "    sub_y_scale = FT_LABELS[sub]\n",
    "\n",
    "    # append sub-codes to sub-id list\n",
    "    sub_ids_total.append([sub] * FEATS[sub].shape[0])  # add subject code, as many times as there are feature rows\n",
    "\n",
    "    # add subjects ft-times to list\n",
    "    ft_times_total.append(FEATS[sub].index.values)\n",
    "\n",
    "    ### Create X with standardised Feature-arrays\n",
    "    sub_X = np.zeros_like((FEATS[sub]))\n",
    "\n",
    "    for n_col, ft in enumerate(FEATS[sub].keys()):\n",
    "        values = FEATS[sub].values[:, n_col]\n",
    "        # split values on Dyskinesia\n",
    "        noLID_values = values[no_LID_sel]\n",
    "        LID_values = values[LID_sel]\n",
    "        \n",
    "        # define mean and std of no-LID for Z-SCORE\n",
    "        m = np.nanmean(noLID_values)\n",
    "        sd = np.nanstd(noLID_values)\n",
    "        # Z-SCORE values\n",
    "        Z_LID_values = (LID_values - m) / sd\n",
    "        Z_noLID_values = (noLID_values - m) / sd\n",
    "        Z_ALL_values = (values - m) / sd\n",
    "\n",
    "        # add feat and z-score values to lists for BOXPLOT (WITHOUT NaNs)\n",
    "        bp_LID_values_list.append(list(Z_LID_values[~np.isnan(LID_values)]))\n",
    "        bp_keys.append(ft)\n",
    "\n",
    "        # store all feats for pred-exploration\n",
    "        sub_X[:, n_col] = Z_ALL_values\n",
    "    \n",
    "    X_total.append(sub_X)\n",
    "    y_total_binary.append(sub_y_bin)\n",
    "    y_total_scale.append(sub_y_scale)\n",
    "\n",
    "    if TO_PLOT:\n",
    "        ##### PLOT BOXPLOT OF FEATURES ######\n",
    "        box = axes[i_s].boxplot(bp_LID_values_list)\n",
    "        plt.setp(box['fliers'], color='gray')\n",
    "        # plt.setp(box['whiskers'], color='red')\n",
    "\n",
    "        axes[i_s].axhline(y=0, xmin=0, xmax=24, color='k', alpha=.3)\n",
    "        for y_line in [-2, 2]: axes[i_s].axhline(y=y_line, xmin=0, xmax=24, color='r', alpha=.3)\n",
    "\n",
    "        axes[i_s].set_ylim(-6, 6)\n",
    "        axes[i_s].set_ylabel(f'z-scores\\nvs no-LID (a.u.)', fontsize=fs)\n",
    "        axes[i_s].set_title(f'Sub-{sub} (mean unilat. CDRS '\n",
    "                            f'{round(np.mean(FT_LABELS[sub]), 2)})',\n",
    "                            weight='bold', fontsize=fs)\n",
    "        axes[i_s].set_xticklabels(['mx', 'mn', 'cv'] * int(len(bp_keys) / 3),\n",
    "                                fontsize=fs,)\n",
    "\n",
    "        for side in ['top','right','bottom']:\n",
    "            axes[i_s].spines[side].set_visible(False)\n",
    "\n",
    "        ### fill colors\n",
    "        colors = {\n",
    "            'alpha': 'yellow',\n",
    "            'lo_beta': 'lightblue',\n",
    "            'hi_beta': 'darkblue',\n",
    "            'midgamma': 'green'\n",
    "        }\n",
    "        hatches = {\n",
    "            'STN': '',\n",
    "            'ECoG': '//'\n",
    "        }\n",
    "\n",
    "        x_fill_list = []\n",
    "        for x1 in np.arange(.5, len(bp_keys) + .5, 3):\n",
    "            x2 = x1 + 3\n",
    "            x_fill_list.append([x1, x2])\n",
    "\n",
    "        for i_x, (src, bw) in  enumerate(product(hatches.keys(), colors.keys())):\n",
    "            axes[i_s].fill_betweenx(\n",
    "                y=np.arange(-6, 6), x1=x_fill_list[i_x][0],\n",
    "                x2=x_fill_list[i_x][1], color=colors[bw], hatch=hatches[src],\n",
    "                label=f'{src} {bw}', alpha=.2, edgecolor='gray',)\n",
    "if TO_PLOT:\n",
    "    leg_content = plt.gca().get_legend_handles_labels()\n",
    "    handles, labels = pltHelp.remove_duplicate_legend(leg_content)\n",
    "    plt.legend(handles, labels, ncol=4, frameon=False,\n",
    "            loc='upper center', bbox_to_anchor=(0.5, -0.2),fancybox=False,\n",
    "            prop={'weight': 'bold', 'size': fs})\n",
    "\n",
    "    plt.suptitle('Individual Feature values during Dyskinesia\\n', weight='bold', fontsize=fs+4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    figname = 'LID_ssdFeatures_boxplots_indiv'\n",
    "    # plt.savefig(os.path.join(figpath, 'ft_exploration', 'SSD', figname),\n",
    "    #             dpi=300, facecolor='w',)\n",
    "    plt.close()\n",
    "\n",
    "print(f'FEATURES X-AXIS: {bp_keys}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all features and labels per Subject together\n",
    "for i, (X_sub, y_sub) in enumerate(zip(X_total, y_total_binary)):\n",
    "    # loop over list with arrays of feats and labels per subject\n",
    "\n",
    "    if i == 0:\n",
    "        X_all = X_sub.copy()\n",
    "        y_all_binary = y_sub.copy()\n",
    "        y_all_scale = y_total_scale[i].copy()\n",
    "        sub_ids = sub_ids_total[i].copy()\n",
    "        ft_times_all = list(ft_times_total[i].copy())\n",
    "\n",
    "    else:\n",
    "        X_all = np.concatenate([X_all, X_sub], axis=0)\n",
    "        y_all_binary.extend(y_sub)\n",
    "        y_all_scale.extend(y_total_scale[i])\n",
    "        sub_ids.extend(sub_ids_total[i])\n",
    "        ft_times_all.extend(ft_times_total[i])\n",
    "\n",
    "y_all_binary = np.atleast_2d(y_all_binary).T\n",
    "y_all_scale = np.atleast_2d(y_all_scale).T\n",
    "sub_ids = np.atleast_2d(sub_ids).T\n",
    "ft_times_all = np.atleast_2d(ft_times_all).T\n",
    "\n",
    "# remove all Rows containing NaN Features\n",
    "nan_row_sel = np.isnan(X_all).any(axis=1)\n",
    "X_all = X_all[~nan_row_sel]\n",
    "y_all_binary = y_all_binary[~nan_row_sel]\n",
    "y_all_scale = y_all_scale[~nan_row_sel]\n",
    "sub_ids = sub_ids[~nan_row_sel]\n",
    "ft_times_all = ft_times_all[~nan_row_sel]\n",
    "\n",
    "# remove all rows not belonging to defined two outcome classes\n",
    "# (for example: if 0 is CDRS=0, and 1 is CDRS>=3, then CDRS scores 1 and 2 are excluded)\n",
    "excl_score_sel = y_all_binary == EXCL_CODE\n",
    "\n",
    "X_all = X_all[~excl_score_sel.ravel()]\n",
    "y_all_binary = y_all_binary[~excl_score_sel]\n",
    "y_all_scale = y_all_scale[~excl_score_sel]\n",
    "sub_ids = sub_ids[~excl_score_sel]\n",
    "ft_times_all = ft_times_all[~excl_score_sel]\n",
    "\n",
    "# X_all contains n-windows, n-features\n",
    "# y_all contains y-values (n-windows)\n",
    "# sub_ids contains subject-codes corresponding to windows (n-windows)\n",
    "print(X_all.shape, y_all_binary.shape, y_all_scale.shape,\n",
    "      sub_ids.shape, ft_times_all.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Explore prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# performance\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay,\n",
    "    auc, roc_curve, RocCurveDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all.copy()\n",
    "y = y_all_binary.copy()\n",
    "groups = sub_ids.ravel()\n",
    "\n",
    "# cv_method = StratifiedKFold\n",
    "cv_method = LeaveOneGroupOut\n",
    "\n",
    "n_folds = 5\n",
    "clf_method = 'logreg'\n",
    "random_state = 42\n",
    "random_perm = False\n",
    "\n",
    "verbose = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_predict.predict_helpers as predHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# REAL PREDICT\n",
    "y_true_all, y_pred_all, y_pred_conf_all = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='logreg',\n",
    "    perform_random_perm = False,\n",
    "    n_perms = 0,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# PERMUTATIONS\n",
    "perm_tpr, perm_fpr = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='logreg',\n",
    "    perform_random_perm=True,\n",
    "    n_perms=500,\n",
    "    perm_return_ROC=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "auc_perms = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
    "fs = 14\n",
    "for x_p, y_p in zip(perm_fpr, perm_tpr):\n",
    "    ax.plot(x_p, y_p, alpha=.2, lw=.5, c='k',)\n",
    "    auc_perms.append(auc(x_p, y_p))\n",
    "\n",
    "alpha01 = np.percentile(auc_perms, 99)\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_pred_conf_all,)\n",
    "auc_score = round(auc(fpr, tpr), 2)\n",
    "ax.plot(fpr, tpr, c='darkgreen', lw=2,\n",
    "        label=f'Real Predicted (AUC: {auc_score})',\n",
    ")\n",
    "ax.plot(0, 0, c='k', label=f'Permutations\\n(n=500, alpha 0.01: {round(alpha01, 3)})')\n",
    "ax.plot([0, 1], [0, 1], lw=3,  c='orange', label='Chance level (50/50)')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=fs, weight='bold',)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=fs, weight='bold',)\n",
    "ax.set_title('Dyskinesia Prediction - Receiver Operator Curve'\n",
    "            '\\nLeave-One-Subject-Out Cross-Validation',\n",
    "            fontsize=fs)\n",
    "\n",
    "ax.legend(frameon=False, fontsize=fs)\n",
    "plt.tick_params(axis='both', labelsize=fs)\n",
    "plt.tight_layout()\n",
    "# fname = f'Group_LID_PRED_MDS23'\n",
    "# plt.savefig(os.path.join(figpath, 'prediction', fname),\n",
    "#             facecolor='w', dpi=300,)\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_pred_standards as plotPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One_subject-Out\n",
    "\n",
    "# show metrics summary\n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "\n",
    "# show confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "cm_figname = ''\n",
    "plotPred.plot_confMatrix(cm, fig_path=figpath, fig_name=cm_figname,\n",
    "                         to_show=False, to_save=False)\n",
    "\n",
    "# show Receiver Operator Cruve\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_pred_conf_all,)\n",
    "# roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show individual prediction course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# REAL PREDICTIONS returned per Subject\n",
    "preds_subs = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='logreg',\n",
    "    perform_random_perm = False,\n",
    "    n_perms = 0,\n",
    "    verbose = False,\n",
    "    return_dict_per_sub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PROBA = False\n",
    "\n",
    "fig, axes = plt.subplots(len(SUBS), 1, figsize=(8, 12))\n",
    "fs = 14\n",
    "for i_s, sub in enumerate(SUBS):\n",
    "    handles, labels = [], []\n",
    "\n",
    "    plot_preds = preds_subs[sub]['pred']\n",
    "    if PLOT_PROBA: plot_probas = preds_subs[sub]['proba'][:, 1]\n",
    "    sub_sel = sub_ids == sub\n",
    "    plot_cdrs = y_all_scale[sub_sel]  # get CDRS as full scale\n",
    "    plot_fttimes = ft_times_all[sub_sel]\n",
    "    assert len(plot_preds) == len(plot_cdrs), (\n",
    "        '# predictions and # scores not equal'\n",
    "    )\n",
    "\n",
    "    ymax = max(plot_cdrs)\n",
    "    if ymax == 0: ymax = 1\n",
    "    \n",
    "    # fill moments where LID was predicted\n",
    "    axes[i_s].fill_between(plot_fttimes,\n",
    "                           y1=-0, y2=ymax,\n",
    "                           where=plot_preds == 1, alpha=.4,\n",
    "                           label='Dyskinesia predicted')\n",
    "    # plot probabilities of prediction\n",
    "    if PLOT_PROBA:\n",
    "        ax2 = axes[i_s].twinx()  # create second y-axis for probabilities\n",
    "        ax2.plot(plot_fttimes, plot_probas, lw=.8, color='purple',\n",
    "                alpha=.8, label='Predicted probability')\n",
    "        ax2.set_ylim(0, 1)\n",
    "        ax2.set_ylabel('Predicted\\nprobability', fontsize=fs, weight='bold',)\n",
    "        ax2.tick_params(axis='both', labelsize=fs, size=fs,)\n",
    "        for side in ['top',]:\n",
    "            ax2.spines[side].set_visible(False)\n",
    "        hnd, lab = ax2.get_legend_handles_labels()\n",
    "        handles.extend(list(hnd))\n",
    "        labels.extend(list(lab))\n",
    "\n",
    "    # plot CDRS as full scale\n",
    "    axes[i_s].plot(plot_fttimes, plot_cdrs, lw=3, color='green',\n",
    "                      label='Real CDRS (unilat.)')\n",
    "\n",
    "    axes[i_s].set_title(f'sub-{sub}', weight='bold', fontsize=fs)\n",
    "    axes[i_s].set_xlabel('Time (minutes vs L-Dopa intake)',\n",
    "                         fontsize=fs, )\n",
    "    axes[i_s].set_ylabel('Dyskinesia\\n(CDRS)',\n",
    "                         fontsize=fs, weight='bold',)\n",
    "    hnd, lab = axes[i_s].get_legend_handles_labels()\n",
    "    handles.extend(list(hnd))\n",
    "    labels.extend(list(lab))\n",
    "\n",
    "axes[0].legend(handles, labels, frameon=False,\n",
    "            loc='lower center', bbox_to_anchor=(.5, 1.2),\n",
    "            fancybox=False, shadow=False,\n",
    "            borderaxespad=1, ncol=3,\n",
    "            prop={\n",
    "                # 'weight': 'bold',\n",
    "                'size': fs\n",
    "            }\n",
    ")\n",
    "\n",
    "# plt.suptitle('Individual binary Dyskinesia-Predictions vs CDRS',\n",
    "#             #  weight='bold',\n",
    "#              fontsize=fs+4)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', labelsize=fs, size=fs,)\n",
    "    for side in ['top','right']:\n",
    "        ax.spines[side].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# fname = f'Indiv_binLID_predict_vs_CDRSscale'\n",
    "# plt.savefig(os.path.join(figpath, 'prediction', fname),\n",
    "#             facecolor='w', dpi=300,)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_dysk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
