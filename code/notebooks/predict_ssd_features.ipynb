{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict CDRS based on SSD'd Spectral Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Load packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import sklearn as sk\n",
    "from scipy import signal, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n",
    "feat_path = os.path.join(projectpath, 'results', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "import utils.utils_windowing as utilsWindows\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "# own data preprocessing functions\n",
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "# own data exploration functions\n",
    "import lfpecog_features.feats_read_proc_data as read_data\n",
    "import lfpecog_plotting.expl_plotting as expl_plot\n",
    "import lfpecog_features.feats_spectral_baseline as specBase\n",
    "import lfpecog_features.feats_spectral_features as spectral\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "\n",
    "\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_analysis.import_ephys_results as importResults\n",
    "import lfpecog_analysis.get_acc_task_derivs as accDerivs\n",
    "\n",
    "import lfpecog_plotting.plotHelpers as pltHelp\n",
    "from lfpecog_plotting.plotHelpers import remove_duplicate_legend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIN_LEN_sec = 10\n",
    "WIN_OVERLAP_part = 0.0\n",
    "ssd_path = os.path.join(feat_path, 'SSD_powers',\n",
    "                        f'windows_{WIN_LEN_sec}s_'\n",
    "                        f'{WIN_OVERLAP_part}overlap')\n",
    "IGNORE_PTS = ['010', ]\n",
    "\n",
    "LID_SCORE_INCL = 1  # from this score, features are labeled into LID+ group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available subs with features \n",
    "SUBS = list(set([name.split('_')[1] for name in os.listdir(ssd_path)]))\n",
    "\n",
    "for sub in IGNORE_PTS:\n",
    "    SUBS.remove(sub)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- only include ECoG and ipsilateral STN LFP\n",
    "- exclude moments where was only Dyskinesia in body-side ipsilateral to ECoG (NOT CORRESPONDING WITH ECoG-hemisphere)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Load Clinical Scores\n",
    "\n",
    "Select moments with Dyskinesia at WRONG BODYSIDE (ipsilateral to ECoG) for removal later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORES = {}\n",
    "# ECOG_SIDES = {}\n",
    "# REMOVE_TIMES = {}  # remove moments with only 'WRONG SIDE' dyskinesia\n",
    "\n",
    "# for sub in SUBS:\n",
    "#         # get CDRS\n",
    "#         scores_temp = importClin.run_import_clinInfo(sub=sub)\n",
    "#                 # check if scores are present\n",
    "#         if type(scores_temp) == type(None):\n",
    "#                 print(f'None CDRS-scores loaded for sub {sub}')\n",
    "#                 continue\n",
    "\n",
    "#         # get ECoG-side\n",
    "#         ecog_side = importClin.get_ecog_side(sub)\n",
    "#         ECOG_SIDES[sub] = ecog_side\n",
    "#         # define CDRS of body-side to include\n",
    "#         if ecog_side == 'left': LID_side_incl = 'right'\n",
    "#         elif ecog_side == 'right': LID_side_incl = 'left'\n",
    "        \n",
    "#         # identify minutes to remove bcs only Dyskinesia at none-ECoG side\n",
    "#         REMOVE_TIMES[sub] = []\n",
    "#         for i, t in enumerate(scores_temp['dopa_time']):\n",
    "#                 if np.logical_and(\n",
    "#                         scores_temp.iloc[i][f'CDRS_total_{LID_side_incl}'] == 0,\n",
    "#                         scores_temp.iloc[i][f'CDRS_total_{ecog_side}'] > 0\n",
    "#                 ):\n",
    "#                         REMOVE_TIMES[sub].append(t)\n",
    "\n",
    "#         # include selected CDRS\n",
    "#         SCORES[sub] = scores_temp[['dopa_time', f'CDRS_total_{LID_side_incl}']]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Load Features\n",
    "\n",
    "Only include ECoG and ECoG-sided STN-LFP for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.load_SSD_features as load_ssdFts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_coh_feats(sub_fts, coh_sides = 'STN_ECOG'):\n",
    "\n",
    "    for i_bw, bw in enumerate(['alpha', 'lo_beta', 'hi_beta', 'narrow_gamma']):\n",
    "\n",
    "        for i_coh, coh_type in enumerate(['sq_coh', 'imag_coh']):\n",
    "            \n",
    "            coh_sel = getattr(sub_fts.coherences, coh_sides)\n",
    "            coh_sel = getattr(coh_sel, bw)\n",
    "            coh_means = getattr(coh_sel, coh_type).mean(axis=1)\n",
    "            coh_maxs = getattr(coh_sel, coh_type).max(axis=1)\n",
    "\n",
    "            if i_bw == i_coh == 0:\n",
    "                coh_values = pd.DataFrame(index=coh_means.index,\n",
    "                                        data=[[coh_means.values,\n",
    "                                                coh_maxs.values]],\n",
    "                                        columns=[f'{coh_type}_{bw}_mn',\n",
    "                                                f'{coh_type}_{bw}_mx'])\n",
    "            else:\n",
    "                new_values = pd.DataFrame(index=coh_means.index,\n",
    "                                        data=[[coh_means.values,\n",
    "                                                coh_maxs.values]],\n",
    "                                        columns=[f'{coh_type}_{bw}_mn',\n",
    "                                                f'{coh_type}_{bw}_mx'])\n",
    "                coh_values = pd.concat([coh_values, new_values],\n",
    "                                    axis=1, ignore_index=False)\n",
    "                \n",
    "    # if necessary: convert to minutes to agree with CDRS score\n",
    "    if max(coh_values.index) > 120: coh_values.index = coh_values.index / 60\n",
    "\n",
    "    return coh_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW LOAD VIA FEATURE CLASS\n",
    "\n",
    "FEATS = {}\n",
    "for sub in SUBS:\n",
    "    # load all features\n",
    "    fts = load_ssdFts.ssdFeatures(sub_list=[sub],)\n",
    "    sub_fts = getattr(fts, f'sub{sub}')\n",
    "    # select ECoG-side power-features\n",
    "    s = importClin.get_ecog_side(sub)\n",
    "    col_sel = [\n",
    "        (f'ecog_{s}' in c or f'lfp_{s}' in c) and\n",
    "        ('peak_freq' not in c and 'broad_gamma' not in c)\n",
    "        for c in list(sub_fts.powers.keys())\n",
    "    ]\n",
    "    power_fts = sub_fts.powers.iloc[:, col_sel]\n",
    "    # if necessary: convert to minutes to agree with CDRS score\n",
    "    if max(power_fts.index) > 120: power_fts.index = power_fts.index / 60\n",
    "    \n",
    "    print(f'\\tsub-{sub}, POWER FEATS SHAPE INCLUDED: {power_fts.shape}')\n",
    "\n",
    "    # LOAD COHERENCES\n",
    "    coh_fts = select_coh_feats(sub_fts=sub_fts, coh_sides='STN_ECOG')\n",
    "    print(f'\\tsub-{sub}, COH FEATS SHAPE INCLUDED: {coh_fts.shape}')\n",
    "    \n",
    "    merged_fts = pd.concat([power_fts, coh_fts], axis=1, ignore_index=False)\n",
    "    print(f'\\tsub-{sub}, MERGED FEATS SHAPE INCLUDED: {merged_fts.shape}')\n",
    "\n",
    "    \n",
    "    FEATS[sub] = merged_fts\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c) Load Scores and Select Feature-Windows to include\n",
    "\n",
    "Exclude feature windows with ONLY dyskinesia present at the NONE-ECoG-corresponding body side"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features to exclude and get CDRS scores to remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection test\n",
    "cdrs_rater = 'Mean'\n",
    "\n",
    "FT_LABELS = {}\n",
    "\n",
    "for sub in SUBS:\n",
    "    ft_times = FEATS[sub].index  # get individual feature-times present\n",
    "    # select features and clinical scores to include\n",
    "    select_bool, ecog_related_cdrs = ftProc.get_idx_discardNonEcogLid(\n",
    "        sub=sub, ft_times=ft_times, cdrs_rater=cdrs_rater,\n",
    "    )\n",
    "    FEATS[sub] = FEATS[sub].iloc[select_bool]\n",
    "    FT_LABELS[sub] = ecog_related_cdrs[select_bool]\n",
    "    \n",
    "    print(f'{sub}: rows delete: {sum(~select_bool)}, '\n",
    "          f'shape post removal: {FEATS[sub].shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_zscored_LID_features(\n",
    "    subs_list: list, X_total: list,\n",
    "    y_total_binary: list, ft_names: list,\n",
    "    TO_SAVE_FIG: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    make boxplots per subject of z-scored\n",
    "    features (only LID) used for prediction\n",
    "\n",
    "    Input:\n",
    "        - subs_list: list with all sub-string codes\n",
    "        - X_total: list with all arrays of all features per subject\n",
    "        - y_total_binary: list with corresponding binary LID-labels\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(len(subs_list), 1, figsize=(12, 16))\n",
    "    fs = 16\n",
    "    ##### PLOT BOXPLOT OF FEATURES ######\n",
    "    for i_s, (sub_fts, sub_y_bin) in enumerate(\n",
    "        zip(X_total, y_total_binary)\n",
    "    ):\n",
    "        sub = subs_list[i_s]\n",
    "        sub_LID_sel = np.array(sub_y_bin).astype(bool)\n",
    "        sub_LID_fts = sub_fts[sub_LID_sel, :]\n",
    "        # make lists for boxplot values (only LID-windows) without NaNs, per features\n",
    "        bp_LID_values_list = [\n",
    "            list(sub_LID_fts[~np.isnan(sub_LID_fts[:, i_ft]), i_ft])\n",
    "            for i_ft in np.arange(sub_LID_fts.shape[1])\n",
    "        ]\n",
    "        box = axes[i_s].boxplot(bp_LID_values_list)\n",
    "        plt.setp(box['fliers'], color='gray')\n",
    "        # plt.setp(box['whiskers'], color='red')\n",
    "\n",
    "        axes[i_s].axhline(y=0, xmin=0, xmax=24, color='k', alpha=.3)\n",
    "        for y_line in [-2, 2]:\n",
    "            axes[i_s].axhline(y=y_line, xmin=0, xmax=24, color='r', alpha=.3)\n",
    "\n",
    "        axes[i_s].set_ylim(-6, 6)\n",
    "        axes[i_s].set_ylabel(f'z-scores\\nvs no-LID (a.u.)', fontsize=fs)\n",
    "        axes[i_s].set_title(f'Sub-{sub} (mean unilat. CDRS '\n",
    "                            f'{round(np.nanmean(FT_LABELS[sub]), 2)})',\n",
    "                            weight='bold', fontsize=fs)\n",
    "        axes[i_s].set_xticklabels(['mx', 'mn', 'cv'] * int(len(ft_names) / 3),\n",
    "                                fontsize=fs,)\n",
    "\n",
    "        for side in ['top','right','bottom']:\n",
    "            axes[i_s].spines[side].set_visible(False)\n",
    "\n",
    "        ### fill colors\n",
    "        colors = {\n",
    "            'alpha': 'yellow',\n",
    "            'lo_beta': 'lightblue',\n",
    "            'hi_beta': 'darkblue',\n",
    "            'midgamma': 'green'\n",
    "        }\n",
    "        hatches = {\n",
    "            'STN': '',\n",
    "            'ECoG': '//'\n",
    "        }\n",
    "\n",
    "        x_fill_list = []\n",
    "        for x1 in np.arange(.5, len(ft_names) + .5, 3):\n",
    "            x2 = x1 + 3\n",
    "            x_fill_list.append([x1, x2])\n",
    "\n",
    "        for i_x, (src, bw) in  enumerate(product(hatches.keys(), colors.keys())):\n",
    "            axes[i_s].fill_betweenx(\n",
    "                y=np.arange(-6, 6), x1=x_fill_list[i_x][0],\n",
    "                x2=x_fill_list[i_x][1], color=colors[bw], hatch=hatches[src],\n",
    "                label=f'{src} {bw}', alpha=.2, edgecolor='gray',)\n",
    "\n",
    "    leg_content = plt.gca().get_legend_handles_labels()\n",
    "    handles, labels = pltHelp.remove_duplicate_legend(leg_content)\n",
    "    plt.legend(handles, labels, ncol=4, frameon=False,\n",
    "            loc='upper center', bbox_to_anchor=(0.5, -0.2),fancybox=False,\n",
    "            prop={'weight': 'bold', 'size': fs})\n",
    "\n",
    "    plt.suptitle('Individual Feature values during Dyskinesia\\n',\n",
    "                 weight='bold', fontsize=fs+4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if TO_SAVE_FIG:\n",
    "        figname = 'LID_ssdFeatures_boxplots_indiv'\n",
    "        plt.savefig(os.path.join(figpath, 'ft_exploration', 'SSD', figname),\n",
    "                    dpi=300, facecolor='w',)\n",
    "    plt.show()\n",
    "\n",
    "    print(f'FEATURES X-AXIS: {ft_names}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDRS_THRESHOLD = .1\n",
    "\n",
    "# create empty list to store individual values for next process part\n",
    "X_total = []\n",
    "y_total_binary = []\n",
    "y_total_scale = []\n",
    "sub_ids_total = []\n",
    "ft_times_total = []\n",
    "\n",
    "EXCL_CODE = 99\n",
    "\n",
    "TO_PLOT = False\n",
    "\n",
    "for i_s, sub in enumerate(SUBS):\n",
    "    ft_names = []\n",
    "\n",
    "    ### Create Y-labels based on CDRS (FT_LABELS)\n",
    "    no_LID_sel = np.array(FT_LABELS[sub]) == 0\n",
    "    LID_sel = np.array(FT_LABELS[sub]) >= CDRS_THRESHOLD\n",
    "\n",
    "    # create binary y-labels\n",
    "    sub_y_bin = []  # y as binary\n",
    "    for noLID, LID in zip(no_LID_sel, LID_sel):\n",
    "        if noLID: sub_y_bin.append(0)\n",
    "        elif LID: sub_y_bin.append(1)\n",
    "        else: sub_y_bin.append(EXCL_CODE)\n",
    "    # add full scaled y-labels\n",
    "    sub_y_scale = FT_LABELS[sub]\n",
    "    # append sub-codes to sub-id list (for later identifying subjects)\n",
    "    sub_ids_total.append([sub] * FEATS[sub].shape[0])  # add subject code, as many times as there are feature rows\n",
    "    # add subjects ft-times to list (for later plotting)\n",
    "    ft_times_total.append(FEATS[sub].index.values)\n",
    "    ### Create X with standardised Feature-arrays\n",
    "    sub_X = np.zeros_like((FEATS[sub]))\n",
    "\n",
    "    for n_col, ft in enumerate(FEATS[sub].keys()):\n",
    "        print(sub, ft)\n",
    "        ft_names.append(ft)\n",
    "        values = FEATS[sub].values[:, n_col]\n",
    "        # Z-score values based NO-LID mean and std\n",
    "        noLID_values = values[no_LID_sel]\n",
    "        m = np.nanmean(noLID_values)\n",
    "        sd = np.nanstd(noLID_values)\n",
    "        Z_ALL_values = (values - m) / sd\n",
    "        sub_X[:, n_col] = Z_ALL_values  # store all feats for pred-exploration\n",
    "        \n",
    "    # add subject values to total lists\n",
    "    X_total.append(sub_X)\n",
    "    y_total_binary.append(sub_y_bin)\n",
    "    y_total_scale.append(sub_y_scale)\n",
    "\n",
    "if TO_PLOT:\n",
    "    boxplot_zscored_LID_features(\n",
    "        subs_list=SUBS, X_total=X_total,\n",
    "        y_total_binary=y_total_binary,\n",
    "        ft_names=ft_names,\n",
    "        TO_SAVE_FIG=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all features and labels per Subject together\n",
    "for i, (X_sub, y_sub) in enumerate(zip(X_total, y_total_binary)):\n",
    "    # loop over list with arrays of feats and labels per subject\n",
    "\n",
    "    if i == 0:\n",
    "        X_all = X_sub.copy()\n",
    "        y_all_binary = y_sub.copy()\n",
    "        y_all_scale = list(y_total_scale[i].copy())\n",
    "        sub_ids = list(sub_ids_total[i].copy())\n",
    "        ft_times_all = list(ft_times_total[i].copy())\n",
    "\n",
    "    else:\n",
    "        X_all = np.concatenate([X_all, X_sub], axis=0)\n",
    "        y_all_binary.extend(y_sub)\n",
    "        y_all_scale.extend(y_total_scale[i])\n",
    "        sub_ids.extend(sub_ids_total[i])\n",
    "        ft_times_all.extend(ft_times_total[i])\n",
    "\n",
    "y_all_binary = np.atleast_2d(y_all_binary).T\n",
    "y_all_scale = np.atleast_2d(y_all_scale).T\n",
    "sub_ids = np.atleast_2d(sub_ids).T\n",
    "ft_times_all = np.atleast_2d(ft_times_all).T\n",
    "\n",
    "# remove all Rows containing NaN Features\n",
    "nan_row_sel = np.isnan(X_all).any(axis=1)\n",
    "X_all = X_all[~nan_row_sel]\n",
    "y_all_binary = y_all_binary[~nan_row_sel]\n",
    "y_all_scale = y_all_scale[~nan_row_sel]\n",
    "sub_ids = sub_ids[~nan_row_sel]\n",
    "ft_times_all = ft_times_all[~nan_row_sel]\n",
    "\n",
    "# remove all rows not belonging to defined two outcome classes\n",
    "# (for example: if 0 is CDRS=0, and 1 is CDRS>=3, then CDRS scores 1 and 2 are excluded)\n",
    "excl_score_sel = y_all_binary == EXCL_CODE\n",
    "\n",
    "X_all = X_all[~excl_score_sel.ravel()]\n",
    "y_all_binary = y_all_binary[~excl_score_sel]\n",
    "y_all_scale = y_all_scale[~excl_score_sel]\n",
    "sub_ids = sub_ids[~excl_score_sel]\n",
    "ft_times_all = ft_times_all[~excl_score_sel]\n",
    "\n",
    "# X_all contains n-windows, n-features\n",
    "# y_all contains y-values (n-windows)\n",
    "# sub_ids contains subject-codes corresponding to windows (n-windows)\n",
    "print(X_all.shape, y_all_binary.shape, y_all_scale.shape,\n",
    "      sub_ids.shape, ft_times_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(X_all, rowvar=False)\n",
    "\n",
    "variances = np.diag(cov_matrix)\n",
    "std_devs = np.sqrt(variances)\n",
    "# scale cov matrix\n",
    "scaled_cov_matrix = cov_matrix / np.outer(std_devs, std_devs)\n",
    "\n",
    "mask = np.abs(scaled_cov_matrix) < .7\n",
    "scaled_cov_matrix[mask] = 0\n",
    "\n",
    "# Plot the covariance matrix\n",
    "plt.imshow(scaled_cov_matrix, cmap='RdYlBu',\n",
    "           vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('Covariance Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Explore prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# performance\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay,\n",
    "    auc, roc_curve, RocCurveDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_all.copy()\n",
    "y = y_all_binary.copy()\n",
    "groups = sub_ids.ravel()\n",
    "\n",
    "# cv_method = StratifiedKFold\n",
    "cv_method = LeaveOneGroupOut\n",
    "\n",
    "n_folds = 5\n",
    "clf_method = 'logreg'\n",
    "random_state = 42\n",
    "random_perm = False\n",
    "\n",
    "verbose = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_predict.predict_helpers as predHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# REAL PREDICT\n",
    "y_true_all, y_pred_all, y_pred_conf_all = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='logreg',\n",
    "    perform_random_perm = False,\n",
    "    n_perms = 0,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# PERMUTATIONS\n",
    "perm_tpr, perm_fpr = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='logreg',\n",
    "    perform_random_perm=True,\n",
    "    n_perms=100,\n",
    "    perm_return_ROC=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "auc_perms = []\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
    "fs = 14\n",
    "for x_p, y_p in zip(perm_fpr, perm_tpr):\n",
    "    ax.plot(x_p, y_p, alpha=.2, lw=.5, c='k',)\n",
    "    auc_perms.append(auc(x_p, y_p))\n",
    "\n",
    "alpha01 = np.percentile(auc_perms, 99)\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_pred_conf_all,)\n",
    "auc_score = round(auc(fpr, tpr), 2)\n",
    "ax.plot(fpr, tpr, c='darkgreen', lw=2,\n",
    "        label=f'Real Predicted (AUC: {auc_score})',\n",
    ")\n",
    "ax.plot(0, 0, c='k', label=f'Permutations\\n(n=500, alpha 0.01: {round(alpha01, 3)})')\n",
    "ax.plot([0, 1], [0, 1], lw=3,  c='orange', label='Chance level (50/50)')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=fs, weight='bold',)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=fs, weight='bold',)\n",
    "ax.set_title('Dyskinesia Prediction - Receiver Operator Curve'\n",
    "            '\\nLeave-One-Subject-Out Cross-Validation',\n",
    "            fontsize=fs)\n",
    "\n",
    "ax.legend(frameon=False, fontsize=fs)\n",
    "plt.tick_params(axis='both', labelsize=fs)\n",
    "plt.tight_layout()\n",
    "# fname = f'Group_LID_PRED_MDS23'\n",
    "# plt.savefig(os.path.join(figpath, 'prediction', fname),\n",
    "#             facecolor='w', dpi=300,)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_pred_standards as plotPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One_subject-Out\n",
    "\n",
    "# show metrics summary\n",
    "print(classification_report(y_true_all, y_pred_all))\n",
    "\n",
    "# show confusion matrix\n",
    "cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "cm_figname = ''\n",
    "plotPred.plot_confMatrix(cm, fig_path=figpath, fig_name=cm_figname,\n",
    "                         to_show=False, to_save=False)\n",
    "\n",
    "# show Receiver Operator Cruve\n",
    "fpr, tpr, _ = roc_curve(y_true_all, y_pred_conf_all,)\n",
    "# roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show individual prediction course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predHelpers)\n",
    "\n",
    "# REAL PREDICTIONS returned per Subject\n",
    "preds_subs = predHelpers.perform_prediction(\n",
    "    X=X_all.copy(), y=y_all_binary.copy(), groups=sub_ids.ravel(),\n",
    "    cv_method=LeaveOneGroupOut,\n",
    "    clf_method='logreg',\n",
    "    perform_random_perm = False,\n",
    "    n_perms = 0,\n",
    "    verbose = False,\n",
    "    return_dict_per_sub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfpecog_plotting.plotHelpers import get_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_PROBA = False\n",
    "clrs = list(get_colors().values())\n",
    "\n",
    "fig, axes = plt.subplots(len(SUBS), 1, figsize=(8, 12))\n",
    "fs = 14\n",
    "for i_s, sub in enumerate(SUBS):\n",
    "    handles, labels = [], []\n",
    "\n",
    "    plot_preds = preds_subs[sub]['pred']\n",
    "    if PLOT_PROBA: plot_probas = preds_subs[sub]['proba'][:, 1]\n",
    "    sub_sel = sub_ids == sub\n",
    "    plot_cdrs = y_all_scale[sub_sel]  # get CDRS as full scale\n",
    "    plot_fttimes = ft_times_all[sub_sel]\n",
    "    assert len(plot_preds) == len(plot_cdrs), (\n",
    "        '# predictions and # scores not equal'\n",
    "    )\n",
    "\n",
    "    ymax = max(plot_cdrs)\n",
    "    if ymax == 0: ymax = 1\n",
    "    \n",
    "    # fill moments where LID was predicted\n",
    "    axes[i_s].fill_between(plot_fttimes,\n",
    "                           y1=-0, y2=ymax,\n",
    "                           where=plot_preds == 1, alpha=.4,\n",
    "                           color=clrs[1],\n",
    "                           label='LID predicted')\n",
    "    # fill moments where NO LID was predicted\n",
    "    axes[i_s].fill_between(plot_fttimes,\n",
    "                           y1=-0, y2=ymax,\n",
    "                           color=clrs[4],\n",
    "                           where=plot_preds == 0, alpha=.4,\n",
    "                           label='No LID predicted')\n",
    "    \n",
    "    # plot probabilities of prediction\n",
    "    if PLOT_PROBA:\n",
    "        ax2 = axes[i_s].twinx()  # create second y-axis for probabilities\n",
    "        ax2.plot(plot_fttimes, plot_probas, lw=.8, color='purple',\n",
    "                alpha=.8, label='Predicted probability')\n",
    "        ax2.set_ylim(0, 1)\n",
    "        ax2.set_ylabel('Predicted\\nprobability', fontsize=fs, weight='bold',)\n",
    "        ax2.tick_params(axis='both', labelsize=fs, size=fs,)\n",
    "        for side in ['top',]:\n",
    "            ax2.spines[side].set_visible(False)\n",
    "        hnd, lab = ax2.get_legend_handles_labels()\n",
    "        handles.extend(list(hnd))\n",
    "        labels.extend(list(lab))\n",
    "\n",
    "    # plot CDRS as full scale\n",
    "    axes[i_s].plot(plot_fttimes, plot_cdrs, lw=3, color='green',\n",
    "                      label='Real CDRS (unilat.)')\n",
    "\n",
    "    axes[i_s].set_title(f'sub-{sub}', weight='bold', fontsize=fs)\n",
    "    axes[i_s].set_xlabel('Time (minutes vs L-Dopa intake)',\n",
    "                         fontsize=fs, )\n",
    "    axes[i_s].set_ylabel('Dyskinesia\\n(CDRS)',\n",
    "                         fontsize=fs, weight='bold',)\n",
    "    hnd, lab = axes[i_s].get_legend_handles_labels()\n",
    "    handles.extend(list(hnd))\n",
    "    labels.extend(list(lab))\n",
    "\n",
    "axes[0].legend(handles, labels, frameon=False,\n",
    "            loc='lower center', bbox_to_anchor=(.5, 1.2),\n",
    "            fancybox=False, shadow=False,\n",
    "            borderaxespad=1, ncol=3,\n",
    "            prop={\n",
    "                # 'weight': 'bold',\n",
    "                'size': fs\n",
    "            }\n",
    ")\n",
    "\n",
    "# plt.suptitle('Individual binary Dyskinesia-Predictions vs CDRS',\n",
    "#             #  weight='bold',\n",
    "#              fontsize=fs+4)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.tick_params(axis='both', labelsize=fs, size=fs,)\n",
    "    for side in ['top','right']:\n",
    "        ax.spines[side].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "fname = f'Indiv_binLID_predict_vs_CDRSscale_{cdrs_rater}'\n",
    "# plt.savefig(os.path.join(figpath, 'prediction', fname),\n",
    "#             facecolor='w', dpi=300,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_dysk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
