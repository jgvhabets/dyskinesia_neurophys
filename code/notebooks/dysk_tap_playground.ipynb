{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze movement based on Accelerometer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib import __version__ as plt_version\n",
    "from scipy import signal, stats\n",
    "\n",
    "# import datetime as dt\n",
    "# #mne\n",
    "# import mne_bids\n",
    "# import mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "\n",
    "# own functions\n",
    "import lfpecog_features.moveDetection_preprocess as movePrep\n",
    "import lfpecog_features.moveDetection_run as run_tap_detect\n",
    "import lfpecog_features.moveDetection_pausedTapFinder as findTap\n",
    "\n",
    "import lfpecog_analysis.load_SSD_features as load_ssd_fts\n",
    "\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_plotting.plotHelpers as plotHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('matplotlib', plt_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Load pickled acc-data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.movement_psd_analysis as movePSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_version = 'v4.0'\n",
    "main_data_path = os.path.join(get_project_path('data'),\n",
    "                              'merged_sub_data',\n",
    "                              data_version)\n",
    "\n",
    "SUBS = load_ssd_fts.get_avail_ssd_subs(DATA_VERSION=data_version)\n",
    "print(SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for sub in SUBS:\n",
    "\n",
    "    if sub in ['010']: continue\n",
    "    \n",
    "    sub_data_path = os.path.join(main_data_path,\n",
    "                                 f'sub-{sub}')\n",
    "    for side in ['left', 'right']:\n",
    "        if side == 'right': continue\n",
    "\n",
    "        fname = (f'{sub}_mergedData_{data_version}'\n",
    "                f'_acc_{side}.P')\n",
    "\n",
    "        # load Acc-detected movement labels\n",
    "        acc = load_class_pickle(os.path.join(sub_data_path, fname))\n",
    "        print(f'\\t...sub-{sub}: loaded {side} Acc-Pickle')\n",
    "        acc = correct_acc_class(acc)\n",
    "\n",
    "        movePSD.plot_overview_tap_detection(acc, SAVE_FIG=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Load SSD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.get_ssd_data as ssd\n",
    "import lfpecog_analysis.get_SSD_timefreqs as ssd_TimeFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get windowed bands of different dtypes per sub\n",
    "# importlib.reload(ssd)\n",
    "\n",
    "sub = '016'\n",
    "\n",
    "# # call from feats_extract_multivar.py\n",
    "# ssd_017 = ssd.get_subject_SSDs(\n",
    "#     sub=sub,\n",
    "#     incl_stn=True,\n",
    "#     incl_ecog=True,\n",
    "#     ft_setting_fname='ftExtr_spectral_v4.json',)\n",
    "\n",
    "# call from feats_extract_multivar.py\n",
    "ssd_sub = ssd.get_subject_SSDs(\n",
    "    sub=sub,\n",
    "    incl_stn=True,\n",
    "    incl_ecog=False,\n",
    "    ft_setting_fname='ftExtr_spectral_v4.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore ACC-activity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '016'\n",
    "\n",
    "acc = {}\n",
    "\n",
    "sub_data_path = os.path.join(main_data_path,\n",
    "                                 f'sub-{sub}')\n",
    "fname = (f'{sub}_mergedData_{data_version}'\n",
    "            f'_acc_{side}.P')\n",
    "\n",
    "# load Acc-detected movement labels\n",
    "for side in ['left', 'right']:\n",
    "    fname = (f'{sub}_mergedData_{data_version}'\n",
    "                f'_acc_{side}.P')\n",
    "    acc[side] = load_class_pickle(os.path.join(sub_data_path, fname))\n",
    "    # fname = (f'{sub}_mergedData_{data_version}'\n",
    "    #             f'_acc_right.P')\n",
    "    # acc_r = load_class_pickle(os.path.join(sub_data_path, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc['left'].colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tap_kernel(\n",
    "    duration_sec=2, Fs=512,\n",
    "):\n",
    "    # kernel for 017\n",
    "    kernel_pattern = np.array([0, 0, 1, -1, 2, -2, 2, -1, 1, 0, 0])\n",
    "\n",
    "    pad = int((Fs * duration_sec) / len(kernel_pattern))\n",
    "    \n",
    "    kernel = np.array(\n",
    "        [np.linspace(kernel_pattern[i],\n",
    "                     kernel_pattern[i+1], pad)\n",
    "         for i in np.arange(len(kernel_pattern) - 1)]\n",
    "    ).ravel()\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.feats_helper_funcs as ftHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tap_finding_017(acc_l_017):\n",
    "    \"\"\"\n",
    "    custom needed due to restless legs and\n",
    "    very slow hand raising\n",
    "\n",
    "    results in indices and times of taps\n",
    "    with left hand only\n",
    "    Tapping movement starts circa two seconds\n",
    "    before and one second after times\n",
    "\n",
    "    Inputs: \n",
    "        - acc: acc class from pickle acc 017\n",
    "    \"\"\"\n",
    "    fs = int(acc_l_017.fs)\n",
    "\n",
    "    d_og = acc_l_017.data[:, 1]  # 1 because of ACC_L_X\n",
    "    t_og = acc_l_017.times\n",
    "    idx_og = np.arange(len(d_og))\n",
    "    task = acc_l_017.data[:, 4]  # 4 is task column\n",
    "\n",
    "    sel = task == 'tap'\n",
    "\n",
    "    d = d_og[sel]\n",
    "    t = t_og[sel]\n",
    "    idx = idx_og[sel]\n",
    "\n",
    "    THR=.5e-7\n",
    "    peak_idx, peak_props = signal.find_peaks(d, height=THR, distance=int(fs*5))\n",
    "\n",
    "    peak_t = t[peak_idx]\n",
    "    peak_i = idx[peak_idx]\n",
    "\n",
    "    # create boolean positive during tap\n",
    "    tap_bool = np.zeros(len(d_og))\n",
    "    for i in peak_i:\n",
    "        try:\n",
    "            if t_og[i+fs] - t_og[i-(2*fs)] > 3:\n",
    "                tap_bool[i - (2*fs):i] = 1\n",
    "            else: tap_bool[i - (2*fs):i+fs] = 1\n",
    "        except IndexError:\n",
    "            tap_bool[i - (2*fs):i] = 1\n",
    "\n",
    "\n",
    "    # plt.scatter(t[peak_idx], np.ones(len(peak_idx)) * 1e-7,\n",
    "    #             color='red', s=10)\n",
    "\n",
    "    # plt.plot(t_og, d_og, color='green', alpha=.5)\n",
    "\n",
    "    # plt.xlim(14, 15)\n",
    "    # plt.show()\n",
    "\n",
    "    return peak_i, peak_t, tap_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_taps_in_data(\n",
    "    neural_data, neural_times, tap_bool, tap_bool_times,\n",
    "    margin_around_tap_sec=1, neural_fs=2048, return_nontap=False,\n",
    "    move_excl_bool=False, move_excl_times=False,\n",
    "):\n",
    "    assert len(neural_data) == len(neural_times), (\n",
    "        'length neural data and times do not match'\n",
    "    )\n",
    "    assert len(tap_bool) == len(tap_bool_times), (\n",
    "        'length tap_bool and times do not match'\n",
    "    )\n",
    "    # convert to arrays\n",
    "    if isinstance(neural_data, list): neural_data = np.array(neural_data)\n",
    "    if isinstance(neural_times, list): neural_times = np.array(neural_times)\n",
    "\n",
    "    # find tap start end indeices\n",
    "    tap_df = np.diff(tap_bool.astype(int))\n",
    "    tap_starts = np.where(tap_df == 1)[0]  # gives indices\n",
    "    tap_ends = np.where(tap_df == -1)[0]\n",
    "    # convert indices into time (dopa_time seconds)\n",
    "    tap_starts = tap_bool_times[tap_starts]\n",
    "    tap_ends = tap_bool_times[tap_ends]\n",
    "\n",
    "    # create boolean arrays to adjust\n",
    "    data_tap_bool = np.zeros_like(neural_data)  # change to positive during taps\n",
    "    if return_nontap:\n",
    "        data_notap_bool = np.ones_like(neural_data)  # change to negative during tap plus pad\n",
    "        pad_idx = int(margin_around_tap_sec * neural_fs)\n",
    "\n",
    "    for t1, t2 in zip(tap_starts, tap_ends):\n",
    "        # find indices in neural data for tap start and end\n",
    "        i1 = np.argmin(abs(neural_times - t1))\n",
    "        i2 = np.argmin(abs(neural_times - t2))\n",
    "        # set selected time window to positive in bool\n",
    "        data_tap_bool[i1:i2] = 1\n",
    "\n",
    "        if return_nontap:\n",
    "            data_notap_bool[i1 - pad_idx:i2 + pad_idx] = 0\n",
    "\n",
    "    if return_nontap and not isinstance(move_excl_bool, bool):\n",
    "         # find tap start end indeices for CONTRA LAT TAPPING\n",
    "        tap_df = np.diff(move_excl_bool.astype(int))\n",
    "        tap_starts = np.where(tap_df == 1)[0]  # gives indices\n",
    "        tap_ends = np.where(tap_df == -1)[0]\n",
    "        # convert indices into time (dopa_time seconds)\n",
    "        tap_starts = move_excl_times[tap_starts]\n",
    "        tap_ends = move_excl_times[tap_ends]\n",
    "\n",
    "        # set no_tap_bool to negative for contra-taps\n",
    "        for t1, t2 in zip(tap_starts, tap_ends):\n",
    "            # find indices in neural data for tap start and end\n",
    "            i1 = np.argmin(abs(neural_times - t1))\n",
    "            i2 = np.argmin(abs(neural_times - t2))\n",
    "            # set selected time window to negative in bool\n",
    "            data_notap_bool[i1 - pad_idx:i2 + pad_idx] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # select neural data based on bool\n",
    "    tap_data = neural_data[data_tap_bool.astype(bool)]\n",
    "\n",
    "    if return_nontap:\n",
    "        no_tap_data = neural_data[data_notap_bool.astype(bool)]\n",
    "\n",
    "    if not return_nontap: return tap_data\n",
    "    \n",
    "    if return_nontap: return tap_data, no_tap_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excl_specific_task(\n",
    "    data_arr, data_times, task_arr, task_times,\n",
    "    task_to_excl\n",
    "):\n",
    "    # convert to arrays\n",
    "    if isinstance(data_times, list): data_times = np.array(data_times)\n",
    "    if isinstance(task_times, list): task_times = np.array(task_times)\n",
    "    if isinstance(task_arr, list): task_arr = np.array(task_arr)\n",
    "    \n",
    "    task_changes = np.diff((task_arr == task_to_excl).astype(int)) \n",
    "    idx_task_start = np.where(task_changes== 1)[0]\n",
    "    idx_task_end = np.where(task_changes == -1)[0]\n",
    "\n",
    "    t_task_start = task_times[idx_task_start]\n",
    "    t_task_end = task_times[idx_task_end]\n",
    "\n",
    "    # set true to keep, false to exclude\n",
    "    incl_bool = np.ones_like(data_arr)\n",
    "\n",
    "    for t1, t2 in zip(t_task_start, t_task_end):\n",
    "        # find indices in neural data for tap start and end\n",
    "        i1 = np.argmin(abs(data_times - t1))\n",
    "        i2 = np.argmin(abs(data_times - t2))\n",
    "\n",
    "        incl_bool[i1:i2] = 0\n",
    "\n",
    "    # select neural data based on bool\n",
    "    data_arr = data_arr[incl_bool.astype(bool)]\n",
    "    data_times = data_times[incl_bool.astype(bool)]\n",
    "\n",
    "\n",
    "    return data_arr, data_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_sub.lfp_left.delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ssd_TimeFreq)\n",
    "\n",
    "lfp_side = 'lfp_right'\n",
    "acc_side = 'left'\n",
    "acc_contra_side = 'right'\n",
    "\n",
    "# create continuous data timeseries for ssd'd signal\n",
    "cont_sig, sig_times, _ = ssd_TimeFreq.get_cont_ssd_arr(\n",
    "    subSourceSSD=getattr(ssd_sub, lfp_side),\n",
    "    bw='gamma',\n",
    "    winLen_sec=ssd_sub.settings['WIN_LEN_sec'],)\n",
    "\n",
    "# find corresponding tap-times\n",
    "if ssd_sub.sub == '017':\n",
    "    peak_idx, peak_t, tap_bool = custom_tap_finding_017(acc[acc_side])\n",
    "else:\n",
    "    i_col_sidetap = [i for i, c in enumerate(acc[acc_side].colnames)\n",
    "                     if c == f'{acc_side}_tap'][0]\n",
    "    tap_bool = acc[acc_side].data[:, i_col_sidetap]\n",
    "    \n",
    "    # to exclude contralat taps from no-tap (rest)\n",
    "    i_col_contratap = [i for i, c in enumerate(acc[acc_side].colnames)\n",
    "                     if c == f'{acc_contra_side}_tap'][0]\n",
    "    contra_tap_bool = acc[acc_side].data[:, i_col_contratap]\n",
    "\n",
    "    i_move = [i for i, c in enumerate(acc[acc_side].colnames)\n",
    "                     if c == f'{acc_contra_side}_move'][0]\n",
    "    move_bool = np.logical_or(contra_tap_bool, acc[acc_side].data[:, i_move])\n",
    "    \n",
    "    i_move = [i for i, c in enumerate(acc[acc_side].colnames)\n",
    "                     if c == f'{acc_side}_move'][0]\n",
    "    move_bool = np.logical_or(move_bool, acc[acc_side].data[:, i_move])\n",
    "\n",
    "# exclude free-tasks for tap vs rest analysis\n",
    "i_col_task = [i for i, c in enumerate(acc[acc_side].colnames) if c == 'task'][0]\n",
    "cont_sig, sig_times = excl_specific_task(\n",
    "    data_arr=cont_sig,\n",
    "    data_times=sig_times,\n",
    "    task_arr=acc[acc_side].data[:, i_col_task],\n",
    "    task_times=acc[acc_side].times,\n",
    "    task_to_excl='free'\n",
    ")\n",
    "\n",
    "# split data in tap vs no-tap\n",
    "tap_data = select_taps_in_data(\n",
    "    neural_data=cont_sig,\n",
    "    neural_times=sig_times,\n",
    "    tap_bool=tap_bool,\n",
    "    tap_bool_times=acc[acc_side].times,\n",
    "    return_nontap=False,)\n",
    "\n",
    "# split data in tap vs no-tap\n",
    "cont_sig_rest, sig_times_rest = excl_specific_task(\n",
    "    data_arr=cont_sig,\n",
    "    data_times=sig_times,\n",
    "    task_arr=acc[acc_side].data[:, i_col_task],\n",
    "    task_times=acc[acc_side].times,\n",
    "    task_to_excl='tap'\n",
    ")\n",
    "\n",
    "_, no_tap_data = select_taps_in_data(\n",
    "    neural_data=cont_sig_rest,\n",
    "    neural_times=sig_times_rest,\n",
    "    tap_bool=tap_bool,\n",
    "    tap_bool_times=acc[acc_side].times,\n",
    "    return_nontap=True,\n",
    "    move_excl_bool=move_bool,\n",
    "    move_excl_times=acc[acc_side].times,\n",
    "    neural_fs=getattr(ssd_sub, lfp_side).fs,\n",
    "    margin_around_tap_sec=2,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.movement_psd_analysis as movePSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(movePSD)\n",
    "\n",
    "for sub in SUBS:\n",
    "    if sub in ['016', '101', '010', '017']: continue\n",
    "    try:\n",
    "        movePSD.create_sub_movement_psds(sub=sub)\n",
    "    except:\n",
    "        print(f'sub {sub} failed and skipped')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wins = len(no_tap_data) // 2048\n",
    "no_tap_data_wins = no_tap_data[:n_wins*2048].reshape(n_wins, 2048)\n",
    "\n",
    "print(no_tap_data_wins.shape)\n",
    "\n",
    "f, psx = signal.welch(x=no_tap_data_wins, fs=ssd_sub.lfp_left.fs,\n",
    "             nperseg=ssd_sub.lfp_left.fs // 1, axis=1)\n",
    "\n",
    "alpha_wins = np.linspace(0.2, 1, num=psx.shape[0])\n",
    "\n",
    "for r, ps_row in enumerate(psx):\n",
    "    plt.plot(f, ps_row, color='purple', alpha=alpha_wins[r])\n",
    "\n",
    "plt.xlim(4, 98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wins = len(tap_data) // 2048\n",
    "tap_data_wins = tap_data[:n_wins*2048].reshape(n_wins, 2048)\n",
    "\n",
    "print(tap_data_wins.shape)\n",
    "\n",
    "f, psx = signal.welch(x=tap_data_wins, fs=ssd_sub.lfp_left.fs,\n",
    "             nperseg=ssd_sub.lfp_left.fs // 1, axis=1)\n",
    "\n",
    "alpha_wins = np.linspace(0.2, 1, num=psx.shape[0])\n",
    "\n",
    "for r, ps_row in enumerate(psx[:50]):\n",
    "    plt.plot(f, ps_row, color='purple', alpha=alpha_wins[r])\n",
    "\n",
    "plt.xlim(4, 98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tap_data.shape, no_tap_data.shape)\n",
    "\n",
    "\n",
    "f, psx = signal.welch(x=tap_data, fs=ssd_sub.lfp_left.fs,\n",
    "             nperseg=ssd_sub.lfp_left.fs // 1,)\n",
    "\n",
    "plt.plot(f, psx, label='taps')\n",
    "\n",
    "f, psx = signal.welch(x=no_tap_data, fs=ssd_sub.lfp_left.fs,\n",
    "             nperseg=ssd_sub.lfp_left.fs // 1,)\n",
    "\n",
    "plt.plot(f, psx, label='no taps')\n",
    "\n",
    "plt.xlim(4, 98)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tap_data) / 2048, len(no_tap_data) / 2048)\n",
    "\n",
    "\n",
    "f, psx = signal.welch(x=tap_data, fs=ssd_017.lfp_left.fs,\n",
    "             nperseg=ssd_017.lfp_left.fs // 1,)\n",
    "\n",
    "plt.plot(f, psx, label='taps')\n",
    "\n",
    "f, psx = signal.welch(x=no_tap_data, fs=ssd_017.lfp_left.fs,\n",
    "             nperseg=ssd_017.lfp_left.fs // 1,)\n",
    "\n",
    "plt.plot(f, psx, label='no taps')\n",
    "\n",
    "plt.xlim(4, 98)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_list_of_lists(lists_to_unpack):\n",
    "\n",
    "    new_list = [i for j in lists_to_unpack for i in j]\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Import processed dataclass per subject, optionally merge ACC-data into EPHYS-df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import subjectData Classes with alligned preprocessed Data\n",
    "# importlib.reload(read_data)\n",
    "# importlib.reload(add_moveStates)\n",
    "# importlib.reload(findTap)\n",
    "\n",
    "# incl_accStates = True\n",
    "\n",
    "# subData = {}\n",
    "\n",
    "# for sub in ['012', '014']:\n",
    "\n",
    "#     print(f'start {sub}')\n",
    "#     # if sub == '008': continue\n",
    "\n",
    "#     subData[sub] = read_data.subjectData(\n",
    "#         sub=sub,\n",
    "#         data_version='v2.3',\n",
    "#         project_path=projectpath,\n",
    "#     )\n",
    "\n",
    "#     if incl_accStates:\n",
    "        \n",
    "#         accStates = run_tap_detect.runTapDetection(subData[sub])\n",
    "\n",
    "#         for group in subData[sub].dtypes:\n",
    "\n",
    "#             if 'lfp' or 'ecog' in group:\n",
    "\n",
    "#                 print(f'adding acc-states for {sub}: {group}')\n",
    "#                 newdf = add_moveStates.add_detected_acc_states(\n",
    "#                     df=getattr(subData[sub], group).data,\n",
    "#                     detectedMoves=accStates,\n",
    "#                 )\n",
    "#                 getattr(subData[sub], group).data = newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Develop and Visualise Movement State Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run single Acc-State Detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(run_tap_detect)\n",
    "importlib.reload(movePrep)\n",
    "importlib.reload(findTap)\n",
    "\n",
    "taplists = {}\n",
    "for sub in ['012',  '014']:  # '008', '013',\n",
    "    print(sub)\n",
    "    taplists[sub] = run_tap_detect.runTapDetection(subData[sub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Performance of Tap/Move-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fonts=20\n",
    "\n",
    "for sub in list(subData.keys()):\n",
    "\n",
    "    for x0, x1 in zip(\n",
    "        # [9, 42],\n",
    "        # [10, 43]\n",
    "        [5, 37,],\n",
    "        [15, 42]\n",
    "    ):\n",
    "\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "        for s, side in enumerate(['left', 'right']):\n",
    "\n",
    "            acc_df = getattr(subData[sub], f'acc_{side}').data  # per side\n",
    "            fs = getattr(subData[sub], f'acc_{side}').fs\n",
    "\n",
    "            ax = movePrep.find_main_axis(\n",
    "                acc_df.iloc[:, 1:4].values\n",
    "            )\n",
    "            svm = movePrep.signalvectormagn(\n",
    "                acc_df.iloc[:, 1:4].values\n",
    "            )\n",
    "\n",
    "            axes[s].plot(\n",
    "                acc_df['dopa_time'] / 60,\n",
    "                acc_df.iloc[:, ax + 1],\n",
    "                alpha=.4, label='uni-axis'\n",
    "            )\n",
    "            axes[s].plot(\n",
    "                acc_df['dopa_time'] / 60,\n",
    "                movePrep.signalvectormagn(\n",
    "                    acc_df.iloc[:, 1:4].values\n",
    "                ), alpha=.4, label='svm', c='r', ls='dotted',\n",
    "            )\n",
    "\n",
    "            axes[s].scatter(\n",
    "                np.array([l[0] for l in taplists2[sub][f'{side}_tap_t']]) / 60,\n",
    "                [.65e-6] * len(taplists2[sub][f'{side}_tap_t']),\n",
    "                s=50, color='g', label='tap-start',\n",
    "            )\n",
    "            axes[s].scatter(\n",
    "                np.array([l[-1] for l in taplists2[sub][f'{side}_tap_t']]) / 60,\n",
    "                [.6e-6] * len(taplists2[sub][f'{side}_tap_t']),\n",
    "                s=50, color='r', label='tap-end'\n",
    "            )\n",
    "            axes[s].scatter(\n",
    "                np.array([m[0] for m in taplists2[sub][f'{side}_move_t']]) / 60,\n",
    "                [.55e-6] * len(taplists2[sub][f'{side}_move_t']),\n",
    "                s=50, color='orange', label='move-start'\n",
    "            )\n",
    "            axes[s].scatter(\n",
    "                np.array([m[1] for m in taplists2[sub][f'{side}_move_t']]) / 60,\n",
    "                [.5e-6] * len(taplists2[sub][f'{side}_move_t']),\n",
    "                s=50, color='purple', label='move-end'\n",
    "            )\n",
    "\n",
    "            axes[s].set_xlim(x0, x1)\n",
    "            axes[s].set_ylim(-1e-6, 1e-6)\n",
    "            axes[s].set_ylabel(\n",
    "                f'Acceleration\\n{side.upper()}'\n",
    "                    '\\n(g, m/s/s)',\n",
    "                size=fonts\n",
    "            )\n",
    "            axes[s].tick_params(labelsize=fonts - 4)\n",
    "\n",
    "        axes[s].set_xlabel('Time (minutes to L-Dopa intake)', size=fonts)\n",
    "\n",
    "\n",
    "        plt.suptitle(\n",
    "            f'Subject {sub} -  bilateral '\n",
    "            'Movement detection',\n",
    "            x=.1, y=.96, ha='left',\n",
    "            size=fonts+4\n",
    "        )\n",
    "        # remove duplicate legend labels\n",
    "        handles, labels = plotHelp.remove_duplicate_legend(\n",
    "            plt.gca().get_legend_handles_labels()\n",
    "        )\n",
    "\n",
    "        fig.legend(\n",
    "            handles, labels,\n",
    "            frameon=False, fontsize=fonts - 4, ncol=3,\n",
    "            loc='center left', bbox_to_anchor = [.55, .95])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        # plt.savefig(os.path.join(\n",
    "        #     fig_dir, 'tapping_detection',\n",
    "        #     f'sub{sub}_moveDetect_newBorders_min{x0}_{x1}'\n",
    "        # ), dpi=150, facecolor='w',)\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIsualisation Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Video-Movement Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate observed taps in video, integers are seconds\n",
    "# from video start\n",
    "# CAVE: orignal Video-starttime is hour in front\n",
    "# values here are corrected one hour backwards (12->11)\n",
    "# Still the video-time seems to be +/- 3 minutes behind\n",
    "# the acc-neurophys-time\n",
    "taptimes_video = {\n",
    "    'SelfpacedHandTapL_StimOffDopa15': {\n",
    "        'left': [\n",
    "            1154, 1160, 1164, 1169, 1174, 1180, 1185,\n",
    "            1191, 1195, 1201, 1207, 1226, 1238, 1243,\n",
    "            1248, 1253\n",
    "        ],\n",
    "        'right':[\n",
    "            1260, 1264, 1270, 1275, 1281, 1290, 1298,\n",
    "            1303, 1308, 1313, 1320, 1324, 1332, 1339,\n",
    "            1345\n",
    "        ],\n",
    "        'starttime': '2021-11-15 11:29' \n",
    "        # original 11:26 but corrected for mismatching times\n",
    "    },\n",
    "    'SelfpacedHandTapL_StimOffDopa35': {\n",
    "        'left': [\n",
    "            878, 883, 888, 893, 898, 903, 908, 915,\n",
    "            919, 926, 933, 946, 951, 957, 963, 970,\n",
    "            976, 984\n",
    "        ],\n",
    "        'right':[\n",
    "            1000, 1006, 1011, 1017, 1024, 1028, 1035,\n",
    "            1041, 1054, 1060, 1081, 1089, 1097, 1103,\n",
    "            1108\n",
    "        ],\n",
    "        'starttime': '2021-11-15 11:51:01'\n",
    "        # original 11:48 but corrected for mismatching times\n",
    "    },\n",
    "    'SelfpacedHandTapL_StimOffDopa60': {\n",
    "        'left': [\n",
    "            641, 647, 652, 657, 662, 666, 671, 676,\n",
    "            682, 686, 692, 697, 703, 708, 713, 719,\n",
    "        ],\n",
    "        'right':[\n",
    "            726, 730, 734, 740, 746, 751, 756, 761,\n",
    "            768, 773, 779, 784, 792, 797, 801\n",
    "        ],\n",
    "        'starttime': '2021-11-15 12:22:59'  # video S1290007\n",
    "        # original 12:20 but corrected for mismatching times\n",
    "    }\n",
    "}\n",
    "# add timedelta in seconds to start-time of video\n",
    "# CAVE videostarttime is on MINUTE-RESOLUTION\n",
    "# thus will be SECONDS OF FROM ACC-TIMESTAMP\n",
    "for run in taptimes_video:\n",
    "    starttime = pd.Timestamp(taptimes_video[run]['starttime'])\n",
    "    for side in ['left', 'right']:\n",
    "        taptimes_video[run][f'{side}_stamps'] = []\n",
    "        for sec in taptimes_video[run][side]:\n",
    "            delta = pd.Timedelta(sec, 'sec')\n",
    "            taptimes_video[run][f'{side}_stamps'].append(\n",
    "                starttime + delta)\n",
    "\n",
    "# Save annotation dict\n",
    "# deriv_dir = os.path.join(\n",
    "#     projectpath, 'data', 'analysis_derivatives', 'sub-008', 'taps'\n",
    "# )\n",
    "# dict_name = f'008_video_ann_tapruns'\n",
    "# np.save(os.path.join(deriv_dir, dict_name),\n",
    "#         taptimes_video)\n",
    "\n",
    "# # Load annotation dict\n",
    "# video_taps = np.load(os.path.join(deriv_dir, f'{dict_name}.npy'),\n",
    "#                      allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '008'\n",
    "annot_dir = os.path.join(projectpath, f'data/analysis_derivatives/sub-{sub}/taps')\n",
    "testannot = np.load(os.path.join(annot_dir, f'{sub}_video_ann_tapruns.npy'),\n",
    "    allow_pickle=True).item()\n",
    "# testannot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated Acc-based Tap detection incl. plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'SelfpacedHandTapL_StimOffDopa35'\n",
    "sides = ['left', 'right']\n",
    "tap_fig_dir = os.path.join(projectpath, 'figures/tapping_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tap_run)\n",
    "\n",
    "restTest, tapTest, _ = tap_run.runTapDetection(\n",
    "    task='paused', fs=SUB08.runs[run].acc_right_Fs,\n",
    "    leftxyz=[accleft[run][0, :], accleft[run][1, :],\n",
    "    accleft[run][2, :]], rightxyz=[accright[run][0, :],\n",
    "    accright[run][1, :], accright[run][2, :]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main function to perform TapDetection functions\n",
    "    ## make new main-function\n",
    "\n",
    "importlib.reload(Tap2)\n",
    "\n",
    "# accright, accleft = {}, {}\n",
    "# restDict, tapDict, moveDict = {}, {}, {}\n",
    "\n",
    "for run in SUB08.runs_incl[1:]:\n",
    "    print(f'Start RUN: {run}')\n",
    "    fs=SUB08.runs[run].acc_right_Fs\n",
    "    accright[run] = SUB08.runs[run].acc_right_arr[1:, :]\n",
    "    accleft[run] = SUB08.runs[run].acc_left_arr[1:, :]\n",
    "\n",
    "    restDict[run], tapDict[run], moveDict[run] = runTapDetection(\n",
    "        task='paused', fs=SUB08.runs[run].acc_right_Fs,\n",
    "        leftxyz=[accleft[run][0, :], accleft[run][1, :],\n",
    "        accleft[run][2, :]], rightxyz=[accright[run][0, :],\n",
    "        accright[run][1, :], accright[run][2, :]],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (function to be) get runstartTimes (include in RUN CLASS (real and dopa times))\n",
    "deriv_dir = os.path.join(projectpath, 'data/analysis_derivatives')\n",
    "runTimes = pd.read_excel(\n",
    "    os.path.join(deriv_dir, f'sub-{sub}', f'sub{sub}_runsInfo.xlsx'))\n",
    "\n",
    "runStartTimes = {}\n",
    "for run in SUB08.runs_incl:\n",
    "    for row in np.arange(runTimes.shape[0]):\n",
    "        if run[-6:] in runTimes.iloc[row]['filename']:\n",
    "            t = runTimes.iloc[row]['acq_time']\n",
    "            runStartTimes[run] = pd.Timestamp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import and process video-annotated tap-times ###\n",
    "\n",
    "## (function to be) Convert video-annotated tap-stamps\n",
    "## into seconds after tmsi-recording\n",
    "\n",
    "# import annotated taptimes (function to be?)\n",
    "sub = '008'\n",
    "annot_dir = os.path.join(projectpath, f'data/analysis_derivatives/sub-{sub}/taps')\n",
    "tapAnnot = np.load(os.path.join(annot_dir, f'{sub}_video_ann_tapruns.npy'),\n",
    "    allow_pickle=True).item()\n",
    "\n",
    "ann_times = {}\n",
    "tapsAnnot_in_runSecs = {}\n",
    "\n",
    "for run in tapDict.keys():\n",
    "    if 'Tap' not in run: continue\n",
    "\n",
    "    # real-time timestamps of video-annotated taps\n",
    "    dt_string = '%Y-%m-%d %H:%M:%S'\n",
    "    t0 = tapAnnot[run]['starttime']\n",
    "    try:\n",
    "        t0 = dt.datetime.strptime(t0, dt_string)\n",
    "    except ValueError:\n",
    "        t0 = dt.datetime.strptime(t0, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    ann_times[run] = {}\n",
    "    tapsAnnot_in_runSecs[run] = {}\n",
    "\n",
    "    for side in sides:\n",
    "        ann_times[run][side] = [t0 + dt.timedelta(\n",
    "            seconds=t) for t in tapAnnot[run][side]]\n",
    "    # minus video start-time -> time after video-start\n",
    "        tapsAnnot_in_runSecs[run][side] = [\n",
    "            (t - runStartTimes[run]).total_seconds(\n",
    "            ) for t in ann_times[run][side]\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO:\n",
    "# - WHY IS check_Polarity turning the signal falsely?\n",
    "# - Why is tapdetection from TapDopa15 Right empty? \n",
    "    # plot incl peaks and thresholds etc\n",
    "\n",
    "# - include plotting of OTHER MVOEMENTS\n",
    "# - split py function for tapping in several py docs!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create plotting functions for tapping\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "run = list(tapsAnnot_in_runSecs.keys())[2]\n",
    "\n",
    "print(f'Plot Figure for run {run}')\n",
    "# specify x-coordinates of zoomed-in subplots\n",
    "ax1_x1, ax1_x2 = 72, 80\n",
    "ax2_x1, ax2_x2 = 150, 160\n",
    "plot_fname=f'TapDetect_08_{run}'\n",
    "if ax1_x1: plot_fname += f'_zooms_{ax1_x1}_{ax2_x1}'\n",
    "plot_fdir=tap_fig_dir\n",
    "\n",
    "plot_params = {\n",
    "        'left': {\n",
    "            'color': 'b',\n",
    "            'alpha': .6\n",
    "        },\n",
    "        'right': {\n",
    "            'color': 'g',\n",
    "            'alpha': .6\n",
    "        },\n",
    "        'rest': {\n",
    "            'color': 'orange',\n",
    "            'alpha': .3\n",
    "        },\n",
    "        'left_up': {\n",
    "            'color': 'dodgerblue',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'left_down': {\n",
    "            'color': 'cyan',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'left_other': {\n",
    "            'facecolor': 'white',\n",
    "            'edgecolor': 'dodgerblue',\n",
    "            'alpha': .8,\n",
    "            'hatch': '//'\n",
    "        },\n",
    "        'right_up': {\n",
    "            'color': 'forestgreen',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'right_down': {\n",
    "            'color': 'lime',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'right_other': {\n",
    "            'facecolor': 'white',\n",
    "            'edgecolor': 'forestgreen',\n",
    "            'alpha': .8,\n",
    "            'hatch': '//'\n",
    "        }\n",
    "    }\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(16, 12))\n",
    "gs = GridSpec(3, 9, figure=fig)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[:2, :])\n",
    "ax1 = fig.add_subplot(gs[2, :4])\n",
    "ax2 = fig.add_subplot(gs[2, 5:], sharey=ax1)\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "for ax in [ax0, ax1, ax2]:\n",
    "    # Plotting traces\n",
    "    ax.plot(\n",
    "        np.arange(0, accleft[run][1, :].shape[0]) / fs,\n",
    "        accleft[run][1, :], **plot_params['left'],\n",
    "        label='Left ACC-trace',\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(0, accright[run][1, :].shape[0]) / fs,\n",
    "        accright[run][1, :], **plot_params['right'],\n",
    "        label='Right ACC-trace',\n",
    "    )\n",
    "    # Plot bilateral Rest-epochs\n",
    "    for d in restDict[run]:\n",
    "        ax.fill_betweenx(label='Bilat. Rest detected',\n",
    "            y=[-1e-6, 1e-6], x1=restDict[run][d][0],\n",
    "            x2=restDict[run][d][1],\n",
    "            **plot_params['rest'],)\n",
    "\n",
    "    # Plot Tap and other-movem. epochs\n",
    "    for side in ['left', 'right']:\n",
    "        ## plot Taps\n",
    "        for t, tList in enumerate(tapDict[run][side]):\n",
    "            ax.fill_betweenx(\n",
    "                y=[-3e-6, 3e-6],\n",
    "                x1=tList[0], x2=tList[2],\n",
    "                label=f'{side} Up detected',\n",
    "                **plot_params[f'{side}_up'],\n",
    "            )\n",
    "            # ax.scatter(tList[1], )  # plot fastest point\n",
    "            ax.fill_betweenx(\n",
    "                y=[-3e-6, 3e-6],\n",
    "                x1=tList[3], x2=tList[4],\n",
    "                label=f'{side} Down detected',\n",
    "                **plot_params[f'{side}_down'],\n",
    "            )\n",
    "        \n",
    "        ## Plot Other Movement's\n",
    "        for t, tList in enumerate(moveDict[run][side]):\n",
    "            ax.fill_betweenx(\n",
    "                y=[-1e-6, 1e-6],\n",
    "                x1=tList[0], x2=tList[1],\n",
    "                label=f'{side} Other Mov. detected',\n",
    "                **plot_params[f'{side}_other'],\n",
    "            )\n",
    "        \n",
    "        ## Plot Accuracy circles based on video-annotations\n",
    "        vid_circle_pos = tapsAnnot_in_runSecs[run][side]\n",
    "        acc_circle_pos = [t[0] for t in tapDict[run][side]]\n",
    "        ax0.scatter(\n",
    "            vid_circle_pos, [3.5e-6] * len(vid_circle_pos),\n",
    "            s=150, edgecolor='k', facecolor='w', lw=2,\n",
    "            label='Video-annotated Tap', **plot_params['left'],\n",
    "        )\n",
    "        ax0.scatter(\n",
    "            acc_circle_pos, [3.5e-6] * len(acc_circle_pos),\n",
    "            s=120, color=plot_params[side]['color'], alpha=.3,\n",
    "            label=f'Acc-classified Tap {side}'\n",
    "        )\n",
    "        tapAcc_handles, tapAcc_labels = ax0.get_legend_handles_labels()\n",
    "        tapAcc_handles = tapAcc_handles[-3:]\n",
    "        tapAcc_labels = tapAcc_labels[-3:]\n",
    "        ax0.legend(tapAcc_handles, tapAcc_labels,\n",
    "            fontsize=16, ncol=3, frameon=False,\n",
    "            loc='upper center', bbox_to_anchor=(.5, .99))\n",
    "\n",
    "        # plot findpeak dots to optimize algorithm\n",
    "        # posPeaks = signal.find_peaks(\n",
    "        #     accleft[run][1, :],\n",
    "        #     height=np.max(accleft[1, :]) * .5,\n",
    "        #     distance=fs,  # 1 s\n",
    "        # )\n",
    "        # ax.scatter(posPeaks[0] / fs, posPeaks[1]['peak_heights'], c='k')\n",
    "        # posPeaks = signal.find_peaks(\n",
    "        #     accright[run][1, :],\n",
    "        #     height=np.max(accright[1, :]) * .5,\n",
    "        #     distance=fs,  # 1 s\n",
    "        # )\n",
    "        # ax.scatter(posPeaks[0] / fs, posPeaks[1]['peak_heights'], c='gray')\n",
    "        \n",
    "        \n",
    "    # make plots pretty\n",
    "    ax.set_xlabel('Time (sec)', size=20)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=16)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    # helping lines for alforithm finetuning\n",
    "    # ax.axhline(np.median(spos), label='median')\n",
    "    # ax.axhline(np.percentile(spos, 75), label='75-%', ls='dotted')\n",
    "    # ax.axhline(-np.percentile(spos, 75), label='-75-%', color='red', ls='dotted')\n",
    "\n",
    "# make plot pretty\n",
    "for ax in [ax0, ax1]: ax.set_ylabel('Acceleration (m/s/s)', size=20)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "# define zoomed subplots\n",
    "ax1.set_xlim(ax1_x1, ax1_x2)\n",
    "ax2.set_xlim(ax2_x1, ax2_x2)\n",
    "\n",
    "# get rid off duplicate legend labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(\n",
    "    by_label.values(), by_label.keys(),\n",
    "    fontsize=20, frameon=False, ncol=3,\n",
    "    loc='upper left', bbox_to_anchor=(.03, -.01)\n",
    ")\n",
    "plt.suptitle(f'sub008: {run}', x=.8, y=.99,\n",
    "    color='gray', alpha=.8, fontsize=16,)\n",
    "# plt.tight_layout(pad=.1)\n",
    "\n",
    "plt.savefig(os.path.join(plot_fdir, plot_fname),\n",
    "    dpi=150, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING ###\n",
    "## using xyz input and output-indices of pausedTap function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(xEpoch, label='x', alpha=.5, c='blue')\n",
    "ax.plot(yEpoch, label='y', alpha=.8, c='green')\n",
    "ax.plot(zEpoch, label='z', alpha=.5, c='orange')\n",
    "# plot vertical lines at tap-moments\n",
    "for t, tap in enumerate(tapi):\n",
    "    if t == 0:\n",
    "        ax.axvline(tap[0], c='green', ls='dotted', alpha=.5, label='start UP')\n",
    "        ax.axvline(tap[1], c='green', ls='solid', alpha=.5, label='end UP')\n",
    "        ax.axvline(tap[2], c='purple', ls='dotted', alpha=.5, label='start DOWN')\n",
    "        ax.axvline(tap[3], c='purple', ls='solid', alpha=.5, label='end DOWN')\n",
    "    else:\n",
    "        ax.axvline(tap[0], c='green', ls='dotted', alpha=.5,)\n",
    "        ax.axvline(tap[1], c='green', ls='solid', alpha=.5,)\n",
    "        ax.axvline(tap[2], c='purple', ls='dotted', alpha=.5,)\n",
    "        ax.axvline(tap[3], c='purple', ls='solid', alpha=.5,)\n",
    "\n",
    "peaklabel = ['lowPos', 'highPos', 'lowNeg', 'highNeg']\n",
    "peakcol = ['lightgreen', 'green', 'orange', 'r']\n",
    "for p, peaks in enumerate([smallPos, largePos, smallNeg, largeNeg]):\n",
    "    ax.scatter(\n",
    "        peaks[0],\n",
    "        yEpoch[peaks[0]],\n",
    "        label=peaklabel[p],\n",
    "        color=peakcol[p],\n",
    "        s=50,\n",
    "    )\n",
    "\n",
    "for mov in movei:  # check saved otherMovements\n",
    "    ax.axvline(mov[0], color='gray', lw=1, ls='dotted')\n",
    "    ax.axvline(mov[-1], color='gray', lw=1)\n",
    "\n",
    "# ax.axhline(-.5e-7)\n",
    "ax.axhline(posThr)\n",
    "ax.axhline(0, c='gray', lw=.5,)\n",
    "# determine what to show\n",
    "ax.set_ylim(-2.5e-6, 2.5e-6)\n",
    "# ax.set_xlim(istart, istop)\n",
    "ax.set_xlim(0, 30000)\n",
    "# ax.set_xticks(np.arange(18600, 20001, 200))\n",
    "# ax.set_xticklabels(np.arange(18600, 20001, 200) // 200)\n",
    "xticks = np.arange(0, len(yEpoch), 6000)\n",
    "xlabs = np.arange(0, len(yEpoch) / 12000, .5)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabs)\n",
    "\n",
    "ax.set_ylabel('Raw Acceleration (m/s/s)', size=14)\n",
    "ax.set_xlabel('Time (minutes)', size=14)\n",
    "\n",
    "ax.set_title(run)\n",
    "\n",
    "# ax.legend(frameon=False, fontsize=14, loc='upper right')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Plot Rest-moments\n",
    "for idx in resti:\n",
    "    ax.fill_betweenx(\n",
    "        y=np.linspace(-3e-6, 3e-6, 5), x1=idx[0], x2=idx[1],\n",
    "        color='blue', alpha=.1,)\n",
    "\n",
    "if to_save:\n",
    "    plt.savefig(\n",
    "        os.path.join(temp_save, 'ACC', f'mountFingerTap_sub08_{run[-6:]}_2'),\n",
    "        dpi=300, facecolor='w',\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "print(f'{run} finisihed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ecog_dysk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
