{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze movement based on Accelerometer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib import __version__ as plt_version\n",
    "from scipy import signal, stats\n",
    "\n",
    "# import datetime as dt\n",
    "# #mne\n",
    "# import mne_bids\n",
    "# import mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "figpath = os.path.join(projectpath, 'figures')\n",
    "datapath = os.path.join(projectpath, 'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(codepath)\n",
    "\n",
    "# own functions\n",
    "import lfpecog_features.moveDetection_preprocess as movePrep\n",
    "import lfpecog_features.moveDetection_run as run_tap_detect\n",
    "import lfpecog_features.moveDetection_pausedTapFinder as findTap\n",
    "\n",
    "import lfpecog_analysis.load_SSD_features as load_ssd_fts\n",
    "\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "from utils.utils_fileManagement import (get_project_path,\n",
    "                                        load_class_pickle,\n",
    "                                        save_class_pickle,\n",
    "                                        mergedData,\n",
    "                                        correct_acc_class)\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_plotting.plotHelpers as plotHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('matplotlib', plt_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Define available Subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.movement_psd_analysis as movePSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['105', '008', '019', '020', '102', '012', '021', '108', '014', '017', '010', '013', '103', '107', '009', '016', '101', '109']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_version = 'v4.0'\n",
    "main_data_path = os.path.join(get_project_path('data'),\n",
    "                              'merged_sub_data',\n",
    "                              data_version)\n",
    "\n",
    "SUBS = load_ssd_fts.get_avail_ssd_subs(DATA_VERSION=data_version)\n",
    "print(SUBS)\n",
    "\n",
    "new_subs = ['107', '020', '108', '109',  '021', '105',]  # '017', '019',\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Load pickled acc-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for sub in SUBS:\n",
    "\n",
    "    if sub in ['010']: continue\n",
    "    \n",
    "    sub_data_path = os.path.join(main_data_path,\n",
    "                                 f'sub-{sub}')\n",
    "    for side in ['left', 'right']:\n",
    "        if side == 'right': continue\n",
    "\n",
    "        fname = (f'{sub}_mergedData_{data_version}'\n",
    "                f'_acc_{side}.P')\n",
    "\n",
    "        # load Acc-detected movement labels\n",
    "        acc = load_class_pickle(os.path.join(sub_data_path, fname))\n",
    "        print(f'\\t...sub-{sub}: loaded {side} Acc-Pickle')\n",
    "        acc = correct_acc_class(acc)\n",
    "\n",
    "        movePSD.plot_overview_tap_detection(acc, SAVE_FIG=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Load SSD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.get_ssd_data as ssd\n",
    "import lfpecog_analysis.get_SSD_timefreqs as ssd_TimeFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get windowed bands of different dtypes per sub\n",
    "# importlib.reload(ssd)\n",
    "\n",
    "sub = '016'\n",
    "\n",
    "# # call from feats_extract_multivar.py\n",
    "# ssd_017 = ssd.get_subject_SSDs(\n",
    "#     sub=sub,\n",
    "#     incl_stn=True,\n",
    "#     incl_ecog=True,\n",
    "#     ft_setting_fname='ftExtr_spectral_v4.json',)\n",
    "\n",
    "# call from feats_extract_multivar.py\n",
    "ssd_sub = ssd.get_subject_SSDs(\n",
    "    sub=sub,\n",
    "    incl_stn=True,\n",
    "    incl_ecog=False,\n",
    "    ft_setting_fname='ftExtr_spectral_v4.json',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explore ACC-activity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '017'\n",
    "\n",
    "acc = {}\n",
    "\n",
    "sub_data_path = os.path.join(main_data_path,\n",
    "                                 f'sub-{sub}')\n",
    "# fname = (f'{sub}_mergedData_{data_version}'\n",
    "#             f'_acc_{side}.P')\n",
    "\n",
    "# load Acc-detected movement labels\n",
    "for side in ['left', 'right']:\n",
    "    fname = (f'{sub}_mergedData_{data_version}'\n",
    "                f'_acc_{side}.P')\n",
    "    acc[side] = load_class_pickle(os.path.join(sub_data_path, fname))\n",
    "    # fname = (f'{sub}_mergedData_{data_version}'\n",
    "    #             f'_acc_right.P')\n",
    "    # acc_r = load_class_pickle(os.path.join(sub_data_path, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore Movement vs PSD analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_features.feats_helper_funcs as ftHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_analysis.movement_psd_analysis as tapPSD\n",
    "import lfpecog_analysis.prep_movement_psd_analysis as prepTapPSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sub-105\n",
      "...\n",
      "SKIP sub-105, all files present\n",
      "start sub-020\n",
      "\t...loaded SSD windowed-data and meta-info for lfp_left of sub-020\n",
      "\t...loaded SSD windowed-data and meta-info for lfp_right of sub-020\n",
      "...\n",
      "SKIP LFP-left, ACC-right (sub-020) (present)\n",
      "...\n",
      "start LFP-right, ACC-left (sub-020)\n",
      "...added tap\n",
      "...added rest no move\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 54.1 MiB for an array with shape (7086080,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\notebooks\\dysk_tap_playground.ipynb Cell 21\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/dysk_tap_playground.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstart sub-\u001b[39m\u001b[39m{\u001b[39;00msub\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/dysk_tap_playground.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/dysk_tap_playground.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m prepTapPSD\u001b[39m.\u001b[39;49mcreate_sub_movement_psds(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/habetsj/Research/projects/dyskinesia_neurophys/code/notebooks/dysk_tap_playground.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     sub\u001b[39m=\u001b[39;49msub, states_to_save\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtap\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrest_no_move\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfree_move\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfree_no_move\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_analysis\\prep_movement_psd_analysis.py:212\u001b[0m, in \u001b[0;36mcreate_sub_movement_psds\u001b[1;34m(sub, data_version, ft_version, states_to_save)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m...added rest no move\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfree_move\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m states_to_save \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfree_no_move\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m states_to_save:\n\u001b[0;32m    211\u001b[0m     \u001b[39m# get no-tap, only rest, no movement data\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     free_lfp_arr, free_sig_times \u001b[39m=\u001b[39m excl_specific_task(\n\u001b[0;32m    213\u001b[0m         data_arr\u001b[39m=\u001b[39;49mlfp_arr\u001b[39m.\u001b[39;49mcopy(),\n\u001b[0;32m    214\u001b[0m         data_times\u001b[39m=\u001b[39;49msig_times\u001b[39m.\u001b[39;49mcopy(),\n\u001b[0;32m    215\u001b[0m         task_arr\u001b[39m=\u001b[39;49macc\u001b[39m.\u001b[39;49mdata[:, i_col_task],\n\u001b[0;32m    216\u001b[0m         task_times\u001b[39m=\u001b[39;49macc\u001b[39m.\u001b[39;49mtimes,\n\u001b[0;32m    217\u001b[0m         task_to_excl\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtap\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrest\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfree_no_move\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m states_to_save:\n\u001b[0;32m    220\u001b[0m         \u001b[39m# excl movement moments (take 2nd return var)\u001b[39;00m\n\u001b[0;32m    221\u001b[0m         _, data_dict[\u001b[39m'\u001b[39m\u001b[39mfreeNoMove\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m select_taps_in_data(\n\u001b[0;32m    222\u001b[0m             neural_data\u001b[39m=\u001b[39mfree_lfp_arr,\n\u001b[0;32m    223\u001b[0m             neural_times\u001b[39m=\u001b[39mfree_sig_times,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m             margin_around_tap_sec\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    231\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\habetsj\\Research\\projects\\dyskinesia_neurophys\\code\\lfpecog_analysis\\prep_movement_psd_analysis.py:278\u001b[0m, in \u001b[0;36mexcl_specific_task\u001b[1;34m(data_arr, data_times, task_arr, task_times, task_to_excl)\u001b[0m\n\u001b[0;32m    274\u001b[0m t_task_end \u001b[39m=\u001b[39m task_times[idx_task_end]\n\u001b[0;32m    276\u001b[0m \u001b[39mfor\u001b[39;00m t1, t2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(t_task_start, t_task_end):\n\u001b[0;32m    277\u001b[0m     \u001b[39m# find indices in neural data for tap start and end\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m     i1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(\u001b[39mabs\u001b[39;49m(data_times \u001b[39m-\u001b[39;49m t1))\n\u001b[0;32m    279\u001b[0m     i2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(\u001b[39mabs\u001b[39m(data_times \u001b[39m-\u001b[39m t2))\n\u001b[0;32m    280\u001b[0m     incl_bool[i1:i2] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 54.1 MiB for an array with shape (7086080,) and data type float64"
     ]
    }
   ],
   "source": [
    "importlib.reload(prepTapPSD)\n",
    "\n",
    "for sub in SUBS:\n",
    "    # TODO:  '010'\n",
    "    # if sub in ['016', '101',]: #continue\n",
    "    if sub in new_subs:\n",
    "\n",
    "        print(f'start sub-{sub}')\n",
    "        # try:\n",
    "        prepTapPSD.create_sub_movement_psds(\n",
    "            sub=sub, states_to_save=['tap', 'rest_no_move', 'free_move', 'free_no_move'])\n",
    "        # except:\n",
    "        #     print(f'sub {sub} failed and skipped')\n",
    "        #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_list_of_lists(lists_to_unpack):\n",
    "\n",
    "    new_list = [i for j in lists_to_unpack for i in j]\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = list(plotHelp.get_colors().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tapPSD)\n",
    "\n",
    "# psd_rest, psd_tap, tap_f = tapPSD.load_movement_psds()\n",
    "state_psds, tap_f = tapPSD.load_movement_psds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_psds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tapPSD)\n",
    "\n",
    "tapPSD.plotPSD_rest_vs_tap(PSDs=state_psds,\n",
    "                           freqs=tap_f,\n",
    "                           data_version=data_version,\n",
    "                           fig_name='STN_PSDs_Tap_vs_Rest_vs_Free_n11'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) Import processed dataclass per subject, optionally merge ACC-data into EPHYS-df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import subjectData Classes with alligned preprocessed Data\n",
    "# importlib.reload(read_data)\n",
    "# importlib.reload(add_moveStates)\n",
    "# importlib.reload(findTap)\n",
    "\n",
    "# incl_accStates = True\n",
    "\n",
    "# subData = {}\n",
    "\n",
    "# for sub in ['012', '014']:\n",
    "\n",
    "#     print(f'start {sub}')\n",
    "#     # if sub == '008': continue\n",
    "\n",
    "#     subData[sub] = read_data.subjectData(\n",
    "#         sub=sub,\n",
    "#         data_version='v2.3',\n",
    "#         project_path=projectpath,\n",
    "#     )\n",
    "\n",
    "#     if incl_accStates:\n",
    "        \n",
    "#         accStates = run_tap_detect.runTapDetection(subData[sub])\n",
    "\n",
    "#         for group in subData[sub].dtypes:\n",
    "\n",
    "#             if 'lfp' or 'ecog' in group:\n",
    "\n",
    "#                 print(f'adding acc-states for {sub}: {group}')\n",
    "#                 newdf = add_moveStates.add_detected_acc_states(\n",
    "#                     df=getattr(subData[sub], group).data,\n",
    "#                     detectedMoves=accStates,\n",
    "#                 )\n",
    "#                 getattr(subData[sub], group).data = newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Develop and Visualise Movement State Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run single Acc-State Detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(run_tap_detect)\n",
    "importlib.reload(movePrep)\n",
    "importlib.reload(findTap)\n",
    "\n",
    "taplists = {}\n",
    "for sub in ['012',  '014']:  # '008', '013',\n",
    "    print(sub)\n",
    "    taplists[sub] = run_tap_detect.runTapDetection(subData[sub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Performance of Tap/Move-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fonts=20\n",
    "\n",
    "for sub in list(subData.keys()):\n",
    "\n",
    "    for x0, x1 in zip(\n",
    "        # [9, 42],\n",
    "        # [10, 43]\n",
    "        [5, 37,],\n",
    "        [15, 42]\n",
    "    ):\n",
    "\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "        for s, side in enumerate(['left', 'right']):\n",
    "\n",
    "            acc_df = getattr(subData[sub], f'acc_{side}').data  # per side\n",
    "            fs = getattr(subData[sub], f'acc_{side}').fs\n",
    "\n",
    "            ax = movePrep.find_main_axis(\n",
    "                acc_df.iloc[:, 1:4].values\n",
    "            )\n",
    "            svm = movePrep.signalvectormagn(\n",
    "                acc_df.iloc[:, 1:4].values\n",
    "            )\n",
    "\n",
    "            axes[s].plot(\n",
    "                acc_df['dopa_time'] / 60,\n",
    "                acc_df.iloc[:, ax + 1],\n",
    "                alpha=.4, label='uni-axis'\n",
    "            )\n",
    "            axes[s].plot(\n",
    "                acc_df['dopa_time'] / 60,\n",
    "                movePrep.signalvectormagn(\n",
    "                    acc_df.iloc[:, 1:4].values\n",
    "                ), alpha=.4, label='svm', c='r', ls='dotted',\n",
    "            )\n",
    "\n",
    "            axes[s].scatter(\n",
    "                np.array([l[0] for l in taplists2[sub][f'{side}_tap_t']]) / 60,\n",
    "                [.65e-6] * len(taplists2[sub][f'{side}_tap_t']),\n",
    "                s=50, color='g', label='tap-start',\n",
    "            )\n",
    "            axes[s].scatter(\n",
    "                np.array([l[-1] for l in taplists2[sub][f'{side}_tap_t']]) / 60,\n",
    "                [.6e-6] * len(taplists2[sub][f'{side}_tap_t']),\n",
    "                s=50, color='r', label='tap-end'\n",
    "            )\n",
    "            axes[s].scatter(\n",
    "                np.array([m[0] for m in taplists2[sub][f'{side}_move_t']]) / 60,\n",
    "                [.55e-6] * len(taplists2[sub][f'{side}_move_t']),\n",
    "                s=50, color='orange', label='move-start'\n",
    "            )\n",
    "            axes[s].scatter(\n",
    "                np.array([m[1] for m in taplists2[sub][f'{side}_move_t']]) / 60,\n",
    "                [.5e-6] * len(taplists2[sub][f'{side}_move_t']),\n",
    "                s=50, color='purple', label='move-end'\n",
    "            )\n",
    "\n",
    "            axes[s].set_xlim(x0, x1)\n",
    "            axes[s].set_ylim(-1e-6, 1e-6)\n",
    "            axes[s].set_ylabel(\n",
    "                f'Acceleration\\n{side.upper()}'\n",
    "                    '\\n(g, m/s/s)',\n",
    "                size=fonts\n",
    "            )\n",
    "            axes[s].tick_params(labelsize=fonts - 4)\n",
    "\n",
    "        axes[s].set_xlabel('Time (minutes to L-Dopa intake)', size=fonts)\n",
    "\n",
    "\n",
    "        plt.suptitle(\n",
    "            f'Subject {sub} -  bilateral '\n",
    "            'Movement detection',\n",
    "            x=.1, y=.96, ha='left',\n",
    "            size=fonts+4\n",
    "        )\n",
    "        # remove duplicate legend labels\n",
    "        handles, labels = plotHelp.remove_duplicate_legend(\n",
    "            plt.gca().get_legend_handles_labels()\n",
    "        )\n",
    "\n",
    "        fig.legend(\n",
    "            handles, labels,\n",
    "            frameon=False, fontsize=fonts - 4, ncol=3,\n",
    "            loc='center left', bbox_to_anchor = [.55, .95])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        # plt.savefig(os.path.join(\n",
    "        #     fig_dir, 'tapping_detection',\n",
    "        #     f'sub{sub}_moveDetect_newBorders_min{x0}_{x1}'\n",
    "        # ), dpi=150, facecolor='w',)\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIsualisation Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Video-Movement Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate observed taps in video, integers are seconds\n",
    "# from video start\n",
    "# CAVE: orignal Video-starttime is hour in front\n",
    "# values here are corrected one hour backwards (12->11)\n",
    "# Still the video-time seems to be +/- 3 minutes behind\n",
    "# the acc-neurophys-time\n",
    "taptimes_video = {\n",
    "    'SelfpacedHandTapL_StimOffDopa15': {\n",
    "        'left': [\n",
    "            1154, 1160, 1164, 1169, 1174, 1180, 1185,\n",
    "            1191, 1195, 1201, 1207, 1226, 1238, 1243,\n",
    "            1248, 1253\n",
    "        ],\n",
    "        'right':[\n",
    "            1260, 1264, 1270, 1275, 1281, 1290, 1298,\n",
    "            1303, 1308, 1313, 1320, 1324, 1332, 1339,\n",
    "            1345\n",
    "        ],\n",
    "        'starttime': '2021-11-15 11:29' \n",
    "        # original 11:26 but corrected for mismatching times\n",
    "    },\n",
    "    'SelfpacedHandTapL_StimOffDopa35': {\n",
    "        'left': [\n",
    "            878, 883, 888, 893, 898, 903, 908, 915,\n",
    "            919, 926, 933, 946, 951, 957, 963, 970,\n",
    "            976, 984\n",
    "        ],\n",
    "        'right':[\n",
    "            1000, 1006, 1011, 1017, 1024, 1028, 1035,\n",
    "            1041, 1054, 1060, 1081, 1089, 1097, 1103,\n",
    "            1108\n",
    "        ],\n",
    "        'starttime': '2021-11-15 11:51:01'\n",
    "        # original 11:48 but corrected for mismatching times\n",
    "    },\n",
    "    'SelfpacedHandTapL_StimOffDopa60': {\n",
    "        'left': [\n",
    "            641, 647, 652, 657, 662, 666, 671, 676,\n",
    "            682, 686, 692, 697, 703, 708, 713, 719,\n",
    "        ],\n",
    "        'right':[\n",
    "            726, 730, 734, 740, 746, 751, 756, 761,\n",
    "            768, 773, 779, 784, 792, 797, 801\n",
    "        ],\n",
    "        'starttime': '2021-11-15 12:22:59'  # video S1290007\n",
    "        # original 12:20 but corrected for mismatching times\n",
    "    }\n",
    "}\n",
    "# add timedelta in seconds to start-time of video\n",
    "# CAVE videostarttime is on MINUTE-RESOLUTION\n",
    "# thus will be SECONDS OF FROM ACC-TIMESTAMP\n",
    "for run in taptimes_video:\n",
    "    starttime = pd.Timestamp(taptimes_video[run]['starttime'])\n",
    "    for side in ['left', 'right']:\n",
    "        taptimes_video[run][f'{side}_stamps'] = []\n",
    "        for sec in taptimes_video[run][side]:\n",
    "            delta = pd.Timedelta(sec, 'sec')\n",
    "            taptimes_video[run][f'{side}_stamps'].append(\n",
    "                starttime + delta)\n",
    "\n",
    "# Save annotation dict\n",
    "# deriv_dir = os.path.join(\n",
    "#     projectpath, 'data', 'analysis_derivatives', 'sub-008', 'taps'\n",
    "# )\n",
    "# dict_name = f'008_video_ann_tapruns'\n",
    "# np.save(os.path.join(deriv_dir, dict_name),\n",
    "#         taptimes_video)\n",
    "\n",
    "# # Load annotation dict\n",
    "# video_taps = np.load(os.path.join(deriv_dir, f'{dict_name}.npy'),\n",
    "#                      allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '008'\n",
    "annot_dir = os.path.join(projectpath, f'data/analysis_derivatives/sub-{sub}/taps')\n",
    "testannot = np.load(os.path.join(annot_dir, f'{sub}_video_ann_tapruns.npy'),\n",
    "    allow_pickle=True).item()\n",
    "# testannot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated Acc-based Tap detection incl. plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'SelfpacedHandTapL_StimOffDopa35'\n",
    "sides = ['left', 'right']\n",
    "tap_fig_dir = os.path.join(projectpath, 'figures/tapping_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tap_run)\n",
    "\n",
    "restTest, tapTest, _ = tap_run.runTapDetection(\n",
    "    task='paused', fs=SUB08.runs[run].acc_right_Fs,\n",
    "    leftxyz=[accleft[run][0, :], accleft[run][1, :],\n",
    "    accleft[run][2, :]], rightxyz=[accright[run][0, :],\n",
    "    accright[run][1, :], accright[run][2, :]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Main function to perform TapDetection functions\n",
    "    ## make new main-function\n",
    "\n",
    "importlib.reload(Tap2)\n",
    "\n",
    "# accright, accleft = {}, {}\n",
    "# restDict, tapDict, moveDict = {}, {}, {}\n",
    "\n",
    "for run in SUB08.runs_incl[1:]:\n",
    "    print(f'Start RUN: {run}')\n",
    "    fs=SUB08.runs[run].acc_right_Fs\n",
    "    accright[run] = SUB08.runs[run].acc_right_arr[1:, :]\n",
    "    accleft[run] = SUB08.runs[run].acc_left_arr[1:, :]\n",
    "\n",
    "    restDict[run], tapDict[run], moveDict[run] = runTapDetection(\n",
    "        task='paused', fs=SUB08.runs[run].acc_right_Fs,\n",
    "        leftxyz=[accleft[run][0, :], accleft[run][1, :],\n",
    "        accleft[run][2, :]], rightxyz=[accright[run][0, :],\n",
    "        accright[run][1, :], accright[run][2, :]],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (function to be) get runstartTimes (include in RUN CLASS (real and dopa times))\n",
    "deriv_dir = os.path.join(projectpath, 'data/analysis_derivatives')\n",
    "runTimes = pd.read_excel(\n",
    "    os.path.join(deriv_dir, f'sub-{sub}', f'sub{sub}_runsInfo.xlsx'))\n",
    "\n",
    "runStartTimes = {}\n",
    "for run in SUB08.runs_incl:\n",
    "    for row in np.arange(runTimes.shape[0]):\n",
    "        if run[-6:] in runTimes.iloc[row]['filename']:\n",
    "            t = runTimes.iloc[row]['acq_time']\n",
    "            runStartTimes[run] = pd.Timestamp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import and process video-annotated tap-times ###\n",
    "\n",
    "## (function to be) Convert video-annotated tap-stamps\n",
    "## into seconds after tmsi-recording\n",
    "\n",
    "# import annotated taptimes (function to be?)\n",
    "sub = '008'\n",
    "annot_dir = os.path.join(projectpath, f'data/analysis_derivatives/sub-{sub}/taps')\n",
    "tapAnnot = np.load(os.path.join(annot_dir, f'{sub}_video_ann_tapruns.npy'),\n",
    "    allow_pickle=True).item()\n",
    "\n",
    "ann_times = {}\n",
    "tapsAnnot_in_runSecs = {}\n",
    "\n",
    "for run in tapDict.keys():\n",
    "    if 'Tap' not in run: continue\n",
    "\n",
    "    # real-time timestamps of video-annotated taps\n",
    "    dt_string = '%Y-%m-%d %H:%M:%S'\n",
    "    t0 = tapAnnot[run]['starttime']\n",
    "    try:\n",
    "        t0 = dt.datetime.strptime(t0, dt_string)\n",
    "    except ValueError:\n",
    "        t0 = dt.datetime.strptime(t0, '%Y-%m-%d %H:%M')\n",
    "\n",
    "    ann_times[run] = {}\n",
    "    tapsAnnot_in_runSecs[run] = {}\n",
    "\n",
    "    for side in sides:\n",
    "        ann_times[run][side] = [t0 + dt.timedelta(\n",
    "            seconds=t) for t in tapAnnot[run][side]]\n",
    "    # minus video start-time -> time after video-start\n",
    "        tapsAnnot_in_runSecs[run][side] = [\n",
    "            (t - runStartTimes[run]).total_seconds(\n",
    "            ) for t in ann_times[run][side]\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO:\n",
    "# - WHY IS check_Polarity turning the signal falsely?\n",
    "# - Why is tapdetection from TapDopa15 Right empty? \n",
    "    # plot incl peaks and thresholds etc\n",
    "\n",
    "# - include plotting of OTHER MVOEMENTS\n",
    "# - split py function for tapping in several py docs!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create plotting functions for tapping\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "run = list(tapsAnnot_in_runSecs.keys())[2]\n",
    "\n",
    "print(f'Plot Figure for run {run}')\n",
    "# specify x-coordinates of zoomed-in subplots\n",
    "ax1_x1, ax1_x2 = 72, 80\n",
    "ax2_x1, ax2_x2 = 150, 160\n",
    "plot_fname=f'TapDetect_08_{run}'\n",
    "if ax1_x1: plot_fname += f'_zooms_{ax1_x1}_{ax2_x1}'\n",
    "plot_fdir=tap_fig_dir\n",
    "\n",
    "plot_params = {\n",
    "        'left': {\n",
    "            'color': 'b',\n",
    "            'alpha': .6\n",
    "        },\n",
    "        'right': {\n",
    "            'color': 'g',\n",
    "            'alpha': .6\n",
    "        },\n",
    "        'rest': {\n",
    "            'color': 'orange',\n",
    "            'alpha': .3\n",
    "        },\n",
    "        'left_up': {\n",
    "            'color': 'dodgerblue',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'left_down': {\n",
    "            'color': 'cyan',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'left_other': {\n",
    "            'facecolor': 'white',\n",
    "            'edgecolor': 'dodgerblue',\n",
    "            'alpha': .8,\n",
    "            'hatch': '//'\n",
    "        },\n",
    "        'right_up': {\n",
    "            'color': 'forestgreen',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'right_down': {\n",
    "            'color': 'lime',\n",
    "            'alpha': .5\n",
    "        },\n",
    "        'right_other': {\n",
    "            'facecolor': 'white',\n",
    "            'edgecolor': 'forestgreen',\n",
    "            'alpha': .8,\n",
    "            'hatch': '//'\n",
    "        }\n",
    "    }\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(16, 12))\n",
    "gs = GridSpec(3, 9, figure=fig)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[:2, :])\n",
    "ax1 = fig.add_subplot(gs[2, :4])\n",
    "ax2 = fig.add_subplot(gs[2, 5:], sharey=ax1)\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "for ax in [ax0, ax1, ax2]:\n",
    "    # Plotting traces\n",
    "    ax.plot(\n",
    "        np.arange(0, accleft[run][1, :].shape[0]) / fs,\n",
    "        accleft[run][1, :], **plot_params['left'],\n",
    "        label='Left ACC-trace',\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(0, accright[run][1, :].shape[0]) / fs,\n",
    "        accright[run][1, :], **plot_params['right'],\n",
    "        label='Right ACC-trace',\n",
    "    )\n",
    "    # Plot bilateral Rest-epochs\n",
    "    for d in restDict[run]:\n",
    "        ax.fill_betweenx(label='Bilat. Rest detected',\n",
    "            y=[-1e-6, 1e-6], x1=restDict[run][d][0],\n",
    "            x2=restDict[run][d][1],\n",
    "            **plot_params['rest'],)\n",
    "\n",
    "    # Plot Tap and other-movem. epochs\n",
    "    for side in ['left', 'right']:\n",
    "        ## plot Taps\n",
    "        for t, tList in enumerate(tapDict[run][side]):\n",
    "            ax.fill_betweenx(\n",
    "                y=[-3e-6, 3e-6],\n",
    "                x1=tList[0], x2=tList[2],\n",
    "                label=f'{side} Up detected',\n",
    "                **plot_params[f'{side}_up'],\n",
    "            )\n",
    "            # ax.scatter(tList[1], )  # plot fastest point\n",
    "            ax.fill_betweenx(\n",
    "                y=[-3e-6, 3e-6],\n",
    "                x1=tList[3], x2=tList[4],\n",
    "                label=f'{side} Down detected',\n",
    "                **plot_params[f'{side}_down'],\n",
    "            )\n",
    "        \n",
    "        ## Plot Other Movement's\n",
    "        for t, tList in enumerate(moveDict[run][side]):\n",
    "            ax.fill_betweenx(\n",
    "                y=[-1e-6, 1e-6],\n",
    "                x1=tList[0], x2=tList[1],\n",
    "                label=f'{side} Other Mov. detected',\n",
    "                **plot_params[f'{side}_other'],\n",
    "            )\n",
    "        \n",
    "        ## Plot Accuracy circles based on video-annotations\n",
    "        vid_circle_pos = tapsAnnot_in_runSecs[run][side]\n",
    "        acc_circle_pos = [t[0] for t in tapDict[run][side]]\n",
    "        ax0.scatter(\n",
    "            vid_circle_pos, [3.5e-6] * len(vid_circle_pos),\n",
    "            s=150, edgecolor='k', facecolor='w', lw=2,\n",
    "            label='Video-annotated Tap', **plot_params['left'],\n",
    "        )\n",
    "        ax0.scatter(\n",
    "            acc_circle_pos, [3.5e-6] * len(acc_circle_pos),\n",
    "            s=120, color=plot_params[side]['color'], alpha=.3,\n",
    "            label=f'Acc-classified Tap {side}'\n",
    "        )\n",
    "        tapAcc_handles, tapAcc_labels = ax0.get_legend_handles_labels()\n",
    "        tapAcc_handles = tapAcc_handles[-3:]\n",
    "        tapAcc_labels = tapAcc_labels[-3:]\n",
    "        ax0.legend(tapAcc_handles, tapAcc_labels,\n",
    "            fontsize=16, ncol=3, frameon=False,\n",
    "            loc='upper center', bbox_to_anchor=(.5, .99))\n",
    "\n",
    "        # plot findpeak dots to optimize algorithm\n",
    "        # posPeaks = signal.find_peaks(\n",
    "        #     accleft[run][1, :],\n",
    "        #     height=np.max(accleft[1, :]) * .5,\n",
    "        #     distance=fs,  # 1 s\n",
    "        # )\n",
    "        # ax.scatter(posPeaks[0] / fs, posPeaks[1]['peak_heights'], c='k')\n",
    "        # posPeaks = signal.find_peaks(\n",
    "        #     accright[run][1, :],\n",
    "        #     height=np.max(accright[1, :]) * .5,\n",
    "        #     distance=fs,  # 1 s\n",
    "        # )\n",
    "        # ax.scatter(posPeaks[0] / fs, posPeaks[1]['peak_heights'], c='gray')\n",
    "        \n",
    "        \n",
    "    # make plots pretty\n",
    "    ax.set_xlabel('Time (sec)', size=20)\n",
    "    ax.tick_params(axis='both', which='both', labelsize=16)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    # helping lines for alforithm finetuning\n",
    "    # ax.axhline(np.median(spos), label='median')\n",
    "    # ax.axhline(np.percentile(spos, 75), label='75-%', ls='dotted')\n",
    "    # ax.axhline(-np.percentile(spos, 75), label='-75-%', color='red', ls='dotted')\n",
    "\n",
    "# make plot pretty\n",
    "for ax in [ax0, ax1]: ax.set_ylabel('Acceleration (m/s/s)', size=20)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "# define zoomed subplots\n",
    "ax1.set_xlim(ax1_x1, ax1_x2)\n",
    "ax2.set_xlim(ax2_x1, ax2_x2)\n",
    "\n",
    "# get rid off duplicate legend labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(\n",
    "    by_label.values(), by_label.keys(),\n",
    "    fontsize=20, frameon=False, ncol=3,\n",
    "    loc='upper left', bbox_to_anchor=(.03, -.01)\n",
    ")\n",
    "plt.suptitle(f'sub008: {run}', x=.8, y=.99,\n",
    "    color='gray', alpha=.8, fontsize=16,)\n",
    "# plt.tight_layout(pad=.1)\n",
    "\n",
    "plt.savefig(os.path.join(plot_fdir, plot_fname),\n",
    "    dpi=150, facecolor='white', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING ###\n",
    "## using xyz input and output-indices of pausedTap function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "ax.plot(xEpoch, label='x', alpha=.5, c='blue')\n",
    "ax.plot(yEpoch, label='y', alpha=.8, c='green')\n",
    "ax.plot(zEpoch, label='z', alpha=.5, c='orange')\n",
    "# plot vertical lines at tap-moments\n",
    "for t, tap in enumerate(tapi):\n",
    "    if t == 0:\n",
    "        ax.axvline(tap[0], c='green', ls='dotted', alpha=.5, label='start UP')\n",
    "        ax.axvline(tap[1], c='green', ls='solid', alpha=.5, label='end UP')\n",
    "        ax.axvline(tap[2], c='purple', ls='dotted', alpha=.5, label='start DOWN')\n",
    "        ax.axvline(tap[3], c='purple', ls='solid', alpha=.5, label='end DOWN')\n",
    "    else:\n",
    "        ax.axvline(tap[0], c='green', ls='dotted', alpha=.5,)\n",
    "        ax.axvline(tap[1], c='green', ls='solid', alpha=.5,)\n",
    "        ax.axvline(tap[2], c='purple', ls='dotted', alpha=.5,)\n",
    "        ax.axvline(tap[3], c='purple', ls='solid', alpha=.5,)\n",
    "\n",
    "peaklabel = ['lowPos', 'highPos', 'lowNeg', 'highNeg']\n",
    "peakcol = ['lightgreen', 'green', 'orange', 'r']\n",
    "for p, peaks in enumerate([smallPos, largePos, smallNeg, largeNeg]):\n",
    "    ax.scatter(\n",
    "        peaks[0],\n",
    "        yEpoch[peaks[0]],\n",
    "        label=peaklabel[p],\n",
    "        color=peakcol[p],\n",
    "        s=50,\n",
    "    )\n",
    "\n",
    "for mov in movei:  # check saved otherMovements\n",
    "    ax.axvline(mov[0], color='gray', lw=1, ls='dotted')\n",
    "    ax.axvline(mov[-1], color='gray', lw=1)\n",
    "\n",
    "# ax.axhline(-.5e-7)\n",
    "ax.axhline(posThr)\n",
    "ax.axhline(0, c='gray', lw=.5,)\n",
    "# determine what to show\n",
    "ax.set_ylim(-2.5e-6, 2.5e-6)\n",
    "# ax.set_xlim(istart, istop)\n",
    "ax.set_xlim(0, 30000)\n",
    "# ax.set_xticks(np.arange(18600, 20001, 200))\n",
    "# ax.set_xticklabels(np.arange(18600, 20001, 200) // 200)\n",
    "xticks = np.arange(0, len(yEpoch), 6000)\n",
    "xlabs = np.arange(0, len(yEpoch) / 12000, .5)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabs)\n",
    "\n",
    "ax.set_ylabel('Raw Acceleration (m/s/s)', size=14)\n",
    "ax.set_xlabel('Time (minutes)', size=14)\n",
    "\n",
    "ax.set_title(run)\n",
    "\n",
    "# ax.legend(frameon=False, fontsize=14, loc='upper right')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Plot Rest-moments\n",
    "for idx in resti:\n",
    "    ax.fill_betweenx(\n",
    "        y=np.linspace(-3e-6, 3e-6, 5), x1=idx[0], x2=idx[1],\n",
    "        color='blue', alpha=.1,)\n",
    "\n",
    "if to_save:\n",
    "    plt.savefig(\n",
    "        os.path.join(temp_save, 'ACC', f'mountFingerTap_sub08_{run[-6:]}_2'),\n",
    "        dpi=300, facecolor='w',\n",
    "    )\n",
    "plt.show()\n",
    "\n",
    "print(f'{run} finisihed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ecog_dysk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
