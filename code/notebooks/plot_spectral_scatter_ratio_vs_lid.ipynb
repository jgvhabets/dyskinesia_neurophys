{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Activity vs Dyskinesia and multi-freq Biomarker Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress, product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from scipy import signal, stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = os.path.dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectpath = get_project_path_in_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(projectpath, 'code'))\n",
    "\n",
    "# own utility functions\n",
    "import utils.utils_fileManagement as utilsFiles\n",
    "\n",
    "# own data exploration functions\n",
    "import lfpecog_preproc.preproc_import_scores_annotations as importClin\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_analysis.psd_lid_stats as lidStats\n",
    "import lfpecog_analysis.ft_processing_helpers as ftProc\n",
    "import lfpecog_features.feats_spectral_helpers as specHelp\n",
    "import lfpecog_analysis.get_acc_task_derivs as getAccTask\n",
    "\n",
    "import lfpecog_predict.prepare_predict_arrays as predArrays\n",
    "import lfpecog_features.extract_ssd_features as ssdFeats\n",
    "import lfpecog_analysis.stats_fts_lid_corrs as ft_stats\n",
    "from lfpecog_plotting.plotHelpers import get_colors\n",
    "import lfpecog_plotting.plotHelpers as pltHelp\n",
    "import lfpecog_plotting.plot_SSD_feat_descriptives as plot_ssd_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib import __version__ as plt_version\n",
    "\n",
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('matplotlib', plt_version)\n",
    "# Python sys 3.9.0 (default, Nov 15 2020, 08:30:55) [MSC v.1916 64 bit (AMD64)]\n",
    "# pandas 1.4.4\n",
    "# numpy 1.23.3\n",
    "# matplotlib 3.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "\n",
    "imports SSD-band-envelops with parallel CDRS, timestamps, task, movement-coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET VERSIONS\n",
    "\n",
    "FT_VERSION='v8'\n",
    "SETTINGS = utilsFiles.load_ft_ext_cfg(FT_VERSION=FT_VERSION)\n",
    "\n",
    "SUBS = utilsFiles.get_avail_ssd_subs(\n",
    "    DATA_VERSION=SETTINGS[\"DATA_VERSION\"],\n",
    "    FT_VERSION=FT_VERSION,\n",
    ")\n",
    "print(f'n = {len(SUBS)} subjects available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIG: Spectral Scatterplot: Movement vs. Dyskinesia dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load STN data (n=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_VERSION = 'v8'\n",
    "INCL_CORE_CDRS = True\n",
    "CATEG_CDRS = False\n",
    "INCL_ECOG = False  # if True, STN-only patients are NOT included\n",
    "MILD_CDRS = 4  # cut off for dyskinesia categorization (4)\n",
    "SEV_CDRS = 8  # cut off for dyskinesia categorization (8)\n",
    "\n",
    "# ### Create Feature Class\n",
    "# FeatLid_STN = ftProc.FeatLidClass(\n",
    "#     FT_VERSION=FT_VERSION,\n",
    "#     CDRS_RATER='Patricia',\n",
    "#     INCL_ECOG=INCL_ECOG,\n",
    "#     INCL_ACC_RMS=False,\n",
    "#     CATEGORICAL_CDRS=CATEG_CDRS,\n",
    "#     CORR_TARGET='CDRS',\n",
    "#     cutMild=MILD_CDRS, cutSevere=SEV_CDRS,\n",
    "#     TO_CALC_CORR=False,\n",
    "# )\n",
    "\n",
    "### LOAD existing classes with features and labels\n",
    "featLabPath = os.path.join(utilsFiles.get_project_path('data'),\n",
    "                           'prediction_data',\n",
    "                           'featLabelClasses')\n",
    "stn_pickle = f'featLabels_ft{FT_VERSION}_Cdrs_StnOnly.P'\n",
    "\n",
    "FeatLid_STN = utilsFiles.load_class_pickle(\n",
    "    os.path.join(featLabPath, stn_pickle),\n",
    "    convert_float_np64=True\n",
    ")\n",
    "\n",
    "\n",
    "# MERGE GAMMA1-2-3 FEATURES\n",
    "for sub in FeatLid_STN.FEATS:\n",
    "    FeatLid_STN.FEATS[sub] = ft_stats.replace_gammas_for_meanGamma(FeatLid_STN.FEATS[sub])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Feature Class for Acc (v6)\n",
    "\n",
    "### Create \n",
    "# Acc_STN = ftProc.FeatLidClass(\n",
    "#     FT_VERSION='v6',\n",
    "#     CDRS_RATER='Patricia',\n",
    "#     INCL_ECOG=INCL_ECOG,\n",
    "#     INCL_ACC_RMS=True,\n",
    "#     CATEGORICAL_CDRS=CATEG_CDRS,\n",
    "#     CORR_TARGET='CDRS',\n",
    "#     cutMild=MILD_CDRS, cutSevere=SEV_CDRS,\n",
    "#     TO_CALC_CORR=False,\n",
    "# )\n",
    "\n",
    "\n",
    "# Load v6 to get ACC-values\n",
    "Acc_STN = utilsFiles.load_class_pickle(\n",
    "    os.path.join(featLabPath, stn_pickle.replace('v8', 'v6')),\n",
    "    convert_float_np64=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ECoG data (n=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_VERSION = 'v8'\n",
    "INCL_CORE_CDRS = True\n",
    "CATEG_CDRS = False\n",
    "INCL_ECOG = True  # if True, STN-only patients are NOT included\n",
    "MILD_CDRS = 4  # cut off for dyskinesia categorization\n",
    "SEV_CDRS = 8  # cut off for dyskinesia categorization\n",
    "\n",
    "### Create Feature Class\n",
    "# FeatLid_ECOG = ftProc.FeatLidClass(\n",
    "#     FT_VERSION=FT_VERSION,\n",
    "#     CDRS_RATER='Patricia',\n",
    "#     INCL_ECOG=INCL_ECOG,\n",
    "#     INCL_ACC_RMS=False,\n",
    "#     CATEGORICAL_CDRS=CATEG_CDRS,\n",
    "#     CORR_TARGET='CDRS',\n",
    "#     cutMild=MILD_CDRS, cutSevere=SEV_CDRS,\n",
    "#     TO_CALC_CORR=False,\n",
    "# )\n",
    "\n",
    "### LOAD existing classes with features and labels\n",
    "featLabPath = os.path.join(utilsFiles.get_project_path('data'),\n",
    "                           'prediction_data',\n",
    "                           'featLabelClasses')\n",
    "ecog_pickle = f'featLabels_ft{FT_VERSION}_Cdrs_Ecog.P'\n",
    "\n",
    "FeatLid_ECOG = utilsFiles.load_class_pickle(\n",
    "    os.path.join(featLabPath, ecog_pickle),\n",
    "    convert_float_np64=True\n",
    ")\n",
    "# MERGE GAMMA1-2-3 FEATURES\n",
    "for sub in FeatLid_ECOG.FEATS:\n",
    "    FeatLid_ECOG.FEATS[sub] = ft_stats.replace_gammas_for_meanGamma(FeatLid_ECOG.FEATS[sub])\n",
    "\n",
    "\n",
    "\n",
    "# Load v6 to get ACC-values\n",
    "Acc_ECOG = utilsFiles.load_class_pickle(\n",
    "    os.path.join(featLabPath, ecog_pickle.replace('v8', 'v6')),\n",
    "    convert_float_np64=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get task data per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_MINS = getAccTask.get_task_minutes(LOAD_JSON=True, SUBS=SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_plotting.plot_Spectrals_vs_LID as plotSpecLid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ftProc)\n",
    "importlib.reload(plotSpecLid)\n",
    "\n",
    "FIG_DATE = '1009'\n",
    "\n",
    "POW_or_COH = 'COH'  # POW or COH\n",
    "SRC = 'ecog'  # ecog or lfp\n",
    "EXCL_FREE = False\n",
    "gamma_peak = 'peak'  # peak / mean\n",
    "\n",
    "if SRC == 'lfp':\n",
    "    FeatClass = FeatLid_STN  # FeatLid_ECOG\n",
    "    AccClass = Acc_STN\n",
    "if SRC == 'ecog':\n",
    "    FeatClass = FeatLid_ECOG\n",
    "    AccClass = Acc_ECOG\n",
    "\n",
    "FIG_NAME = (f'{FIG_DATE}_PowerScatter_{SRC.upper()}_LID_MOVE_g{gamma_peak}'\n",
    "            f'_n{len(FeatClass.FEATS.keys())}_ft{FT_VERSION}_shf')\n",
    "if EXCL_FREE: FIG_NAME = 'woFREE_' + FIG_NAME\n",
    "\n",
    "plotSpecLid.scatter_Feats_LID_MOVE(\n",
    "    FeatClass=FeatClass,\n",
    "    AccClass=AccClass,\n",
    "    POW_or_COH=POW_or_COH,\n",
    "    SRC=SRC,\n",
    "    SHUFFLE_SCATTERS=True,\n",
    "    SAVE_FIG=True,\n",
    "    FIG_NAME=FIG_NAME,\n",
    "    gamma_mean_or_peakband=gamma_peak,\n",
    "    EXCL_FREE=EXCL_FREE,\n",
    "    task_minutes=TASK_MINS,\n",
    "    ZERO_SPACE=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIG) Simple biomarker versus Dyskinesia onset\n",
    "\n",
    "\n",
    "Calculates based on envelop arrays from predArrays.get_move_selected_env_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lfpecog_analysis.psd_analysis_classes import PSD_vs_Move_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(predArrays)\n",
    "\n",
    "# get move-selected env arrays\n",
    "# contains: freq-bands, CDRS, timestamps, tasks, mov-coding\n",
    "\n",
    "# TODO: FIRST extract via cmd: lfpecog_predict.prepare_precit_arrays\n",
    "DATA, env_fbands = {}, {}\n",
    "\n",
    "for sub in SUBS:\n",
    "    DATA[sub], env_fbands[sub] = predArrays.get_move_selected_env_arrays(\n",
    "        sub=sub, LOAD_SAVE=True,\n",
    "        FT_VERSION='v8',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'lfp_left'\n",
    "\n",
    "ex_sub = list(env_fbands.keys())[0]\n",
    "ex_src= list(env_fbands[ex_sub].keys())[0]\n",
    "\n",
    "i_theta = np.where([k == 'theta' for k in env_fbands[sub][src]])[0][0]\n",
    "i_beta = np.where([k == 'lo_beta' for k in env_fbands[sub][src]])[0][0]\n",
    "i_gammaPeak = np.where([k == 'gammaPeak' for k in env_fbands[sub][src]])[0][0]\n",
    "i_cdrs = len(env_fbands[sub][src])\n",
    "i_time = i_cdrs + 1\n",
    "i_task = i_time + 1\n",
    "# i_move is last\n",
    "\n",
    "time_list = {'lid': [], 'nolid': []}\n",
    "ratio_list = {'lid': [], 'nolid': []}\n",
    "\n",
    "lid_onsets = []\n",
    "\n",
    "sub_list = []\n",
    "\n",
    "for sub, src in product(DATA.keys(),\n",
    "                        ['lfp_left', 'lfp_right']):\n",
    "    \n",
    "    if sum(DATA[sub][src][i_cdrs, :]) == 0:\n",
    "        print(f'sub {sub} had no LID')\n",
    "        subgroup = 'nolid'\n",
    "    else:\n",
    "        subgroup = 'lid'\n",
    "\n",
    "    print(f'...calc {sub, src}')\n",
    "    \n",
    "    idx_sort = np.argsort(DATA[sub][src][i_time, :])\n",
    "    sort_arr = DATA[sub][src][:, idx_sort]\n",
    "\n",
    "    theta = sort_arr[i_theta, :]\n",
    "    beta = sort_arr[i_beta, :]\n",
    "    gamma = sort_arr[i_gammaPeak, :]\n",
    "\n",
    "\n",
    "    for arr in [theta, beta, gamma]:\n",
    "        off_sel = sort_arr[i_time, :] < 5\n",
    "        m = np.mean(arr[off_sel])\n",
    "        sd = np.std(arr[off_sel])\n",
    "        arr = (arr - m) / sd\n",
    "\n",
    "    assert theta.shape == beta.shape, 'shapes unequal'\n",
    "\n",
    "    # sets all times to ZERO at LID onset\n",
    "    if subgroup == 'lid':\n",
    "        i0_lid = np.where(sort_arr[i_cdrs, :] > 0)[0][0]\n",
    "        t0_lid = sort_arr[i_time, i0_lid]\n",
    "        lid_times = sort_arr[i_time, :] - t0_lid\n",
    "        lid_onsets.append(t0_lid)\n",
    "    else:\n",
    "        lid_times = sort_arr[i_time, :]\n",
    "\n",
    "\n",
    "    time_list[subgroup].append(lid_times)\n",
    "    ratio = (theta / beta) * gamma\n",
    "    ratio = (ratio - np.mean(ratio)) / np.std(ratio)\n",
    "    ratio_list[subgroup].append(ratio)\n",
    "\n",
    "    sub_list.append(f'{sub}_{src}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sec, max_sec = (\n",
    "    int(np.min([np.min(l) for l in time_list['lid']])),\n",
    "    int(np.max([np.max(l) for l in time_list['lid']]))\n",
    ")\n",
    "\n",
    "print(f'mean LID onset: {round(np.mean(lid_onsets) / 60, 1)} minutes'\n",
    "      f' (sd: {round(np.std(lid_onsets) / 60, 1)})')\n",
    "# correct group without LID to comparable time offsets\n",
    "nolid_new_times = []\n",
    "for t in time_list['nolid']:\n",
    "    nolid_new_times.append(t - np.mean(lid_onsets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overall array per X seconds\n",
    "WIN_LEN = 10\n",
    "\n",
    "## LID group\n",
    "min_sec, max_sec = (\n",
    "    int(np.min([np.min(l) for l in time_list['lid']])),\n",
    "    int(np.max([np.max(l) for l in time_list['lid']]))\n",
    ")\n",
    "t_new = np.arange(min_sec, max_sec, WIN_LEN)\n",
    "\n",
    "ratio_arr = np.array([[np.nan] * len(t_new)] * len(ratio_list['lid']))\n",
    "\n",
    "for i_t, t0 in enumerate(t_new):\n",
    "\n",
    "    for i_row, (sig_temp, t_temp) in enumerate(\n",
    "        zip(ratio_list['lid'], time_list['lid'])\n",
    "    ):\n",
    "        # select idx for window\n",
    "        win_sel = np.logical_and(t_temp > t0, t_temp < (t0 + WIN_LEN))\n",
    "        # add mean ratio to correct idx\n",
    "        ratio_arr[i_row, i_t] = np.mean(sig_temp[win_sel])\n",
    "\n",
    "\n",
    "## NO-LID group\n",
    "\n",
    "# correct group without LID to comparable time offsets\n",
    "nolid_new_times = []\n",
    "for t in time_list['nolid']:\n",
    "    nolid_new_times.append(t - np.mean(lid_onsets))\n",
    "\n",
    "ratio_arr_noLID = np.array([[np.nan] * len(t_new)] * len(ratio_list['nolid']))\n",
    "\n",
    "# use same time frame\n",
    "for i_t, t0 in enumerate(t_new):\n",
    "\n",
    "    for i_row, (sig_temp, t_temp) in enumerate(\n",
    "        zip(ratio_list['nolid'], nolid_new_times)\n",
    "    ):\n",
    "        # select idx for window\n",
    "        win_sel = np.logical_and(t_temp > t0, t_temp < (t0 + WIN_LEN))\n",
    "        # add mean ratio to correct idx\n",
    "        ratio_arr_noLID[i_row, i_t] = np.mean(sig_temp[win_sel])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Ratio over Time vs LID-onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotSpecLid)\n",
    "\n",
    "# plot_ratio_biomarker(ratio_arr=ratio_arr,\n",
    "#                      Z_SCORE_RATIOS=False,\n",
    "#                      MIN_SUBS=5,\n",
    "#                      SMOOTH_WIN=0,)\n",
    "\n",
    "plotSpecLid.plot_ratio_biomarker(\n",
    "    ratio_arr=ratio_arr,\n",
    "    t_new=t_new,\n",
    "    Z_SCORE_RATIOS=False,\n",
    "    MIN_SUBS=5,\n",
    "    SMOOTH_WIN=10,\n",
    "    SAVE_FIG=False,\n",
    ")\n",
    "\n",
    "# plot_ratio_biomarker(ratio_arr=ratio_arr_noLID,\n",
    "#                      Z_SCORE_RATIOS=False, MIN_SUBS=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate binary AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove no-lid-subjects from sub_list\n",
    "sub_list = [s for s in sub_list if \n",
    "            all(c not in s for c in ['101', '017', '109'])]\n",
    "\n",
    "thresholds = np.arange(-.5, .9, .001)\n",
    "\n",
    "auroc = []\n",
    "\n",
    "for sub in np.unique([s.split('_')[0] for s in sub_list]):\n",
    "    \n",
    "    sub_roc = []\n",
    "    \n",
    "    # print(f'sub-{sub}')\n",
    "    sub_sel = [sub in s for s in sub_list]\n",
    "    sub_arr = np.mean(ratio_arr.copy()[sub_sel], axis=0)\n",
    "    sub_t = t_new.copy()\n",
    "    sel = [not np.isnan(v) for v in sub_arr]\n",
    "    sub_arr = sub_arr[sel]\n",
    "    sub_t = sub_t[sel]\n",
    "    sub_y_true = (sub_t > 0).astype(int)\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (sub_arr > t).astype(int)\n",
    "        tp = sum(np.logical_and(y_pred == 1, sub_y_true == 1))\n",
    "        fn = sum(np.logical_and(y_pred == 0, sub_y_true == 1))\n",
    "        tpr = tp / (tp + fn)\n",
    "        fp = sum(np.logical_and(y_pred == 1, sub_y_true == 0))\n",
    "        tn = sum(np.logical_and(y_pred == 0, sub_y_true == 0))\n",
    "        fpr = fp / (fp + tn)\n",
    "        sub_roc.append([fpr, tpr])\n",
    "    \n",
    "    auroc.append(sub_roc)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single AUROCs\n",
    "for roc in auroc:\n",
    "    roc = np.array(roc)\n",
    "    plt.plot(roc[:, 0], roc[:, 1], alpha=.3,)\n",
    "\n",
    "plt.xlim(-.05, 1.05)\n",
    "plt.ylim(-.05, 1.05)\n",
    "\n",
    "# change level\n",
    "plt.plot([0, 1], [0, 1], lw=3, alpha=.8, color='gray',\n",
    "         ls='--',)\n",
    "\n",
    "plt.xlabel('False pos. rate', size=16, weight='bold',)\n",
    "plt.ylabel('True pos. rate', size=16, weight='bold',)\n",
    "\n",
    "plt.title('AUROC based on [ \\u03B8 * \\u03B2 / \\u03B3 ] ratio',\n",
    "          size=16, weight='bold',)\n",
    "\n",
    "FIG_PATH = os.path.join(utilsFiles.get_project_path('figures'),\n",
    "                            'final_Q1_2024',\n",
    "                            'prediction', 'ratio')\n",
    "            \n",
    "plt.savefig(os.path.join(FIG_PATH, '000_RATIO_AUROC_v6'),\n",
    "            dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean AUROC\n",
    "SAVEFIG=True\n",
    "FIG_DATE='0918'\n",
    "\n",
    "all_aurocs = np.array(auroc)\n",
    "\n",
    "mean_roc = np.mean(all_aurocs, axis=0)\n",
    "sd_roc = np.std(all_aurocs, axis=0)\n",
    "\n",
    "plt.plot(mean_roc[:, 0], mean_roc[:, 1],\n",
    "         c='k', alpha=.8, lw=3,)\n",
    "\n",
    "plt.fill_between(x=mean_roc[:, 0],\n",
    "                 y1=mean_roc[:, 1] - sd_roc[:, 1],\n",
    "                 y2=mean_roc[:, 1] + sd_roc[:, 1],\n",
    "                 color='gray', alpha=.4, lw=0,)\n",
    "\n",
    "plt.xlim(-.05, 1.05)\n",
    "plt.ylim(-.05, 1.05)\n",
    "\n",
    "# change level\n",
    "plt.plot([0, 1], [0, 1], lw=3, alpha=.8, color='gray',\n",
    "         ls='--',)\n",
    "\n",
    "plt.xlabel('False pos. rate', size=16, weight='bold',)\n",
    "plt.ylabel('True pos. rate', size=16, weight='bold',)\n",
    "\n",
    "plt.title('AUROC based on [ \\u03B8 * \\u03B2 / \\u03B3 ] ratio',\n",
    "          size=16, weight='bold',)\n",
    "\n",
    "FIG_PATH = os.path.join(utilsFiles.get_project_path('figures'),\n",
    "                            'final_Q1_2024',\n",
    "                            'prediction', 'ratio')\n",
    "if SAVEFIG:          \n",
    "    plt.savefig(os.path.join(FIG_PATH, f'{FIG_DATE}_RATIO_meanAUROC_v6'),\n",
    "                dpi=300, facecolor='w',)\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-subject-out Cross-Validation of Ratio-Biomarker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data: mean LFP Ratio with binary-LID for every subject\n",
    "\n",
    "- single spectral bands are standardised against their first 5 minutes\n",
    "- ecpohed mean-envelop values are saved as json files per STN (L vs R)\n",
    "- epoch length is variable (default 10 seconds)\n",
    "- envelop-ratio calculated on high-sampling rate, then per hemisphere ecpohed mean, then mean over both hemispheres for identical epoch-times (rounded on 10 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratios_json(sub, src, version='v1',):\n",
    "\n",
    "    try:\n",
    "        path = os.path.join(projectpath, 'data', 'prediction_data', 'ratio_marker')\n",
    "        if version == 'v2':\n",
    "            path = os.path.join(projectpath, 'data', 'prediction_data', 'ratio_marker_v2')\n",
    "        f_name = f'{sub}_{src}_ratio_data.json'\n",
    "\n",
    "        with open(os.path.join(path, f_name), 'r') as f:\n",
    "            temp = json.load(f)\n",
    "        \n",
    "        print(f'successfully loaded loading {f_name} from {path}!')\n",
    "\n",
    "        return True, temp\n",
    "\n",
    "    except:\n",
    "        print(f'could not load RATIO-json {f_name} from {path}')\n",
    "\n",
    "        return False, False\n",
    "\n",
    "\n",
    "def save_ratios_json(sub, src, data_dict, version='v1'):\n",
    "\n",
    "    path = os.path.join(projectpath, 'data', 'prediction_data', 'ratio_marker')\n",
    "    if version == 'v2':\n",
    "        path = os.path.join(projectpath, 'data', 'prediction_data', 'ratio_marker_v2')\n",
    "    f_name = f'{sub}_{src}_ratio_data.json'\n",
    "\n",
    "    with open(os.path.join(path, f_name), 'wt') as f:\n",
    "        json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "consider v2 with unilateral z-scoring (line )\n",
    "\"\"\"\n",
    "UNILAT_STD = False\n",
    "RATIO_V = 'v1'\n",
    "\n",
    "WIN_LEN = 10\n",
    "\n",
    "ratio_arrays = {}  # collect mean ratios left-right STN\n",
    "lid_arrays = {}  # collect mean ratios left-right STN\n",
    "\n",
    "# for sub in DATA.keys():\n",
    "#     temp_ratio_arrays[sub] = {}\n",
    "#     temp_time_arrays[sub] = {}\n",
    "\n",
    "lid_onsets = []\n",
    "\n",
    "sub_list = []\n",
    "\n",
    "for sub in DATA.keys():\n",
    "\n",
    "    temp_ratio = {}  # collect mean ratios left-right STN\n",
    "    temp_times = {}  # collect timestamps to check left-right match\n",
    "    temp_lid = {}\n",
    "\n",
    "    for src in ['lfp_left', 'lfp_right']:\n",
    "\n",
    "        LOAD_SUCCESS, temp_dict = load_ratios_json(sub=sub, src=src, version=RATIO_V,)\n",
    "\n",
    "        if LOAD_SUCCESS:\n",
    "            assert temp_dict[\"sub\"] == sub, f'incorrect sub loaded {temp_dict[sub]} vs {sub}'\n",
    "            assert temp_dict[\"src\"] == src, f'incorrect sub loaded {temp_dict[src]} vs {src}'\n",
    "            temp_ratio[src] = np.array(temp_dict['ratio'])\n",
    "            temp_times[src] = np.array(temp_dict['times'])\n",
    "            temp_lid[src] = np.array(temp_dict['lid'])\n",
    "\n",
    "            continue\n",
    "        \n",
    "        # IF LOADING WAS NOT successful....:\n",
    "\n",
    "        print(f'...calc {sub, src}')\n",
    "\n",
    "        i_theta = np.where([k == 'theta' for k in env_fbands[sub][src]])[0][0]\n",
    "        i_beta = np.where([k == 'lo_beta' for k in env_fbands[sub][src]])[0][0]\n",
    "        i_gammaPeak = np.where([k == 'gammaPeak' for k in env_fbands[sub][src]])[0][0]\n",
    "        i_cdrs = len(env_fbands[sub][src])\n",
    "        i_time = i_cdrs + 1\n",
    "        i_task = i_time + 1\n",
    "\n",
    "        idx_sort = np.argsort(DATA[sub][src][i_time, :])\n",
    "        sort_arr = DATA[sub][src][:, idx_sort]\n",
    "\n",
    "        # get spectral bands\n",
    "        theta = sort_arr[i_theta, :]\n",
    "        beta = sort_arr[i_beta, :]\n",
    "        gamma = sort_arr[i_gammaPeak, :]\n",
    "\n",
    "        # standardise bands separately (against 'OFF')\n",
    "        for arr in [theta, beta, gamma]:\n",
    "            off_sel = sort_arr[i_time, :] < 5\n",
    "            m = np.mean(arr[off_sel])\n",
    "            sd = np.std(arr[off_sel])\n",
    "            arr = (arr - m) / sd\n",
    "\n",
    "        assert theta.shape == beta.shape, 'shapes unequal'\n",
    "\n",
    "        # add unilateral ratio, not z-scored\n",
    "        ratio = (theta / beta) * gamma\n",
    "        if UNILAT_STD: ratio = (ratio - np.mean(ratio)) / np.std(ratio)\n",
    "\n",
    "        # define binary LID\n",
    "        temp_lid[src] = sort_arr[i_cdrs, :] > 0\n",
    "        \n",
    "        # add times to check matching sides\n",
    "        temp_times[src] = sort_arr[i_time, :]\n",
    "    \n",
    "        # MERGE VALUES INTO X-sec EPOCHS\n",
    "        print(f'...START EPOCHING {src} in {WIN_LEN}-sec epochs')\n",
    "        time_range = np.arange(round(min(temp_times[src]), -1),\n",
    "                          round(max(temp_times[src]), -1), WIN_LEN)\n",
    "        new_ratios, new_lid, new_times = [], [], []\n",
    "        \n",
    "        print('min-max-time', np.min(temp_times[src]), np.max(temp_times[src]))\n",
    "        t_start = round(min(temp_times[src]), -1)\n",
    "\n",
    "        while (t_start + WIN_LEN) < round(max(temp_times[src]), -1):\n",
    "            # print('new loop:', t_start)\n",
    "            t_start = round(t_start, -1)\n",
    "            t_end = t_start + WIN_LEN\n",
    "            i_start = np.argmin(abs(temp_times[src] - t_start))\n",
    "            i_end = np.argmin(abs(temp_times[src] - t_end))\n",
    "            \n",
    "            if (i_end - i_start) < 2000:\n",
    "                t_start = temp_times[src][i_end + 2000]\n",
    "                print(f'too small epoch, jump to time = {t_start}')\n",
    "                continue\n",
    "            \n",
    "            print('adding..........', t_start, t_end, (i_end-i_start))\n",
    "            new_ratios.append(np.mean(ratio[i_start:i_end]))\n",
    "            new_lid.append(any(temp_lid[src][i_start:i_end] > 0))\n",
    "            new_times.append(t_start)\n",
    "            t_start += WIN_LEN\n",
    "\n",
    "\n",
    "        # STORE PER SUB SOURCE IN PICKLE\n",
    "        ind_src_dict = {\n",
    "            \"sub\": sub,\n",
    "            \"src\": src,\n",
    "            \"times\": new_times,\n",
    "            \"lid\": new_lid,\n",
    "            \"ratio\": new_ratios\n",
    "        }\n",
    "        save_ratios_json(sub=sub, src=src, data_dict=ind_src_dict, version=RATIO_V,)\n",
    "\n",
    "        # replace with epoched values\n",
    "        temp_ratio[src] = np.array(new_ratios)\n",
    "        temp_lid[src] = np.array(new_lid)\n",
    "        temp_times[src] = np.array(new_times)\n",
    "\n",
    "    ### Get MEAN ratios L/R (after left and right arrays created)\n",
    "    sub_lid = temp_lid['lfp_left']\n",
    "    sub_times = temp_times['lfp_left']  # for posthoc LID-binary correction based on time\n",
    "\n",
    "    if len(temp_ratio['lfp_left']) != len(temp_ratio['lfp_right']):\n",
    "        print(f'correct different ratio lengths L/R')\n",
    "        # INCLUDE ONLY MUTUAL TIMES!\n",
    "        incl_left = np.isin(temp_times['lfp_left'],\n",
    "                            temp_times['lfp_right'])\n",
    "        incl_right = np.isin(temp_times['lfp_right'],\n",
    "                             temp_times['lfp_left'])\n",
    "        \n",
    "        # select ratio values corresponding to mutual times\n",
    "        temp_ratio['lfp_left'] = temp_ratio['lfp_left'][incl_left]\n",
    "        temp_ratio['lfp_right'] = temp_ratio['lfp_right'][incl_right]\n",
    "        \n",
    "        # select binary lid corr to times and ratios\n",
    "        sub_lid = temp_lid['lfp_left'][incl_left]\n",
    "        sub_times = temp_times['lfp_left'][incl_left]\n",
    "        \n",
    "    sub_mratio = np.mean([temp_ratio['lfp_left'],\n",
    "                          temp_ratio['lfp_right']], axis=0)\n",
    "    \n",
    "    assert len(sub_mratio) == len(sub_lid)\n",
    "\n",
    "    sub_mratio = (sub_mratio - np.mean(sub_mratio)) / np.std(sub_mratio)  # z-score mean ratio\n",
    "    ratio_arrays[sub] = sub_mratio  # add zscored mean ratio per sub\n",
    "\n",
    "    if RATIO_V == 'v1':  # correct false binary values\n",
    "        cdrs_times, cdrs_scores = importClin.get_cdrs_specific(sub=sub, INCL_CORE_CDRS=True,)\n",
    "        cdrs_times *= 60  # correct minutes to seconds\n",
    "        corr_lid = [cdrs_scores[np.argmin(abs(cdrs_times - t))] for t in sub_times]  # match ratio times to closest-cdrs\n",
    "        sub_lid = np.array(corr_lid) > 0\n",
    "\n",
    "    lid_arrays[sub] = sub_lid  # add binary dysk per sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_lid = [cdrs_scores[np.argmin(abs(cdrs_times - t))] for t in sub_times]\n",
    "# for t in sub_times:\n",
    "#     cdrs_i = np.argmin(abs(cdrs_times - t))\n",
    "#     print(cdrs_scores[cdrs_i])\n",
    "\n",
    "plt.plot(sub_times, np.array(corr_lid) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdrs_times, cdrs_scores = importClin.get_cdrs_specific(sub=sub, INCL_CORE_CDRS=True,)\n",
    "cdrs_times *= 60\n",
    "plt.plot(cdrs_times, cdrs_scores)\n",
    "lid_i0 = np.where(cdrs_scores > 0)[0][0]\n",
    "# correct for seconds\n",
    "# lid_s0 = \n",
    "print(cdrs_times[lid_i0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform LOSO Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_opt_thresh = []\n",
    "cv_test_acc = []\n",
    "\n",
    "for test_sub in ratio_arrays.keys():\n",
    "    print(f'\\n.....TEST sub-{sub}')\n",
    "    # get values for test sub\n",
    "    test_X = ratio_arrays[test_sub]\n",
    "    test_y = lid_arrays[test_sub]\n",
    "\n",
    "    # get all values for other subs as training\n",
    "    train_X, train_y_true = [], []\n",
    "\n",
    "    for train_sub in ratio_arrays.keys():\n",
    "        if train_sub == test_sub:\n",
    "            print(f'... no including sub-{train_sub}')\n",
    "            continue\n",
    "        print(f'include sub-{train_sub} for training :)')\n",
    "\n",
    "        train_X.extend(ratio_arrays[train_sub])\n",
    "        train_y_true.extend(lid_arrays[train_sub])\n",
    "    \n",
    "    # Training: finding optimal threshold\n",
    "    train_perf = []\n",
    "    threshes = np.arange(-2, 2, .01)\n",
    "\n",
    "    for thresh in threshes:\n",
    "        y_train_pred = train_X > thresh\n",
    "        # get balanced accuracy\n",
    "        thresh_acc = balanced_accuracy_score(y_train_true,\n",
    "                                             y_train_pred)\n",
    "        train_perf.append(thresh_acc)\n",
    "        print(f'...train (thresh: {thresh}) acc: {thresh_acc}')\n",
    "    \n",
    "    # find optimal threshold\n",
    "    i_opt_thresh = np.argmax(train_perf)\n",
    "    cv_opt_thresh.append(threshes[i_opt_thresh])\n",
    "    cv_test_acc.append(train_perf[i_opt_thresh])\n",
    "\n",
    "    print(f'\\ntest-performance sub-{test_sub}: {train_perf[i_opt_thresh]}'\n",
    "          f' (threshold: {threshes[i_opt_thresh]})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old)\n",
    "\n",
    "Extract Spectral Power and Variation in Feature windows\n",
    "\n",
    "TODO:\n",
    "- current gamma: only indiv peak, add sum gamma over 60 - 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indiv_zscoring_feats(X_arr, sub_arr):\n",
    "\n",
    "    for i_f, sub in product(np.arange(X_arr.shape[1]),\n",
    "                            np.unique(sub_arr)):\n",
    "        # loop over all feature and sub combinations\n",
    "        sub_sel = sub_arr == sub\n",
    "        m = np.mean(X_arr[sub_sel, i_f])\n",
    "        sd = np.std(X_arr[sub_sel, i_f])\n",
    "        # z-score values for sub\n",
    "        X_arr[sub_sel, i_f] = (X_arr[sub_sel, i_f] - m) / sd\n",
    "    \n",
    "    return X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ssdFeats)\n",
    "\n",
    "X_arrs, y_arrs, sub_arrs = {}, {}, {}\n",
    "mov_dep_code = {}\n",
    "\n",
    "for i_mov, MOV_SEL in enumerate(['INDEP', 'DEPEND']):\n",
    "    # loading/ creating/ saving in ssdFeats script\n",
    "    (\n",
    "        X_arrs[i_mov], y_arrs[i_mov], sub_arrs[i_mov], feat_names\n",
    "    ) = ssdFeats.get_moveSpec_predArrays(\n",
    "        MOV_SEL=MOV_SEL, LOAD_SOURCES=['STN',],\n",
    "        POWER_METHOD='ENV'\n",
    "    )\n",
    "    # add movement code\n",
    "    mov_dep_code[i_mov] = np.array([i_mov] * X_arrs[i_mov]['STN'].shape[0]).T\n",
    "\n",
    "# merging for zscoring together\n",
    "stn_X = np.concatenate([X_arrs[0]['STN'], X_arrs[1]['STN']], axis=0)\n",
    "stn_y = np.concatenate([y_arrs[0]['STN'], y_arrs[1]['STN']], axis=0)\n",
    "stn_subids = np.concatenate([sub_arrs[0]['STN'], sub_arrs[1]['STN']], axis=0)\n",
    "\n",
    "mov_dep_code = np.concatenate([mov_dep_code[0], mov_dep_code[1]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coefficients and pvalues\n",
    "CDRS_categs = {0: 'none', 1: 'mild',\n",
    "               2: 'moderate', 3: 'severe'}\n",
    "\n",
    "X = stn_X.copy()\n",
    "y = stn_y.copy()\n",
    "sub_ids = stn_subids.copy()\n",
    "\n",
    "stat_arr = {'INDEP': {'coef': [], 'pval': []},\n",
    "            'DEPEND': {'coef': [], 'pval': []}}\n",
    "\n",
    "X = indiv_zscoring_feats(X, sub_arr=sub_ids)\n",
    "\n",
    "for i_ft, ft in enumerate(feat_names['STN']):\n",
    "    \n",
    "\n",
    "    for i_mov, MOV_SEL in enumerate(['INDEP', 'DEPEND']):\n",
    "        mov_bool = mov_dep_code == i_mov\n",
    "        # define X and groups for feat\n",
    "        ft_temp = X[mov_bool, i_ft]\n",
    "        y_temp = y[mov_bool]\n",
    "        box_categs = [ft_temp[y_temp == cat]\n",
    "                      for cat in CDRS_categs.keys()]\n",
    "        # run LMM\n",
    "        coeff, pval = lidStats.run_mixEff_wGroups(\n",
    "            dep_var=ft_temp,\n",
    "            indep_var=y_temp,\n",
    "            groups=sub_ids[mov_bool],\n",
    "            TO_ZSCORE=False,\n",
    "        )\n",
    "        # save in dict-lists\n",
    "        stat_arr[MOV_SEL]['coef'].append(coeff)\n",
    "        stat_arr[MOV_SEL]['pval'].append(pval)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boxplots per feature\n",
    "\n",
    "FIG_NAME = '0129env_boxplots_specPowerVar_vs_LIDcategs'\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(len(feat_names['STN']), 2,\n",
    "                         figsize=(12, 18),\n",
    "                         sharex='col', sharey='row')\n",
    "\n",
    "for i_ft, ft in enumerate(feat_names['STN']):\n",
    "    \n",
    "    for i_mov, MOV_SEL in enumerate(['INDEP', 'DEPEND']):\n",
    "        # get boxplot data\n",
    "        mov_bool = mov_dep_code == i_mov\n",
    "        # define X and groups for feat\n",
    "        ft_temp = X[mov_bool, i_ft]\n",
    "        y_temp = y[mov_bool]\n",
    "        box_categs = [ft_temp[y_temp == cat]\n",
    "                      for cat in CDRS_categs.keys()]\n",
    "        \n",
    "        # stats are calculated before\n",
    "\n",
    "        # plotting\n",
    "        coeff = stat_arr[MOV_SEL]['coef'][i_ft]\n",
    "        pval = stat_arr[MOV_SEL]['pval'][i_ft]\n",
    "        axes[i_ft, i_mov].boxplot(box_categs)\n",
    "        if pval < (.05 / len(feat_names['STN'])): w = 'bold'\n",
    "        else: w='normal'\n",
    "        axes[i_ft, i_mov].set_title(f'{ft}, mov-{MOV_SEL}\\n'\n",
    "                f'(coeff {round(coeff, 2)}, '\n",
    "                f'p={round(pval, 5)})',\n",
    "                weight=w,)\n",
    "        axes[i_ft, i_mov].set_ylim(-3, 3)\n",
    "\n",
    "        axes[i_ft, i_mov].set_xticks([1,2,3,4])\n",
    "        axes[i_ft, i_mov].set_xticklabels(CDRS_categs.values())\n",
    "        axes[i_ft, i_mov].set_ylabel('indiv. z-scored feature\\n(a.u.)')\n",
    "        axes[i_ft, i_mov].set_xlabel('LID (CDRS sum)')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(utilsFiles.get_project_path('figures'),\n",
    "                            'feat_dysk_corrs',\n",
    "                            'corr_boxplots',\n",
    "                            FIG_NAME),\n",
    "            dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot HEATMAP\n",
    "\n",
    "FIG_NAME = '0129cf_heatmap_specPowerVar_vs_LIDcategs'\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,\n",
    "                         figsize=(12, 4),)\n",
    "ALPHA = .05 / len(feat_names['STN'])\n",
    "# 0 is not sign, 1 is sign\n",
    "heat_arrs = {sig_label: np.array([\n",
    "    [np.nan] * len(feat_names['STN'])\n",
    "] * 2) for sig_label in [0, 1]}\n",
    "\n",
    "for i_ft, ft in enumerate(feat_names['STN']):\n",
    "    \n",
    "    for i_mov, MOV_SEL in enumerate(['INDEP', 'DEPEND']):\n",
    "        # fill arrays with stats calculated before\n",
    "        coeff = stat_arr[MOV_SEL]['coef'][i_ft]\n",
    "        pval = stat_arr[MOV_SEL]['pval'][i_ft]\n",
    "        sig_lab = (pval < ALPHA).astype(int)\n",
    "        heat_arrs[sig_lab][i_mov, i_ft] = coeff\n",
    "\n",
    "# non-sign heatmap\n",
    "vmin, vmax = -.25, .25\n",
    "cmap = 'coolwarm'  # RdBu_r\n",
    "nonsig_map = ax.imshow(heat_arrs[0], vmin=vmin, vmax=vmax,\n",
    "                           cmap=cmap, )\n",
    "# hatch = plt.pcolor(heat_arrs[0], vmin=vmin, vmax=vmax,\n",
    "#                    hatch='//', cmap=cmap,\n",
    "#                    edgecolor='w', )\n",
    "\n",
    "# ax.imshow(X=heat_arrs[0], cmap='coolwarm',\n",
    "        #   alpha=.6, vmin=-.3, vmax=.3,)\n",
    "sig_map = ax.imshow(X=heat_arrs[1], cmap=cmap,  # RdBu_r\n",
    "                    alpha=.9, vmin=vmin, vmax=vmax,)\n",
    "\n",
    "for i_m, i_f in product(np.arange(heat_arrs[1].shape[0]),\n",
    "                        np.arange(heat_arrs[1].shape[1])):\n",
    "    if np.isnan(heat_arrs[1][i_m, i_f]): continue\n",
    "    if abs(heat_arrs[1][i_m, i_f]) > .3: c='w'\n",
    "    else: c = 'black'\n",
    "    ax.text(i_f, i_m, s=round(heat_arrs[1][i_m, i_f], 2),\n",
    "            color=c, horizontalalignment='center',\n",
    "            verticalalignment='center', weight='bold',)\n",
    "\n",
    "cbar = fig.colorbar(sig_map, pad=.01)\n",
    "cbar.ax.set_ylabel('LMM coefficient (a.u.)')\n",
    "\n",
    "ax.set_xticks(np.arange(len(feat_names['STN'])))\n",
    "ax.set_xticklabels(feat_names['STN'],\n",
    "                   rotation=75,)\n",
    "ax.set_yticks([0, 1])\n",
    "ax.set_yticklabels(['move-INDEPENDENT', 'move-DEPENDENT'],)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(utilsFiles.get_project_path('figures'),\n",
    "                            'feat_dysk_corrs',\n",
    "                            'corr_boxplots',\n",
    "                            FIG_NAME),\n",
    "            dpi=300, facecolor='w',)\n",
    "\n",
    "plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_arrs[1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecog_dysk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
