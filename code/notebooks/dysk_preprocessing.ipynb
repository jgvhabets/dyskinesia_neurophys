{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Neurophysiology Data [ReTune Dyskinesia Project]\n",
    "\n",
    "\n",
    "This notebook contains a step-by-step overview of the preprocessing workflow for ECoG- and LFP-data within the ReTune-Project work package B04. This step-wise structure is provided to understand, visualize, and adjust the single steps. Besides this notebook, another script provides execution of the preprocessing steps at once.\n",
    "\n",
    "\n",
    "<b> Data is required to converted into the BIDS-standard. </b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass, field, fields\n",
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import csv\n",
    "\n",
    "#mne\n",
    "import mne_bids\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
      "[Clang 10.0.0 ]\n",
      "pandas 1.3.4\n",
      "numpy 1.20.3\n",
      "mne_bids 0.9\n",
      "mne 0.24.1\n",
      "sci-py 1.7.1\n",
      "sci-kit learn 1.0.1\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('mne_bids', mne_bids.__version__)\n",
    "print('mne', mne.__version__)\n",
    "print('sci-py', scipy.__version__)\n",
    "print('sci-kit learn', sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define local storage directories\n",
    "projectpath = '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'\n",
    "codepath = os.path.join(projectpath, 'code')\n",
    "pynmd_path = os.path.join(codepath, 'py_neuromodulation')\n",
    "rawdatapath = '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata'\n",
    "\n",
    "# define external storage directories\n",
    "ext_projectpath = '/Volumes/JH/Research/CHARITE/projects/dyskinesia_neurophys'\n",
    "ext_datapath = os.path.join(ext_projectpath, 'data/BIDS_Berlin_ECOG_LFP/rawdata')\n",
    "\n",
    "# change working directory to project-code folder\n",
    "os.chdir(codepath)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfpecog_preproc.preproc_data_management as dataMng\n",
    "import lfpecog_preproc.preproc_reref as reref\n",
    "import lfpecog_preproc.preproc_artefacts as artefacts\n",
    "import lfpecog_preproc.preproc_filters as fltrs\n",
    "import lfpecog_preproc.preproc_resample as resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/py_neuromodulation\n"
     ]
    }
   ],
   "source": [
    "# # import from py_neuromodulation after setting directory\n",
    "# # PM the directory of py_neuromodulation has to be added to sys.PATHS\n",
    "# os.chdir(pynmd_path)\n",
    "# print(os.getcwd())\n",
    "# # run from dyskinesia branch-folder in py_nmd\n",
    "# import dyskinesia.preprocessing as preproc\n",
    "# import dyskinesia.preproc_reref as reref\n",
    "# import dyskinesia.preproc_artefacts as artefacts\n",
    "# import dyskinesia.preproc_filters as fltrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data selection, defining Settings\n",
    "\n",
    "\n",
    "\n",
    "Relevant info on BIDS-structure and the handling data-classes\n",
    "\n",
    "\n",
    "- Note that the resulting Data-Class Objects below do not contain actual data yet (!)\n",
    "- Create RawBrainVision data-objects: load data with rawRun1.ecog.load_data() (incl. internal mne-functionality)\n",
    "- Create np.array's: load data with rawRun1.ecog.get_data(), use return_times=True to return two tuples (data, times); (used in preprocessing.py functions)\n",
    "\n",
    "BIDS-RAW Data Structure Info:\n",
    "- Grouped MNE BIDS Raw Object consists all channels within the group,\n",
    "e.g. lfp_left, lfp_left, ecog, acc. Each channel (rawRun1.ecog[0])\n",
    "is a tuple with the first object a ndarray of shape 1, N_samples.\n",
    "- Calling rawRun1.ecog[0][0] gives the ndarray containing only data-points.\n",
    "- Calling rawRun1.ecog[1] gives the ndarray containing the time stamps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1A. Define Preprocess Settings\n",
    "\n",
    "\n",
    "Create data-structures (named-tuples) which contain the defined settings for the preprocessing. These settings contain the parameters of the preprocessing analyses:\n",
    "- win_len (float): Length of single windows in which the data is binned (Default: 1 sec)\n",
    "- artfct_sd_tresh (float): how many std-dev's are used as artefact removal threshold\n",
    "- bandpass_f (int, int): lower and higher borders of freq bandpass filter\n",
    "- transBW (int): transition bandwidth for notch-filter (is full width, 50% above and 50% below the chosen frequencies to filter)\n",
    "- notchW (int): Notch width of notch filter\n",
    "- Fs_orig (int): original sampling frequency (Hz)\n",
    "- Fs_resample (int): sampling frequency (Hz) to which data is resampled\n",
    "- settings_version (str): Abbreviation/codename for this specific version of settings (do not use spaces but rather underscores), e.g. 'v0.0_Jan22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Notes to setting definition:\n",
    "- std dev: 2.5 - 3: removes higher parts of signal which does not look\n",
    "    like artefact;\n",
    "- notch transition width 10 and notch width 2 leaves in 50-100Hz peaks\n",
    "    during ftextraction visualization\n",
    "'''\n",
    "\n",
    "default_lfp_settings = [1, 4, (1, 120), 20, 5, 4000, 800, 'debug_v0.3_Jan22']\n",
    "default_ecog_settings = [1, 4, (1, 120), 20, 5, 4000, 800, 'debug_v0.3_Jan22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload() is used everywhere to be sure that the latest\n",
    "# saved version of a module/function is import during coding/debugging\n",
    "importlib.reload(dataMng)\n",
    "\n",
    "settings = dataMng.Settings(\n",
    "    dataMng.PreprocSettings(*default_lfp_settings),\n",
    "    dataMng.PreprocSettings(*default_lfp_settings),\n",
    "    dataMng.PreprocSettings(*default_ecog_settings),\n",
    "# '*' before lists unpacks the list-values as seperate args\n",
    ")\n",
    "groups = list(settings._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1B. Define Patient and Recording Settings\n",
    "\n",
    "- First DataClass (RunInfo) gets Patient-Run specific input variables to define which run/data-file should be used\n",
    "    - sub (str): patient number\n",
    "    - ses (str): session code (new version e.g. 'LfpEcogMedOn01', old version e.g. 'EphysMedOn01')\n",
    "    - task (str): performed task, e.g. 'Rest'\n",
    "    - acq (str): acquisition, aka state of recording, usually indicates Stimulation status, but also contains time after Dopamine-intake in case of Dyskinesia-Protocol, e.g. 'StimOn01', or 'StimOn02Dopa30'\n",
    "    - run (str): run number, e.g. '01'\n",
    "    - raw_path (str): directory where the raw-BIDS-data is stored (Poly5-files etc), needs to direct to '/.../BIDS_Berlin_ECOG_LFP/rawdata'\n",
    "    - project_path (str): directory where created files and figures are saved; should be main-project-directory, containing sub-folders 'data', 'code', 'figures'\n",
    "    - preproc_sett (str): code of preprocessing settings, is extracted from PreprocSettings DataClass\n",
    "\n",
    "- Second DataClass (RunRawData) creates the MNE-objects which are used in the following function to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PTATIENT-RUN SETTINGS\n",
    "sub = '008'\n",
    "ses = 'EphysMedOn01'  # 'EphysMedOn02'\n",
    "task = 'Rest'\n",
    "acq = 'StimOff'  # 'StimOffLD00'\n",
    "run = '01'\n",
    "rawpath = rawdatapath  # ext_datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------ BIDS DATA INFO ------------\n",
      "The raw-bids-object contains 49 channels with 1208604 datapoints and sample freq  4000.0 Hz\n",
      "Bad channels are: ['LFP_R_16_STN_BS', 'LFP_L_10_STN_BS', 'LFP_L_13_STN_BS', 'LFP_L_14_STN_BS'] \n",
      "\n",
      "BIDS contains:\n",
      "6 ECOG channels,\n",
      "28 DBS channels: (13 left, 15 right), \n",
      "2 EMG channels, \n",
      "1 ECG channel(s), \n",
      "6 Accelerometry (misc) channels.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/lfpecog_preproc/preproc_data_management.py:148: RuntimeWarning: Did not find any events.tsv associated with sub-008_ses-EphysMedOn01_task-Rest_acq-StimOff_run-01.\n",
      "\n",
      "The search_str was \"/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata/sub-008/**/ieeg/sub-008_ses-EphysMedOn01*events.tsv\"\n",
      "  print('\\n\\n------------ BIDS DATA INFO ------------\\n'\n",
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/lfpecog_preproc/preproc_data_management.py:148: RuntimeWarning: Defaulting coordinate frame to unknown from coordinate system input Other\n",
      "  print('\\n\\n------------ BIDS DATA INFO ------------\\n'\n",
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/lfpecog_preproc/preproc_data_management.py:148: RuntimeWarning: Fiducial point nasion not found, assuming identity unknown to head transformation\n",
      "  print('\\n\\n------------ BIDS DATA INFO ------------\\n'\n",
      "/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys/code/lfpecog_preproc/preproc_data_management.py:148: RuntimeWarning: DigMontage is only a subset of info. There are 2 channel positions not present in the DigMontage. The required channels are:\n",
      "\n",
      "['EEG_Cz_TM', 'EEG_Fz_TM'].\n",
      "\n",
      "Consider using inst.set_channel_types if these are not EEG channels, or use the on_missing parameter if the channel positions are allowed to be unknown in your analyses.\n",
      "  print('\\n\\n------------ BIDS DATA INFO ------------\\n'\n"
     ]
    }
   ],
   "source": [
    "# create specific patient-run BIDS-Object for further pre-processing\n",
    "importlib.reload(dataMng)\n",
    "runInfo0 = dataMng.RunInfo(\n",
    "    sub=sub,\n",
    "    ses=ses,\n",
    "    task=task,\n",
    "    acq=acq,\n",
    "    run=run,\n",
    "    raw_path=rawpath,  # used to import the source-bids-data\n",
    "    preproc_sett=settings.lfp_left.settings_version,\n",
    "    project_path=projectpath,  # used to write the created figures and processed data\n",
    ")\n",
    "rawRun = dataMng.RunRawData(bidspath=runInfo0.bidspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional viewer for un-processed data with MNE's interactive viewer\n",
    "\n",
    "NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load grouped BIDS-Objects:\n",
    "# rawRun1.ecog.load_data()\n",
    "\n",
    "# to visualize non-pre-processed data PSD's\n",
    "# for interactive plotter: activate matplotlib qt line\n",
    "# %matplotlib qt\n",
    "# %matplotlib inline\n",
    "\n",
    "# rawRun1.lfp_left.plot()\n",
    "# rawRun1.lfp_left.plot_psd(n_fft=1024)\n",
    "# rawRun1.ecog.plot_psd(n_fft=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Automated Artefact Removal (incl. Visualization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidspath\n",
      "bids\n",
      "lfp\n",
      "lfp_left\n",
      "Reading 0 ... 1208603  =      0.000 ...   302.151 secs...\n",
      "lfp_right\n",
      "Reading 0 ... 1208603  =      0.000 ...   302.151 secs...\n",
      "ecog\n",
      "Reading 0 ... 1208603  =      0.000 ...   302.151 secs...\n",
      "acc\n",
      "emg\n",
      "ecg\n"
     ]
    }
   ],
   "source": [
    "# Actual Loading of the Data from BIDS-files\n",
    "\n",
    "# data_raw is filled with loaded mne-bids data per group\n",
    "data_raw = {}\n",
    "for field in rawRun.__dataclass_fields__:\n",
    "    print(field)\n",
    "    # loops over variables within the data class\n",
    "    if str(field)[:4] == 'lfp_':\n",
    "        data_raw[str(field)] = getattr(rawRun, field).load_data()\n",
    "    elif str(field)[:4] == 'ecog':\n",
    "        data_raw[str(field)] = getattr(rawRun, field).load_data()\n",
    "\n",
    "ch_names = {}\n",
    "for group in groups:\n",
    "    ch_names[group] = data_raw[group].info['ch_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ARTEFACT REMOVAL: lfp_left\n",
      "Ch LFP_L_1_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_2_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_3_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_4_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_5_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_6_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_7_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_8_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_9_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_11_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_12_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_15_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_L_16_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "START ARTEFACT REMOVAL: lfp_right\n",
      "Ch LFP_R_1_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_2_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_3_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_4_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_5_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_6_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_7_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_8_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_9_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_10_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_11_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_12_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_13_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_14_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "Ch LFP_R_15_STN_BS: 0.0% is NaN (artefact or zero)\n",
      "START ARTEFACT REMOVAL: ecog\n",
      "Ch ECOG_L_1_SMC_AT: 0.0% is NaN (artefact or zero)\n",
      "Ch ECOG_L_2_SMC_AT: 0.0% is NaN (artefact or zero)\n",
      "Ch ECOG_L_3_SMC_AT: 0.0% is NaN (artefact or zero)\n",
      "Ch ECOG_L_4_SMC_AT: 0.0% is NaN (artefact or zero)\n",
      "Ch ECOG_L_5_SMC_AT: 0.0% is NaN (artefact or zero)\n",
      "Ch ECOG_L_6_SMC_AT: 0.0% is NaN (artefact or zero)\n"
     ]
    }
   ],
   "source": [
    "# Artefact Removal\n",
    "\n",
    "importlib.reload(artefacts)\n",
    "data_clean = {}\n",
    "ch_nms_clean = {}\n",
    "save_dir = runInfo0.fig_path\n",
    "saveNot = None\n",
    "for group in groups:\n",
    "    data_clean[group], ch_nms_clean[group] = artefacts.artefact_selection(\n",
    "        data_bids=data_raw[group],  # raw BIDS group to process\n",
    "        group=group,\n",
    "        win_len=getattr(settings, group).win_len,\n",
    "        n_stds_cut=getattr(settings, group).artfct_sd_tresh,  # number of std-dev from mean that is used as cut-off\n",
    "        # to save: give directory, to show inline: give 'show', w/o fig: None\n",
    "        save=saveNot,  # if None: no figure saved\n",
    "        RunInfo=runInfo0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group(s) removed: []\n"
     ]
    }
   ],
   "source": [
    "# Quality check: delete groups without valid channels\n",
    "to_del = []\n",
    "for group in data_clean.keys():\n",
    "    if data_clean[group].shape[1] <= 1:\n",
    "        to_del.append(group)\n",
    "for group in to_del:\n",
    "    del(data_clean[group])\n",
    "    del(ch_nms_clean[group])\n",
    "    groups.remove(group)\n",
    "print(f'Group(s) removed: {to_del}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bandpass Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(fltrs)\n",
    "\n",
    "data_bp = {}\n",
    "for group in groups:\n",
    "    data_bp[group] = fltrs.bp_filter(\n",
    "        data=data_clean[group],\n",
    "        sfreq=getattr(settings, group).Fs_orig,\n",
    "        l_freq=getattr(settings, group).bandpass_f[0],\n",
    "        h_freq=getattr(settings, group).bandpass_f[1],\n",
    "        method='iir',  # faster than fir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Notch-filtering for Powerline Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Notch-Filter GROUP: lfp_left\n",
      "Start Notch-Filter GROUP: lfp_right\n",
      "Start Notch-Filter GROUP: ecog\n"
     ]
    }
   ],
   "source": [
    "# notch filtering in BLOCKS\n",
    "\n",
    "importlib.reload(fltrs)\n",
    "save_dir = runInfo0.fig_path\n",
    "saveNOT = None\n",
    "data_nf = {}\n",
    "for group in data_bp.keys():\n",
    "    print(f'Start Notch-Filter GROUP: {group}')\n",
    "    data_nf[group] = fltrs.notch_filter(\n",
    "        data=data_bp[group],\n",
    "        ch_names=ch_nms_clean[group],\n",
    "        group=group,\n",
    "        transBW=getattr(settings, group).transBW,\n",
    "        notchW=getattr(settings, group).notchW,\n",
    "        method='fir',  #iir (8th or. Butterwidth) takes too long\n",
    "        save=saveNOT,  # if None: no figures made and saved\n",
    "        verbose=False,\n",
    "        RunInfo=runInfo0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Resampling\n",
    "\n",
    "\n",
    "Since freq's of interest are up to +/- 100 - 120 Hz, according to the Nyquist-theorem the max sample freq does not need to be more than double (~ 250 Hz).\n",
    "\n",
    "Check differences with resampling to 400 or 800 Hz later. Or working with wider windows.\n",
    "- Swann '16: 800 Hz\n",
    "- Heger/ Herff: 600 Hz (https://www.csl.uni-bremen.de/cms/images/documents/publications/IS2015_brain2text.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(resample)\n",
    "\n",
    "# resampling one run at a time\n",
    "data_rs = {}  # dict to store resampled data\n",
    "for group in groups:\n",
    "    data_rs[group] = resample.resample(\n",
    "        data=data_nf[group],\n",
    "        Fs_orig=getattr(settings, 'ecog').Fs_orig,\n",
    "        Fs_new = getattr(settings, 'ecog').Fs_resample,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Rereferencing\n",
    "\n",
    "\n",
    "\n",
    "Common Practice LFP Re-referencing: difference between two nieghbouring contacts\n",
    "- For segmented Leads: average every level\n",
    "\n",
    "\n",
    "Relevant ECOG-rereferencing literature used: \n",
    "- Common Average Rereferencing (Liu ea, J Neural Eng 2015 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5485665/)\n",
    "- ECOG is local sign with spread +/- 3mm (Dubey, J Neurosc 2019): https://www.jneurosci.org/content/39/22/4299 \n",
    "- READ ON - DATA ANALYSIS: Relevance of data-driven spatial filtering for invasive EEG. For gamma: CAR is probably sufficient. For alpha-beta: ... Hihg inter-subject variability in ECOG. (Shaworonko & Voytek, PLOS Comp Biol 2021: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009298)\n",
    "- Submilimeter (micro)ECOG: http://iebl.ucsd.edu/sites/iebl.ucsd.edu/files/2018-06/Sub-millimeter%20ECoG%20pitch%20in%20human%20enables%20higher%20%EF%AC%81delity%20cognitiveneural%20state%20estimation.pdf\n",
    "\n",
    "\n",
    "Check rereferencing methods:\n",
    "- de Cheveigne/Arzounian NeuroImage 2018\n",
    "- pre-prints Merk 2021 and Petersen 2021 (AG Kühn / AG Neumann)\n",
    "- pre-print epilepsy ecog movement (MUMC)\n",
    "\n",
    "\n",
    "P.M. Check further in to Spatial Filtering:\n",
    "- Spatial filter estimation via spatio-spectral decomposition: ............ TO READ   (Nikulin & Curio, NeuroImage 2011, https://www.sciencedirect.com/science/article/pii/S1053811911000930?via%3Dihub)\n",
    "- Spatio-Spectral Decomposition: proposed dimensionality-reduction instead of PCA (Haufe, ..., Nikulin, https://www.sciencedirect.com/science/article/pii/S1053811914005503?via%3Dihub)\n",
    "- Also check: SPoC (Castano et al NeuroImage Clin 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFP_L_1_STN_BS\tLFP_L_2_STN_BS\tLFP_L_3_STN_BS\tLFP_L_4_STN_BS\tLFP_L_5_STN_BS\tLFP_L_6_STN_BS\tLFP_L_7_STN_BS\tLFP_L_8_STN_BS\tLFP_L_9_STN_BS\tLFP_L_11_STN_BS\tLFP_L_12_STN_BS\tLFP_L_15_STN_BS\tLFP_L_16_STN_BS\n",
      "{0: ['LFP_L_1_', 'LFP_L_2_', 'LFP_L_3_'], 1: ['LFP_L_4_', 'LFP_L_5_', 'LFP_L_6_'], 2: ['LFP_L_7_', 'LFP_L_8_', 'LFP_L_9_'], 3: ['LFP_L_11_', 'LFP_L_12_'], 4: ['LFP_L_15_'], 5: ['LFP_L_16_']}\n",
      "{0: [1, 2, 3], 1: [4, 5, 6], 2: [7, 8, 9], 3: [10, 11], 4: [12], 5: [13]}\n",
      "\n",
      " Rereferencing BS Vercise Cartesia X (L) against other contacts of same level\n",
      "Row REFS [2, 3], SHAPE (302, 14, 800)\n",
      "Row REFS [1, 3], SHAPE (302, 14, 800)\n",
      "Row REFS [1, 2], SHAPE (302, 14, 800)\n",
      "Row REFS [5, 6], SHAPE (302, 14, 800)\n",
      "Row REFS [4, 6], SHAPE (302, 14, 800)\n",
      "Row REFS [4, 5], SHAPE (302, 14, 800)\n",
      "Row REFS [8, 9], SHAPE (302, 14, 800)\n",
      "Row REFS [7, 9], SHAPE (302, 14, 800)\n",
      "Row REFS [7, 8], SHAPE (302, 14, 800)\n",
      "Row REFS [11], SHAPE (302, 14, 800)\n",
      "Row REFS [10], SHAPE (302, 14, 800)\n",
      "TAKE LEVEL HIGHER\n",
      "ref rows [13]\n",
      "(302, 14, 800)\n",
      "TAKE LEVEL LOWER\n",
      "ref rows [12]\n",
      "(302, 14, 800)\n",
      "LFP_R_1_STN_BS\tLFP_R_2_STN_BS\tLFP_R_3_STN_BS\tLFP_R_4_STN_BS\tLFP_R_5_STN_BS\tLFP_R_6_STN_BS\tLFP_R_7_STN_BS\tLFP_R_8_STN_BS\tLFP_R_9_STN_BS\tLFP_R_10_STN_BS\tLFP_R_11_STN_BS\tLFP_R_12_STN_BS\tLFP_R_13_STN_BS\tLFP_R_14_STN_BS\tLFP_R_15_STN_BS\n",
      "{0: ['LFP_R_1_', 'LFP_R_2_', 'LFP_R_3_'], 1: ['LFP_R_4_', 'LFP_R_5_', 'LFP_R_6_'], 2: ['LFP_R_7_', 'LFP_R_8_', 'LFP_R_9_'], 3: ['LFP_R_10_', 'LFP_R_11_', 'LFP_R_12_'], 4: ['LFP_R_13_', 'LFP_R_14_', 'LFP_R_15_'], 5: []}\n",
      "{0: [1, 2, 3], 1: [4, 5, 6], 2: [7, 8, 9], 3: [10, 11, 12], 4: [13, 14, 15], 5: []}\n",
      "\n",
      " Rereferencing BS Vercise Cartesia X (R) against other contacts of same level\n",
      "Row REFS [2, 3], SHAPE (302, 16, 800)\n",
      "Row REFS [1, 3], SHAPE (302, 16, 800)\n",
      "Row REFS [1, 2], SHAPE (302, 16, 800)\n",
      "Row REFS [5, 6], SHAPE (302, 16, 800)\n",
      "Row REFS [4, 6], SHAPE (302, 16, 800)\n",
      "Row REFS [4, 5], SHAPE (302, 16, 800)\n",
      "Row REFS [8, 9], SHAPE (302, 16, 800)\n",
      "Row REFS [7, 9], SHAPE (302, 16, 800)\n",
      "Row REFS [7, 8], SHAPE (302, 16, 800)\n",
      "Row REFS [11, 12], SHAPE (302, 16, 800)\n",
      "Row REFS [10, 12], SHAPE (302, 16, 800)\n",
      "Row REFS [10, 11], SHAPE (302, 16, 800)\n",
      "Row REFS [14, 15], SHAPE (302, 16, 800)\n",
      "Row REFS [13, 15], SHAPE (302, 16, 800)\n",
      "Row REFS [13, 14], SHAPE (302, 16, 800)\n",
      "\n",
      " ECoG Rereferncing: Common Average\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(reref)\n",
    "lfp_reref='segments'\n",
    "data_rrf = {}\n",
    "names = {}\n",
    "\n",
    "# deleting possible existing report-file\n",
    "if 'reref_report.txt' in os.listdir(\n",
    "        runInfo0.data_path):\n",
    "    with open(os.path.join(runInfo0.data_path,\n",
    "            'reref_report.txt'), 'w'):\n",
    "        pass\n",
    "\n",
    "for group in groups:\n",
    "    data_rrf[group], names[group] = reref.rereferencing(\n",
    "        data=data_rs[group],\n",
    "        group=group,\n",
    "        runInfo=runInfo0,\n",
    "        lfp_reref=lfp_reref,\n",
    "        chs_clean=ch_nms_clean[group],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Saving Preprocessed Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataMng)\n",
    "for group in groups:\n",
    "    dataMng.save_arrays(\n",
    "        data=data_rrf[group],\n",
    "        names=names[group],\n",
    "        group=group,\n",
    "        runInfo=runInfo0,\n",
    "        lfp_reref=lfp_reref,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3215b98ba4c40f90b358cffaa32696e7bfbdbe38275c45cfefc4b84b3a964fcf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ecog_dysk': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
