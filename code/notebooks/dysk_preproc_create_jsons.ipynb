{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Neurophysiology Data: Create json-files to Run\n",
    "[ReTune B04 Dyskinesia Project]\n",
    "\n",
    "\n",
    "This notebooks helps to create the JSON-files step-by-step, which define 1) which preprocessing settings are used, and 2) which recordings are included in the preprocessing workflow for ECoG- and LFP-data within the ReTune-Project work package B04.\n",
    "\n",
    "\n",
    "This step-wise structure is provided to understand, visualize, and adjust the single steps. Besides this notebook, a separate py-script provides execution of the preprocessing steps at once via the command line.\n",
    "\n",
    "\n",
    "<b> Data is required to converted into the BIDS-standard. </b>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Loading packages and functions, defining paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "from os import getcwd, makedirs, chdir\n",
    "from os.path import join, dirname, exists\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_path_in_notebook(\n",
    "    subfolder: str = '',\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds path of projectfolder from Notebook.\n",
    "    Start running this once to correctly find\n",
    "    other modules/functions\n",
    "    \"\"\"\n",
    "    path = getcwd()\n",
    "\n",
    "    while path[-20:] != 'dyskinesia_neurophys':\n",
    "\n",
    "        path = dirname(path)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\habetsj\\\\Research\\\\projects\\\\dyskinesia_neurophys\\\\code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define local storage directories\n",
    "projectpath = get_project_path_in_notebook()\n",
    "codepath = join(projectpath, 'code')\n",
    "\n",
    "# change working directory to project-code folder\n",
    "chdir(codepath)\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_fileManagement import get_project_path, get_onedrive_path\n",
    "import lfpecog_preproc.preproc_data_management as dataMng"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix TSV\n",
    "\n",
    "Use in case a scans_tsv file has to be edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = '019'\n",
    "bids_sub='EL019'\n",
    "onedrive_data_path = get_onedrive_path('data')\n",
    "sub_json_path = join(onedrive_data_path, 'preprocess_jsons',\n",
    "                    f'runInfo_{sub}.json')\n",
    "sub_runs = {}\n",
    "     \n",
    "with open(sub_json_path) as f:\n",
    "     sub_json = json.load(f, )  # list of runinfo-dicts\n",
    "\n",
    "scans_path = join(get_onedrive_path('bids_rawdata'),\n",
    "                             f'sub-{bids_sub}',\n",
    "                             f'ses-{sub_json[\"ses\"]}',\n",
    "                             f'sub-{bids_sub}_ses-{sub_json[\"ses\"]}_scans.tsv')\n",
    "\n",
    "# scans_pathTEST = join(get_onedrive_path('bids_rawdata'),\n",
    "#                              f'sub-{bids_sub}',\n",
    "#                              f'ses-{sub_json[\"ses\"]}',\n",
    "#                              f'sub-{bids_sub}_ses-{sub_json[\"ses\"]}_scansTEST.tsv')\n",
    "\n",
    "scans_df = pd.read_csv(scans_path, sep='\\t',)\n",
    "\n",
    "new_df = pd.DataFrame(columns=['filename', 'acq_time'],\n",
    "                      data=[['', '']] * scans_df.shape[0])\n",
    "\n",
    "for i in np.arange(scans_df.shape[0]):\n",
    "\n",
    "     s = scans_df['filename  acq_time'][i]\n",
    "     s1, s2 = s.split(' ')\n",
    "     new_df['filename'][i] = s1\n",
    "     new_df['acq_time'][i] = s2\n",
    "\n",
    "new_df.to_csv(scans_path, sep='\\t', header=True, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_fname = 'preprocSettings_v3.1.json'\n",
    "\n",
    "json_folder = join(get_onedrive_path('data'), 'preprocess_jsons')\n",
    "json_path = join(json_folder, json_fname)\n",
    "\n",
    "with open(json_path, 'r') as json_data:\n",
    "\n",
    "    mainSettings = json.load(json_data)  # gets dir\n",
    "\n",
    "for sub in mainSettings['subs_include']:\n",
    "\n",
    "    if sub == '014': continue\n",
    "\n",
    "    sub_runs = dataMng.get_sub_runs(sub)\n",
    "\n",
    "    for run in list(sub_runs.values()):\n",
    "    \n",
    "        if 'dopa' not in run['acq'].lower():\n",
    "            # print(f'\\n\\tRun {run} SKIPPED, NO \"DOPA\" IN NAME')\n",
    "            continue\n",
    "\n",
    "        print(f'\\nSTART PREPROCESSING Run: {run}\\n')\n",
    "\n",
    "        runInfo = dataMng.RunInfo(\n",
    "            mainSettings=mainSettings,\n",
    "            runDict=run,\n",
    "            project_path=projectpath,\n",
    "        )\n",
    "        \n",
    "        rawRun = dataMng.defineMneRunData(\n",
    "            runInfo=runInfo,\n",
    "            subSettings=run,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACC_R_X_D2_TM',\n",
       " 'ACC_R_Y_D2_TM',\n",
       " 'ACC_R_Z_D2_TM',\n",
       " 'ACC_L_X_D2_TM',\n",
       " 'ACC_L_Y_D2_TM',\n",
       " 'ACC_L_Z_D2_TM']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawRun.acc.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIDSPath(\n",
       "root: c:/Users/habetsj/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata\n",
       "datatype: ieeg\n",
       "basename: sub-EL012_ses-EcogLfpMedOffOnDys01_task-Free_acq-StimOffDopa50_run-1_ieeg.vhdr)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runInfo.bidspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import own functions\n",
    "import lfpecog_preproc.preproc_json_creator as json_creator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Settings of Preprocessing and JSON-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_settings(\n",
    "    version: str, create: bool, json_dir: str,\n",
    "    ecog_sett_list: list = None, lfp_sett_list: list = None,\n",
    "    plot_figures: bool = False, lfp_reref: str = None\n",
    "):\n",
    "    '''\n",
    "    Function...\n",
    "\n",
    "    Arguments:\n",
    "        - version: name of settings-version\n",
    "        - create: To create new or not (used existing)\n",
    "        - json_dir: path to json-folder\n",
    "        - ecog_sett_list/ lfp_sett_list: Lists with new settings\n",
    "        to make for ecog and lfp preprocessing:\n",
    "        [win_len, artfct_sd_tresh,\n",
    "        (bandpass_f_low, bandpass_f_low), transBW, notchW,\n",
    "        Fs_origin, Fs_resample, settings_version]\n",
    "\n",
    "    '''\n",
    "    f = f'settings_{version}.json'\n",
    "    if create:\n",
    "        # check for already existing\n",
    "        if f in os.listdir(json_dir):\n",
    "                print(f'\\nSettings-JSON {version} does already exist,'\n",
    "                ' define new name for current version')\n",
    "                return\n",
    "        for newlist in [ecog_sett_list, lfp_sett_list]:\n",
    "            if newlist is None:  # check if new list is inserted\n",
    "                print('Enter list(s) with new settings')\n",
    "                return\n",
    "            if (float or str) in [type(s) for s in newlist]:  # only int\n",
    "                print('List with new settings can only contain integers')\n",
    "                return\n",
    "        if lfp_reref not in ['segments', 'levels']:\n",
    "            print('LFP-reref method has to be levels / segments')\n",
    "            return\n",
    "\n",
    "        # if all requirements are met: create new json\n",
    "        dict_settings = {  # dict to write into json\n",
    "            'lfp': lfp_sett_list + [version],\n",
    "            'ecog': ecog_sett_list + [version],\n",
    "            'plot_figs': plot_figures,\n",
    "            'lfp_reref': lfp_reref,\n",
    "        }\n",
    "        with open(os.path.join(json_dir, f), 'w') as jsonfile:\n",
    "            json.dump(dict_settings, jsonfile, indent=4)\n",
    "        return os.path.join(json_dir, f)\n",
    "\n",
    "    if not create:\n",
    "        # Define existing version to use\n",
    "        if f not in os.listdir(json_dir):\n",
    "            print(f'Setting-json {version} does not exist.\\n'\n",
    "                  'Insert existing settings-version!!')\n",
    "            return\n",
    "        else:\n",
    "            print(f'Settings {version} exist, please proceed :)')\n",
    "            return os.path.join(json_dir, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_settings = [1024, 4, (1, 120), 10, 2, 4000, 800,]\n",
    "ecog_settings = [1024, 4, (1, 120), 10, 2, 4000, 800,]\n",
    "\n",
    "json_settings = define_settings(\n",
    "    'v0.6_Feb22', create=True, json_dir=json_dir,\n",
    "    ecog_sett_list=ecog_settings, lfp_sett_list=lfp_settings,\n",
    "    plot_figures=True, lfp_reref='levels'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select Recordings to Preprocess\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Print available recordings in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available runs for pt 008 in session MedOn02:\n",
      "\n",
      " 0 ['task-Rest', 'acq-StimOffDopa00', 'run-1']\n",
      "\n",
      " 1 ['task-SelfpacedHandTapL', 'acq-StimOffDopa60', 'run-1']\n",
      "\n",
      " 2 ['task-SelfpacedHandTapL', 'acq-StimOffDopa15', 'run-1']\n",
      "\n",
      " 3 ['task-Rest', 'acq-StimOffDopa10', 'run-1']\n",
      "\n",
      " 4 ['task-Free', 'acq-StimOffDopa55', 'run-1']\n",
      "\n",
      " 5 ['task-SelfpacedHandTapL', 'acq-StimOffDopa35', 'run-1']\n",
      "\n",
      " 6 ['task-Rest', 'acq-StimOffDopa30', 'run-1']\n",
      "\n",
      " 7 ['task-Free', 'acq-StimOffDopa20', 'run-1']\n",
      "\n",
      " 8 ['task-Rest', 'acq-StimOffDopa50', 'run-1']\n"
     ]
    }
   ],
   "source": [
    "# define sub and ses and check available runs\n",
    "sub = '008'\n",
    "ses = 'MedOn02'\n",
    "ses_path = os.path.join(\n",
    "    rawdatapath,\n",
    "    f'sub-{sub}',\n",
    "    f'ses-Ephys{ses}/ieeg'  #EcogLfp\n",
    ")\n",
    "files = [f for f in os.listdir(ses_path) if f[-4:] == '.eeg']\n",
    "print(f'Available runs for pt {sub} in session {ses}:')\n",
    "for n, f in enumerate(files): print('\\n',n, f.split('_')[2:5])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Choose which recordings to exclude from Preprocessing execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclusion from Preprocessing:\n",
      "sub-008_ses-EphysMedOn02_task-Free_acq-StimOffDopa20_run-1_ieeg.eeg added to exclude from preprocessing\n"
     ]
    }
   ],
   "source": [
    "# Select files based on numbers above\n",
    "print('Excluded from Preprocessing:')\n",
    "num_sel_excl = [7]  # add numbers here, or leave empty to include all recordings\n",
    "to_excl = []  # leave empty\n",
    "for f_ex in num_sel_excl:\n",
    "    to_excl.append(files[f_ex])\n",
    "    print(f'{files[f_ex]} added to exclude from preprocessing')\n",
    "\n",
    "# Can not be run twice!! First re-run the cell above to reset the numbers again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included for Preprocessing:\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-Rest_acq-StimOffDopa00_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-SelfpacedHandTapL_acq-StimOffDopa60_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-SelfpacedHandTapL_acq-StimOffDopa15_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-Rest_acq-StimOffDopa10_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-Free_acq-StimOffDopa55_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-SelfpacedHandTapL_acq-StimOffDopa35_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-Rest_acq-StimOffDopa30_run-1_ieeg.eeg\n",
      "\n",
      "sub-008_ses-EphysMedOn02_task-Rest_acq-StimOffDopa50_run-1_ieeg.eeg\n"
     ]
    }
   ],
   "source": [
    "# Check included files after removal\n",
    "for f_ex in to_excl: files.remove(f_ex)\n",
    "print('Included for Preprocessing:')\n",
    "for f in files:\n",
    "    print(f'\\n{f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Create dict's and write them into JSON-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check dictionaries of included runs:\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'Rest', 'acq': 'StimOffDopa00', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'SelfpacedHandTapL', 'acq': 'StimOffDopa60', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'SelfpacedHandTapL', 'acq': 'StimOffDopa15', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'Rest', 'acq': 'StimOffDopa10', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'Free', 'acq': 'StimOffDopa55', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'SelfpacedHandTapL', 'acq': 'StimOffDopa35', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'Rest', 'acq': 'StimOffDopa30', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n",
      "\n",
      "{'sub': '008', 'ses': 'EphysMedOn02', 'task': 'Rest', 'acq': 'StimOffDopa50', 'run': '1', 'raw_path': '/Users/jeroenhabets/OneDrive - Charité - Universitätsmedizin Berlin/BIDS_Berlin_ECOG_LFP/rawdata', 'project_path': '/Users/jeroenhabets/Research/CHARITE/projects/dyskinesia_neurophys'}\n"
     ]
    }
   ],
   "source": [
    "# convert files into dictionaries to write into JSON\n",
    "list_dicts = []\n",
    "for f in files:\n",
    "    list_dicts.append({  # dict to write into json\n",
    "        'sub': f.split('-')[1][:3],\n",
    "        'ses': f.split('-')[2][:-5],\n",
    "        'task': f.split('-')[3][:-4],\n",
    "        'acq': f.split('-')[4][:-4],\n",
    "        'run': f.split('-')[5][0],\n",
    "        'raw_path': rawdatapath,\n",
    "        'project_path': projectpath,\n",
    "    })\n",
    "\n",
    "print('Check dictionaries of included runs:')\n",
    "for d in list_dicts: print(f'\\n{d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write JSON-file with run-dict's\n",
    "fname = 'runinfos_11FEB22b.json'\n",
    "f = os.path.join(json_dir, fname)\n",
    "with open(f, 'w') as jsonfile:\n",
    "    json.dump(list_dicts, jsonfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('ecog_dysk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b948574b4cc10c9dd8fa8cab55862e7a8500229b4c7ca6593391d5001a62fb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
